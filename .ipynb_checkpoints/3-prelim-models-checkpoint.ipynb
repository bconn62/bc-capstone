{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianconnor/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook is a mess but here's what it includes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a preliminary NN of all features thrown together, NaNs dropped, .2 MAE away from the top score on Driven Data\n",
    "- a secondary NN of polynomial'ed weather features plus the other regular features, 1.7 MAE away from top\n",
    "- a (mostly complete) function on creating a submission dataframe and csv from a few different inputs\n",
    "\n",
    "What needs to be done:\n",
    "- filling in NaN values in the test holdout because Driven Data will only accept submissions with all predictions\n",
    "    - thinking about filling in values based on an average of the same week every year, or possibly with a value from one month before or after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = \"./data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>week_start_date</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>...</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_sat_precip_amt_mm</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>18</td>\n",
       "      <td>1990-04-30</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.103725</td>\n",
       "      <td>0.198483</td>\n",
       "      <td>0.177617</td>\n",
       "      <td>12.42</td>\n",
       "      <td>...</td>\n",
       "      <td>73.365714</td>\n",
       "      <td>12.42</td>\n",
       "      <td>14.012857</td>\n",
       "      <td>2.628571</td>\n",
       "      <td>25.442857</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>29.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>19</td>\n",
       "      <td>1990-05-07</td>\n",
       "      <td>0.169900</td>\n",
       "      <td>0.142175</td>\n",
       "      <td>0.162357</td>\n",
       "      <td>0.155486</td>\n",
       "      <td>22.82</td>\n",
       "      <td>...</td>\n",
       "      <td>77.368571</td>\n",
       "      <td>22.82</td>\n",
       "      <td>15.372857</td>\n",
       "      <td>2.371429</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.371429</td>\n",
       "      <td>31.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>20</td>\n",
       "      <td>1990-05-14</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>0.172967</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.170843</td>\n",
       "      <td>34.54</td>\n",
       "      <td>...</td>\n",
       "      <td>82.052857</td>\n",
       "      <td>34.54</td>\n",
       "      <td>16.848571</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.485714</td>\n",
       "      <td>32.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>41.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>21</td>\n",
       "      <td>1990-05-21</td>\n",
       "      <td>0.128633</td>\n",
       "      <td>0.245067</td>\n",
       "      <td>0.227557</td>\n",
       "      <td>0.235886</td>\n",
       "      <td>15.36</td>\n",
       "      <td>...</td>\n",
       "      <td>80.337143</td>\n",
       "      <td>15.36</td>\n",
       "      <td>16.672857</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>27.471429</td>\n",
       "      <td>6.771429</td>\n",
       "      <td>33.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sj</td>\n",
       "      <td>1990</td>\n",
       "      <td>22</td>\n",
       "      <td>1990-05-28</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.262200</td>\n",
       "      <td>0.251200</td>\n",
       "      <td>0.247340</td>\n",
       "      <td>7.52</td>\n",
       "      <td>...</td>\n",
       "      <td>80.460000</td>\n",
       "      <td>7.52</td>\n",
       "      <td>17.210000</td>\n",
       "      <td>3.014286</td>\n",
       "      <td>28.942857</td>\n",
       "      <td>9.371429</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 city  year  weekofyear week_start_date   ndvi_ne   ndvi_nw  \\\n",
       "0           0   sj  1990          18      1990-04-30  0.122600  0.103725   \n",
       "1           1   sj  1990          19      1990-05-07  0.169900  0.142175   \n",
       "2           2   sj  1990          20      1990-05-14  0.032250  0.172967   \n",
       "3           3   sj  1990          21      1990-05-21  0.128633  0.245067   \n",
       "4           4   sj  1990          22      1990-05-28  0.196200  0.262200   \n",
       "\n",
       "    ndvi_se   ndvi_sw  precipitation_amt_mm     ...       \\\n",
       "0  0.198483  0.177617                 12.42     ...        \n",
       "1  0.162357  0.155486                 22.82     ...        \n",
       "2  0.157200  0.170843                 34.54     ...        \n",
       "3  0.227557  0.235886                 15.36     ...        \n",
       "4  0.251200  0.247340                  7.52     ...        \n",
       "\n",
       "   reanalysis_relative_humidity_percent  reanalysis_sat_precip_amt_mm  \\\n",
       "0                             73.365714                         12.42   \n",
       "1                             77.368571                         22.82   \n",
       "2                             82.052857                         34.54   \n",
       "3                             80.337143                         15.36   \n",
       "4                             80.460000                          7.52   \n",
       "\n",
       "   reanalysis_specific_humidity_g_per_kg  reanalysis_tdtr_k  \\\n",
       "0                              14.012857           2.628571   \n",
       "1                              15.372857           2.371429   \n",
       "2                              16.848571           2.300000   \n",
       "3                              16.672857           2.428571   \n",
       "4                              17.210000           3.014286   \n",
       "\n",
       "   station_avg_temp_c  station_diur_temp_rng_c  station_max_temp_c  \\\n",
       "0           25.442857                 6.900000                29.4   \n",
       "1           26.714286                 6.371429                31.7   \n",
       "2           26.714286                 6.485714                32.2   \n",
       "3           27.471429                 6.771429                33.3   \n",
       "4           28.942857                 9.371429                35.0   \n",
       "\n",
       "   station_min_temp_c  station_precip_mm  total_cases  \n",
       "0                20.0               16.0            4  \n",
       "1                22.2                8.6            5  \n",
       "2                22.8               41.4            4  \n",
       "3                23.3                4.0            3  \n",
       "4                23.9                5.8            6  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to drop the week start date column because it is redundant\n",
    "train.drop(\"week_start_date\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>reanalysis_avg_temp_k</th>\n",
       "      <th>reanalysis_dew_point_temp_k</th>\n",
       "      <th>reanalysis_max_air_temp_k</th>\n",
       "      <th>reanalysis_min_air_temp_k</th>\n",
       "      <th>reanalysis_precip_amt_kg_per_m2</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_sat_precip_amt_mm</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>city_iq</th>\n",
       "      <th>city_sj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>18</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.103725</td>\n",
       "      <td>0.198483</td>\n",
       "      <td>0.177617</td>\n",
       "      <td>12.42</td>\n",
       "      <td>297.572857</td>\n",
       "      <td>297.742857</td>\n",
       "      <td>292.414286</td>\n",
       "      <td>299.8</td>\n",
       "      <td>295.9</td>\n",
       "      <td>32.00</td>\n",
       "      <td>73.365714</td>\n",
       "      <td>12.42</td>\n",
       "      <td>14.012857</td>\n",
       "      <td>2.628571</td>\n",
       "      <td>25.442857</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>29.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>19</td>\n",
       "      <td>0.169900</td>\n",
       "      <td>0.142175</td>\n",
       "      <td>0.162357</td>\n",
       "      <td>0.155486</td>\n",
       "      <td>22.82</td>\n",
       "      <td>298.211429</td>\n",
       "      <td>298.442857</td>\n",
       "      <td>293.951429</td>\n",
       "      <td>300.9</td>\n",
       "      <td>296.4</td>\n",
       "      <td>17.94</td>\n",
       "      <td>77.368571</td>\n",
       "      <td>22.82</td>\n",
       "      <td>15.372857</td>\n",
       "      <td>2.371429</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.371429</td>\n",
       "      <td>31.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>20</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>0.172967</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.170843</td>\n",
       "      <td>34.54</td>\n",
       "      <td>298.781429</td>\n",
       "      <td>298.878571</td>\n",
       "      <td>295.434286</td>\n",
       "      <td>300.5</td>\n",
       "      <td>297.3</td>\n",
       "      <td>26.10</td>\n",
       "      <td>82.052857</td>\n",
       "      <td>34.54</td>\n",
       "      <td>16.848571</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.485714</td>\n",
       "      <td>32.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>41.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>21</td>\n",
       "      <td>0.128633</td>\n",
       "      <td>0.245067</td>\n",
       "      <td>0.227557</td>\n",
       "      <td>0.235886</td>\n",
       "      <td>15.36</td>\n",
       "      <td>298.987143</td>\n",
       "      <td>299.228571</td>\n",
       "      <td>295.310000</td>\n",
       "      <td>301.4</td>\n",
       "      <td>297.0</td>\n",
       "      <td>13.90</td>\n",
       "      <td>80.337143</td>\n",
       "      <td>15.36</td>\n",
       "      <td>16.672857</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>27.471429</td>\n",
       "      <td>6.771429</td>\n",
       "      <td>33.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>22</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.262200</td>\n",
       "      <td>0.251200</td>\n",
       "      <td>0.247340</td>\n",
       "      <td>7.52</td>\n",
       "      <td>299.518571</td>\n",
       "      <td>299.664286</td>\n",
       "      <td>295.821429</td>\n",
       "      <td>301.9</td>\n",
       "      <td>297.5</td>\n",
       "      <td>12.20</td>\n",
       "      <td>80.460000</td>\n",
       "      <td>7.52</td>\n",
       "      <td>17.210000</td>\n",
       "      <td>3.014286</td>\n",
       "      <td>28.942857</td>\n",
       "      <td>9.371429</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  weekofyear   ndvi_ne   ndvi_nw   ndvi_se   ndvi_sw  \\\n",
       "0  1990          18  0.122600  0.103725  0.198483  0.177617   \n",
       "1  1990          19  0.169900  0.142175  0.162357  0.155486   \n",
       "2  1990          20  0.032250  0.172967  0.157200  0.170843   \n",
       "3  1990          21  0.128633  0.245067  0.227557  0.235886   \n",
       "4  1990          22  0.196200  0.262200  0.251200  0.247340   \n",
       "\n",
       "   precipitation_amt_mm  reanalysis_air_temp_k  reanalysis_avg_temp_k  \\\n",
       "0                 12.42             297.572857             297.742857   \n",
       "1                 22.82             298.211429             298.442857   \n",
       "2                 34.54             298.781429             298.878571   \n",
       "3                 15.36             298.987143             299.228571   \n",
       "4                  7.52             299.518571             299.664286   \n",
       "\n",
       "   reanalysis_dew_point_temp_k  reanalysis_max_air_temp_k  \\\n",
       "0                   292.414286                      299.8   \n",
       "1                   293.951429                      300.9   \n",
       "2                   295.434286                      300.5   \n",
       "3                   295.310000                      301.4   \n",
       "4                   295.821429                      301.9   \n",
       "\n",
       "   reanalysis_min_air_temp_k  reanalysis_precip_amt_kg_per_m2  \\\n",
       "0                      295.9                            32.00   \n",
       "1                      296.4                            17.94   \n",
       "2                      297.3                            26.10   \n",
       "3                      297.0                            13.90   \n",
       "4                      297.5                            12.20   \n",
       "\n",
       "   reanalysis_relative_humidity_percent  reanalysis_sat_precip_amt_mm  \\\n",
       "0                             73.365714                         12.42   \n",
       "1                             77.368571                         22.82   \n",
       "2                             82.052857                         34.54   \n",
       "3                             80.337143                         15.36   \n",
       "4                             80.460000                          7.52   \n",
       "\n",
       "   reanalysis_specific_humidity_g_per_kg  reanalysis_tdtr_k  \\\n",
       "0                              14.012857           2.628571   \n",
       "1                              15.372857           2.371429   \n",
       "2                              16.848571           2.300000   \n",
       "3                              16.672857           2.428571   \n",
       "4                              17.210000           3.014286   \n",
       "\n",
       "   station_avg_temp_c  station_diur_temp_rng_c  station_max_temp_c  \\\n",
       "0           25.442857                 6.900000                29.4   \n",
       "1           26.714286                 6.371429                31.7   \n",
       "2           26.714286                 6.485714                32.2   \n",
       "3           27.471429                 6.771429                33.3   \n",
       "4           28.942857                 9.371429                35.0   \n",
       "\n",
       "   station_min_temp_c  station_precip_mm  total_cases  city_iq  city_sj  \n",
       "0                20.0               16.0            4        0        1  \n",
       "1                22.2                8.6            5        0        1  \n",
       "2                22.8               41.4            4        0        1  \n",
       "3                23.3                4.0            3        0        1  \n",
       "4                23.9                5.8            6        0        1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The gameplan:\n",
    "Using NN to create an \"index\" from the pixel index. Polynomial all the weather features. lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first, just one off the cuff NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"total_cases\"\n",
    "columns = [x for x in train.columns if x != target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralX = train[columns]\n",
    "neuralY = train[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralX_train, neuralX_test, neuraly_train, neuraly_test = train_test_split(neuralX, neuralY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_ss = StandardScaler()\n",
    "neuralXs_train = neural_ss.fit_transform(neuralX_train)\n",
    "neuralXs_test = neural_ss.transform(neuralX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(899, 24)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuralXs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 899 samples, validate on 300 samples\n",
      "Epoch 1/500\n",
      "899/899 [==============================] - 1s 660us/step - loss: 32.8875 - val_loss: 26.9852\n",
      "Epoch 2/500\n",
      "899/899 [==============================] - 0s 63us/step - loss: 26.1717 - val_loss: 21.8031\n",
      "Epoch 3/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 22.4336 - val_loss: 19.3650\n",
      "Epoch 4/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 20.7284 - val_loss: 18.0079\n",
      "Epoch 5/500\n",
      "899/899 [==============================] - 0s 60us/step - loss: 19.9838 - val_loss: 17.2581\n",
      "Epoch 6/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 18.9190 - val_loss: 16.8135\n",
      "Epoch 7/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 18.4538 - val_loss: 16.4992\n",
      "Epoch 8/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 18.4126 - val_loss: 16.2708\n",
      "Epoch 9/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 18.1292 - val_loss: 16.1151\n",
      "Epoch 10/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 17.7811 - val_loss: 16.0177\n",
      "Epoch 11/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 17.9380 - val_loss: 15.8933\n",
      "Epoch 12/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 17.5955 - val_loss: 15.7400\n",
      "Epoch 13/500\n",
      "899/899 [==============================] - 0s 60us/step - loss: 17.5286 - val_loss: 15.6826\n",
      "Epoch 14/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 17.6482 - val_loss: 15.5638\n",
      "Epoch 15/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 17.3155 - val_loss: 15.4677\n",
      "Epoch 16/500\n",
      "899/899 [==============================] - 0s 62us/step - loss: 17.1603 - val_loss: 15.3803\n",
      "Epoch 17/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 17.2364 - val_loss: 15.3205\n",
      "Epoch 18/500\n",
      "899/899 [==============================] - 0s 62us/step - loss: 16.6845 - val_loss: 15.2945\n",
      "Epoch 19/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 17.3471 - val_loss: 15.2189\n",
      "Epoch 20/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 16.7489 - val_loss: 15.1653\n",
      "Epoch 21/500\n",
      "899/899 [==============================] - 0s 60us/step - loss: 16.5016 - val_loss: 15.1248\n",
      "Epoch 22/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 16.6972 - val_loss: 15.0784\n",
      "Epoch 23/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 16.8210 - val_loss: 15.0778\n",
      "Epoch 24/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 16.7194 - val_loss: 14.9933\n",
      "Epoch 25/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 16.4793 - val_loss: 14.9188\n",
      "Epoch 26/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 16.7434 - val_loss: 14.8929\n",
      "Epoch 27/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 17.0517 - val_loss: 14.8479\n",
      "Epoch 28/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 16.4406 - val_loss: 14.8017\n",
      "Epoch 29/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 16.1948 - val_loss: 14.7881\n",
      "Epoch 30/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 16.7610 - val_loss: 14.7525\n",
      "Epoch 31/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 16.5217 - val_loss: 14.7420\n",
      "Epoch 32/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 16.5607 - val_loss: 14.7053\n",
      "Epoch 33/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 16.3569 - val_loss: 14.7274\n",
      "Epoch 34/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 16.2585 - val_loss: 14.6608\n",
      "Epoch 35/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 16.4907 - val_loss: 14.6334\n",
      "Epoch 36/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 16.2133 - val_loss: 14.6091\n",
      "Epoch 37/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 16.0857 - val_loss: 14.5911\n",
      "Epoch 38/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 16.1890 - val_loss: 14.5766\n",
      "Epoch 39/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 16.3557 - val_loss: 14.5542\n",
      "Epoch 40/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.8546 - val_loss: 14.5433\n",
      "Epoch 41/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.9704 - val_loss: 14.5439\n",
      "Epoch 42/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 16.3281 - val_loss: 14.4937\n",
      "Epoch 43/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 16.0167 - val_loss: 14.4976\n",
      "Epoch 44/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 16.3140 - val_loss: 14.4315\n",
      "Epoch 45/500\n",
      "899/899 [==============================] - 0s 49us/step - loss: 15.7442 - val_loss: 14.4286\n",
      "Epoch 46/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.9934 - val_loss: 14.4376\n",
      "Epoch 47/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 15.9936 - val_loss: 14.3962\n",
      "Epoch 48/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 16.2684 - val_loss: 14.3826\n",
      "Epoch 49/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 16.1465 - val_loss: 14.3700\n",
      "Epoch 50/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 16.0823 - val_loss: 14.3800\n",
      "Epoch 51/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 16.0619 - val_loss: 14.3722\n",
      "Epoch 52/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.9461 - val_loss: 14.3791\n",
      "Epoch 53/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 16.0127 - val_loss: 14.3366\n",
      "Epoch 54/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 15.8741 - val_loss: 14.3107\n",
      "Epoch 55/500\n",
      "899/899 [==============================] - 0s 62us/step - loss: 15.8904 - val_loss: 14.2858\n",
      "Epoch 56/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 15.6825 - val_loss: 14.2640\n",
      "Epoch 57/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 15.8559 - val_loss: 14.2604\n",
      "Epoch 58/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.6096 - val_loss: 14.2815\n",
      "Epoch 59/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.8412 - val_loss: 14.2644\n",
      "Epoch 60/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 16.0262 - val_loss: 14.2257\n",
      "Epoch 61/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.8321 - val_loss: 14.2460\n",
      "Epoch 62/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.7656 - val_loss: 14.2279\n",
      "Epoch 63/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 16.1649 - val_loss: 14.2105\n",
      "Epoch 64/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.4650 - val_loss: 14.1972\n",
      "Epoch 65/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.9039 - val_loss: 14.2222\n",
      "Epoch 66/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.6851 - val_loss: 14.1595\n",
      "Epoch 67/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.7488 - val_loss: 14.1304\n",
      "Epoch 68/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.3126 - val_loss: 14.1686\n",
      "Epoch 69/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.7090 - val_loss: 14.1377\n",
      "Epoch 70/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.7946 - val_loss: 14.1046\n",
      "Epoch 71/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.9933 - val_loss: 14.1110\n",
      "Epoch 72/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.8368 - val_loss: 14.1233\n",
      "Epoch 73/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.8949 - val_loss: 14.1228\n",
      "Epoch 74/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.8821 - val_loss: 14.0766\n",
      "Epoch 75/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.5122 - val_loss: 14.0699\n",
      "Epoch 76/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.5198 - val_loss: 14.0498\n",
      "Epoch 77/500\n",
      "899/899 [==============================] - 0s 49us/step - loss: 15.9637 - val_loss: 14.0432\n",
      "Epoch 78/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.5144 - val_loss: 14.0519\n",
      "Epoch 79/500\n",
      "899/899 [==============================] - 0s 49us/step - loss: 15.8821 - val_loss: 14.0420\n",
      "Epoch 80/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.6734 - val_loss: 14.0504\n",
      "Epoch 81/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.6050 - val_loss: 14.0329\n",
      "Epoch 82/500\n",
      "899/899 [==============================] - 0s 49us/step - loss: 15.7793 - val_loss: 14.0327\n",
      "Epoch 83/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.1845 - val_loss: 14.0136\n",
      "Epoch 84/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.5466 - val_loss: 14.0146\n",
      "Epoch 85/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.6395 - val_loss: 14.0112\n",
      "Epoch 86/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.9063 - val_loss: 14.0096\n",
      "Epoch 87/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 15.8283 - val_loss: 13.9999\n",
      "Epoch 88/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 15.3575 - val_loss: 14.0148\n",
      "Epoch 89/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.4294 - val_loss: 13.9923\n",
      "Epoch 90/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 16.0215 - val_loss: 14.0293\n",
      "Epoch 91/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.3813 - val_loss: 13.9529\n",
      "Epoch 92/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.8644 - val_loss: 13.9273\n",
      "Epoch 93/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.6173 - val_loss: 13.9085\n",
      "Epoch 94/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.7009 - val_loss: 13.9054\n",
      "Epoch 95/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.3454 - val_loss: 13.9394\n",
      "Epoch 96/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.4006 - val_loss: 13.9834\n",
      "Epoch 97/500\n",
      "899/899 [==============================] - 0s 49us/step - loss: 15.4175 - val_loss: 13.9612\n",
      "Epoch 98/500\n",
      "899/899 [==============================] - 0s 49us/step - loss: 16.0393 - val_loss: 13.9454\n",
      "Epoch 99/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 16.1094 - val_loss: 13.9701\n",
      "Epoch 100/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.9788 - val_loss: 13.9334\n",
      "Epoch 101/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.5957 - val_loss: 13.9208\n",
      "Epoch 102/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 15.6245 - val_loss: 13.9101\n",
      "Epoch 103/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.6376 - val_loss: 13.8892\n",
      "Epoch 104/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.6277 - val_loss: 13.9097\n",
      "Epoch 105/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.4816 - val_loss: 13.9692\n",
      "Epoch 106/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 15.4175 - val_loss: 13.9235\n",
      "Epoch 107/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.4156 - val_loss: 13.8686\n",
      "Epoch 108/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.5149 - val_loss: 13.8451\n",
      "Epoch 109/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.3684 - val_loss: 13.9073\n",
      "Epoch 110/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 15.5977 - val_loss: 13.8595\n",
      "Epoch 111/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 15.5997 - val_loss: 13.8273\n",
      "Epoch 112/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.5553 - val_loss: 13.8594\n",
      "Epoch 113/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.5840 - val_loss: 13.8216\n",
      "Epoch 114/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.4587 - val_loss: 13.8185\n",
      "Epoch 115/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.5365 - val_loss: 13.8145\n",
      "Epoch 116/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.5533 - val_loss: 13.8269\n",
      "Epoch 117/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.4993 - val_loss: 13.8245\n",
      "Epoch 118/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.6563 - val_loss: 13.8077\n",
      "Epoch 119/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 15.4880 - val_loss: 13.7949\n",
      "Epoch 120/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.8303 - val_loss: 13.8092\n",
      "Epoch 121/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.8337 - val_loss: 13.8052\n",
      "Epoch 122/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.1429 - val_loss: 13.8548\n",
      "Epoch 123/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.4160 - val_loss: 13.8433\n",
      "Epoch 124/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.6817 - val_loss: 13.7947\n",
      "Epoch 125/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.2233 - val_loss: 13.7699\n",
      "Epoch 126/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.5032 - val_loss: 13.7685\n",
      "Epoch 127/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.7015 - val_loss: 13.7646\n",
      "Epoch 128/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.2214 - val_loss: 13.7716\n",
      "Epoch 129/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.3954 - val_loss: 13.7141\n",
      "Epoch 130/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 15.5753 - val_loss: 13.7435\n",
      "Epoch 131/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.4611 - val_loss: 13.7077\n",
      "Epoch 132/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.7149 - val_loss: 13.7235\n",
      "Epoch 133/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.5191 - val_loss: 13.7310\n",
      "Epoch 134/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.7504 - val_loss: 13.7673\n",
      "Epoch 135/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.5999 - val_loss: 13.7271\n",
      "Epoch 136/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.6204 - val_loss: 13.7388\n",
      "Epoch 137/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.4262 - val_loss: 13.7583\n",
      "Epoch 138/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 15.6877 - val_loss: 13.7644\n",
      "Epoch 139/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 15.4227 - val_loss: 13.6997\n",
      "Epoch 140/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 15.3000 - val_loss: 13.7450\n",
      "Epoch 141/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 15.6828 - val_loss: 13.7317\n",
      "Epoch 142/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 15.4394 - val_loss: 13.7602\n",
      "Epoch 143/500\n",
      "899/899 [==============================] - 0s 60us/step - loss: 15.7001 - val_loss: 13.7861\n",
      "Epoch 144/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 15.2775 - val_loss: 13.7516\n",
      "Epoch 145/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 15.1726 - val_loss: 13.7070\n",
      "Epoch 146/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 15.8357 - val_loss: 13.7059\n",
      "Epoch 147/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 15.4387 - val_loss: 13.7070\n",
      "Epoch 148/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 15.6136 - val_loss: 13.6738\n",
      "Epoch 149/500\n",
      "899/899 [==============================] - 0s 60us/step - loss: 15.6056 - val_loss: 13.6685\n",
      "Epoch 150/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 15.5431 - val_loss: 13.7220\n",
      "Epoch 151/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 15.3997 - val_loss: 13.6796\n",
      "Epoch 152/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.1264 - val_loss: 13.6935\n",
      "Epoch 153/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 15.1013 - val_loss: 13.7981\n",
      "Epoch 154/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 15.5262 - val_loss: 13.7080\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899/899 [==============================] - 0s 54us/step - loss: 15.5687 - val_loss: 13.6791\n",
      "Epoch 156/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 15.6304 - val_loss: 13.6479\n",
      "Epoch 157/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 15.2464 - val_loss: 13.6666\n",
      "Epoch 158/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.0902 - val_loss: 13.6804\n",
      "Epoch 159/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.5522 - val_loss: 13.6314\n",
      "Epoch 160/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 15.2953 - val_loss: 13.6291\n",
      "Epoch 161/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 15.4425 - val_loss: 13.6667\n",
      "Epoch 162/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 15.6364 - val_loss: 13.6595\n",
      "Epoch 163/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.3417 - val_loss: 13.6728\n",
      "Epoch 164/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.0764 - val_loss: 13.6853\n",
      "Epoch 165/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.5576 - val_loss: 13.6548\n",
      "Epoch 166/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 15.1486 - val_loss: 13.6460\n",
      "Epoch 167/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 14.9912 - val_loss: 13.6385\n",
      "Epoch 168/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.2254 - val_loss: 13.6135\n",
      "Epoch 169/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.1176 - val_loss: 13.6294\n",
      "Epoch 170/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 15.1937 - val_loss: 13.6401\n",
      "Epoch 171/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 15.3708 - val_loss: 13.6356\n",
      "Epoch 172/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.2426 - val_loss: 13.6173\n",
      "Epoch 173/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.1894 - val_loss: 13.6098\n",
      "Epoch 174/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.3207 - val_loss: 13.6108\n",
      "Epoch 175/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.2374 - val_loss: 13.6235\n",
      "Epoch 176/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.1045 - val_loss: 13.5919\n",
      "Epoch 177/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.1322 - val_loss: 13.5916\n",
      "Epoch 178/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.5225 - val_loss: 13.5930\n",
      "Epoch 179/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.3640 - val_loss: 13.6013\n",
      "Epoch 180/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.3181 - val_loss: 13.5775\n",
      "Epoch 181/500\n",
      "899/899 [==============================] - 0s 49us/step - loss: 15.1501 - val_loss: 13.5753\n",
      "Epoch 182/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 15.0655 - val_loss: 13.5989\n",
      "Epoch 183/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.5184 - val_loss: 13.5806\n",
      "Epoch 184/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.2948 - val_loss: 13.5981\n",
      "Epoch 185/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 15.5176 - val_loss: 13.5787\n",
      "Epoch 186/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.2200 - val_loss: 13.5936\n",
      "Epoch 187/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.3793 - val_loss: 13.6046\n",
      "Epoch 188/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.3329 - val_loss: 13.5839\n",
      "Epoch 189/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.1454 - val_loss: 13.5986\n",
      "Epoch 190/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.2171 - val_loss: 13.5943\n",
      "Epoch 191/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.4376 - val_loss: 13.5928\n",
      "Epoch 192/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.0845 - val_loss: 13.5806\n",
      "Epoch 193/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 14.9052 - val_loss: 13.5637\n",
      "Epoch 194/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.2354 - val_loss: 13.5835\n",
      "Epoch 195/500\n",
      "899/899 [==============================] - 0s 49us/step - loss: 15.2679 - val_loss: 13.5897\n",
      "Epoch 196/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.0508 - val_loss: 13.5814\n",
      "Epoch 197/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 15.0557 - val_loss: 13.5726\n",
      "Epoch 198/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.1320 - val_loss: 13.5694\n",
      "Epoch 199/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.3171 - val_loss: 13.5745\n",
      "Epoch 200/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.1247 - val_loss: 13.5908\n",
      "Epoch 201/500\n",
      "899/899 [==============================] - 0s 49us/step - loss: 15.1499 - val_loss: 13.5728\n",
      "Epoch 202/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.2834 - val_loss: 13.5295\n",
      "Epoch 203/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.3731 - val_loss: 13.5203\n",
      "Epoch 204/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.2661 - val_loss: 13.5417\n",
      "Epoch 205/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.5829 - val_loss: 13.5320\n",
      "Epoch 206/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.5244 - val_loss: 13.5228\n",
      "Epoch 207/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.4447 - val_loss: 13.5268\n",
      "Epoch 208/500\n",
      "899/899 [==============================] - 0s 60us/step - loss: 15.1120 - val_loss: 13.5148\n",
      "Epoch 209/500\n",
      "899/899 [==============================] - 0s 62us/step - loss: 15.1298 - val_loss: 13.5036\n",
      "Epoch 210/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.9449 - val_loss: 13.5387\n",
      "Epoch 211/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.9767 - val_loss: 13.5261\n",
      "Epoch 212/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.2523 - val_loss: 13.5000\n",
      "Epoch 213/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 15.2938 - val_loss: 13.5005\n",
      "Epoch 214/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.2031 - val_loss: 13.4967\n",
      "Epoch 215/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.9613 - val_loss: 13.4864\n",
      "Epoch 216/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 15.9533 - val_loss: 13.5168\n",
      "Epoch 217/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.1736 - val_loss: 13.4979\n",
      "Epoch 218/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.0108 - val_loss: 13.4925\n",
      "Epoch 219/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 15.1486 - val_loss: 13.4778\n",
      "Epoch 220/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.1860 - val_loss: 13.4736\n",
      "Epoch 221/500\n",
      "899/899 [==============================] - 0s 48us/step - loss: 14.6783 - val_loss: 13.5080\n",
      "Epoch 222/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.8302 - val_loss: 13.4921\n",
      "Epoch 223/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.2022 - val_loss: 13.4585\n",
      "Epoch 224/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 14.9785 - val_loss: 13.5038\n",
      "Epoch 225/500\n",
      "899/899 [==============================] - 0s 49us/step - loss: 14.4040 - val_loss: 13.4925\n",
      "Epoch 226/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 15.0653 - val_loss: 13.4360\n",
      "Epoch 227/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 15.3335 - val_loss: 13.4658\n",
      "Epoch 228/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.3792 - val_loss: 13.4492\n",
      "Epoch 229/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.0527 - val_loss: 13.4512\n",
      "Epoch 230/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.1153 - val_loss: 13.4230\n",
      "Epoch 231/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.0135 - val_loss: 13.4229\n",
      "Epoch 232/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.0994 - val_loss: 13.4506\n",
      "Epoch 233/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 15.1774 - val_loss: 13.4409\n",
      "Epoch 234/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 15.2440 - val_loss: 13.4760\n",
      "Epoch 235/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.2950 - val_loss: 13.4812\n",
      "Epoch 236/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.2149 - val_loss: 13.4847\n",
      "Epoch 237/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.1632 - val_loss: 13.4519\n",
      "Epoch 238/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.3244 - val_loss: 13.4692\n",
      "Epoch 239/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 15.2140 - val_loss: 13.4241\n",
      "Epoch 240/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.1390 - val_loss: 13.4421\n",
      "Epoch 241/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.0772 - val_loss: 13.4422\n",
      "Epoch 242/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.0375 - val_loss: 13.4301\n",
      "Epoch 243/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.1291 - val_loss: 13.4478\n",
      "Epoch 244/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.3107 - val_loss: 13.4733\n",
      "Epoch 245/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.0828 - val_loss: 13.4070\n",
      "Epoch 246/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.4273 - val_loss: 13.4009\n",
      "Epoch 247/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.1261 - val_loss: 13.4099\n",
      "Epoch 248/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 15.0809 - val_loss: 13.4223\n",
      "Epoch 249/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.2912 - val_loss: 13.4084\n",
      "Epoch 250/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 14.4997 - val_loss: 13.4682\n",
      "Epoch 251/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.3363 - val_loss: 13.3913\n",
      "Epoch 252/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.4087 - val_loss: 13.4306\n",
      "Epoch 253/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.1089 - val_loss: 13.3846\n",
      "Epoch 254/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 14.8823 - val_loss: 13.3683\n",
      "Epoch 255/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.9723 - val_loss: 13.3794\n",
      "Epoch 256/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 14.9862 - val_loss: 13.4022\n",
      "Epoch 257/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.3831 - val_loss: 13.3973\n",
      "Epoch 258/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 14.7373 - val_loss: 13.4493\n",
      "Epoch 259/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 14.9049 - val_loss: 13.4098\n",
      "Epoch 260/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 15.3035 - val_loss: 13.4224\n",
      "Epoch 261/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 15.0571 - val_loss: 13.3976\n",
      "Epoch 262/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 14.9313 - val_loss: 13.4141\n",
      "Epoch 263/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.1155 - val_loss: 13.4426\n",
      "Epoch 264/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 15.5048 - val_loss: 13.4311\n",
      "Epoch 265/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.1317 - val_loss: 13.4853\n",
      "Epoch 266/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 14.8601 - val_loss: 13.4077\n",
      "Epoch 267/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 15.2301 - val_loss: 13.3907\n",
      "Epoch 268/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 15.0090 - val_loss: 13.4000\n",
      "Epoch 269/500\n",
      "899/899 [==============================] - 0s 60us/step - loss: 14.8057 - val_loss: 13.3953\n",
      "Epoch 270/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.3465 - val_loss: 13.3987\n",
      "Epoch 271/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 14.8750 - val_loss: 13.4421\n",
      "Epoch 272/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.2627 - val_loss: 13.4117\n",
      "Epoch 273/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.2191 - val_loss: 13.4016\n",
      "Epoch 274/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 14.5884 - val_loss: 13.4095\n",
      "Epoch 275/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.2581 - val_loss: 13.4032\n",
      "Epoch 276/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 14.7638 - val_loss: 13.3997\n",
      "Epoch 277/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.8775 - val_loss: 13.3985\n",
      "Epoch 278/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.1004 - val_loss: 13.4015\n",
      "Epoch 279/500\n",
      "899/899 [==============================] - 0s 49us/step - loss: 15.1773 - val_loss: 13.3555\n",
      "Epoch 280/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.4895 - val_loss: 13.3647\n",
      "Epoch 281/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.7816 - val_loss: 13.4107\n",
      "Epoch 282/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.0278 - val_loss: 13.3797\n",
      "Epoch 283/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.1107 - val_loss: 13.3705\n",
      "Epoch 284/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 14.7648 - val_loss: 13.3959\n",
      "Epoch 285/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 14.8577 - val_loss: 13.3977\n",
      "Epoch 286/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 15.0750 - val_loss: 13.3854\n",
      "Epoch 287/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 15.0119 - val_loss: 13.3814\n",
      "Epoch 288/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 14.9391 - val_loss: 13.3739\n",
      "Epoch 289/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 15.0842 - val_loss: 13.3770\n",
      "Epoch 290/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.0529 - val_loss: 13.4180\n",
      "Epoch 291/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.0809 - val_loss: 13.3798\n",
      "Epoch 292/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.2620 - val_loss: 13.3799\n",
      "Epoch 293/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.8933 - val_loss: 13.3646\n",
      "Epoch 294/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 14.7243 - val_loss: 13.3566\n",
      "Epoch 295/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.1636 - val_loss: 13.3937\n",
      "Epoch 296/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.3713 - val_loss: 13.4145\n",
      "Epoch 297/500\n",
      "899/899 [==============================] - 0s 49us/step - loss: 14.8746 - val_loss: 13.3894\n",
      "Epoch 298/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.1671 - val_loss: 13.3616\n",
      "Epoch 299/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 14.9861 - val_loss: 13.4041\n",
      "Epoch 300/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 15.1602 - val_loss: 13.3821\n",
      "Epoch 301/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.0924 - val_loss: 13.3870\n",
      "Epoch 302/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 14.9944 - val_loss: 13.3895\n",
      "Epoch 303/500\n",
      "899/899 [==============================] - 0s 48us/step - loss: 15.0442 - val_loss: 13.3782\n",
      "Epoch 304/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.0004 - val_loss: 13.4007\n",
      "Epoch 305/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 14.9617 - val_loss: 13.3822\n",
      "Epoch 306/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.3388 - val_loss: 13.3803\n",
      "Epoch 307/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.1724 - val_loss: 13.3501\n",
      "Epoch 308/500\n",
      "899/899 [==============================] - 0s 47us/step - loss: 14.8578 - val_loss: 13.3388\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899/899 [==============================] - 0s 53us/step - loss: 14.9563 - val_loss: 13.3340\n",
      "Epoch 310/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.3000 - val_loss: 13.3422\n",
      "Epoch 311/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.0217 - val_loss: 13.3634\n",
      "Epoch 312/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.0032 - val_loss: 13.3486\n",
      "Epoch 313/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 14.7312 - val_loss: 13.3639\n",
      "Epoch 314/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.2421 - val_loss: 13.4216\n",
      "Epoch 315/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.3055 - val_loss: 13.4122\n",
      "Epoch 316/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.3357 - val_loss: 13.3743\n",
      "Epoch 317/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.3136 - val_loss: 13.3543\n",
      "Epoch 318/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.2807 - val_loss: 13.3414\n",
      "Epoch 319/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 14.9906 - val_loss: 13.3533\n",
      "Epoch 320/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.0310 - val_loss: 13.3548\n",
      "Epoch 321/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.9146 - val_loss: 13.3502\n",
      "Epoch 322/500\n",
      "899/899 [==============================] - 0s 48us/step - loss: 14.9778 - val_loss: 13.3499\n",
      "Epoch 323/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 14.9322 - val_loss: 13.3118\n",
      "Epoch 324/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 14.9063 - val_loss: 13.3299\n",
      "Epoch 325/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 14.8581 - val_loss: 13.3273\n",
      "Epoch 326/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.2023 - val_loss: 13.3158\n",
      "Epoch 327/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 14.6429 - val_loss: 13.3435\n",
      "Epoch 328/500\n",
      "899/899 [==============================] - 0s 48us/step - loss: 15.1397 - val_loss: 13.3414\n",
      "Epoch 329/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.4202 - val_loss: 13.3277\n",
      "Epoch 330/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 14.9855 - val_loss: 13.3078\n",
      "Epoch 331/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 14.7384 - val_loss: 13.3118\n",
      "Epoch 332/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 14.9799 - val_loss: 13.3049\n",
      "Epoch 333/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.2017 - val_loss: 13.3132\n",
      "Epoch 334/500\n",
      "899/899 [==============================] - 0s 49us/step - loss: 14.9176 - val_loss: 13.3170\n",
      "Epoch 335/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 14.8556 - val_loss: 13.3033\n",
      "Epoch 336/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.2278 - val_loss: 13.3042\n",
      "Epoch 337/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 14.7281 - val_loss: 13.2956\n",
      "Epoch 338/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.0190 - val_loss: 13.3204\n",
      "Epoch 339/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.0143 - val_loss: 13.3062\n",
      "Epoch 340/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.0867 - val_loss: 13.3214\n",
      "Epoch 341/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.9522 - val_loss: 13.2945\n",
      "Epoch 342/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.1817 - val_loss: 13.3106\n",
      "Epoch 343/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 14.9493 - val_loss: 13.3155\n",
      "Epoch 344/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 14.6325 - val_loss: 13.3674\n",
      "Epoch 345/500\n",
      "899/899 [==============================] - 0s 49us/step - loss: 15.0857 - val_loss: 13.3522\n",
      "Epoch 346/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.1074 - val_loss: 13.3357\n",
      "Epoch 347/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 14.8204 - val_loss: 13.3216\n",
      "Epoch 348/500\n",
      "899/899 [==============================] - 0s 49us/step - loss: 15.1369 - val_loss: 13.3135\n",
      "Epoch 349/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 14.9079 - val_loss: 13.3151\n",
      "Epoch 350/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.8364 - val_loss: 13.3024\n",
      "Epoch 351/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 14.5798 - val_loss: 13.3149\n",
      "Epoch 352/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.0306 - val_loss: 13.3237\n",
      "Epoch 353/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 14.8879 - val_loss: 13.3025\n",
      "Epoch 354/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 14.8649 - val_loss: 13.3265\n",
      "Epoch 355/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 14.7665 - val_loss: 13.3128\n",
      "Epoch 356/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 14.8125 - val_loss: 13.3331\n",
      "Epoch 357/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.0144 - val_loss: 13.3261\n",
      "Epoch 358/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.0634 - val_loss: 13.2908\n",
      "Epoch 359/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 14.9339 - val_loss: 13.2831\n",
      "Epoch 360/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.1622 - val_loss: 13.2946\n",
      "Epoch 361/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 14.9569 - val_loss: 13.3106\n",
      "Epoch 362/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.8569 - val_loss: 13.2871\n",
      "Epoch 363/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.0182 - val_loss: 13.3123\n",
      "Epoch 364/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.0757 - val_loss: 13.3332\n",
      "Epoch 365/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 15.0456 - val_loss: 13.3159\n",
      "Epoch 366/500\n",
      "899/899 [==============================] - 0s 76us/step - loss: 14.8127 - val_loss: 13.3171\n",
      "Epoch 367/500\n",
      "899/899 [==============================] - 0s 79us/step - loss: 14.6190 - val_loss: 13.3097\n",
      "Epoch 368/500\n",
      "899/899 [==============================] - 0s 63us/step - loss: 14.8239 - val_loss: 13.2954\n",
      "Epoch 369/500\n",
      "899/899 [==============================] - 0s 62us/step - loss: 15.0161 - val_loss: 13.3369\n",
      "Epoch 370/500\n",
      "899/899 [==============================] - 0s 64us/step - loss: 14.7489 - val_loss: 13.3254\n",
      "Epoch 371/500\n",
      "899/899 [==============================] - 0s 66us/step - loss: 14.7317 - val_loss: 13.3484\n",
      "Epoch 372/500\n",
      "899/899 [==============================] - 0s 64us/step - loss: 14.8212 - val_loss: 13.2922\n",
      "Epoch 373/500\n",
      "899/899 [==============================] - 0s 62us/step - loss: 14.8531 - val_loss: 13.3161\n",
      "Epoch 374/500\n",
      "899/899 [==============================] - 0s 71us/step - loss: 14.8055 - val_loss: 13.3542\n",
      "Epoch 375/500\n",
      "899/899 [==============================] - 0s 62us/step - loss: 14.8395 - val_loss: 13.3182\n",
      "Epoch 376/500\n",
      "899/899 [==============================] - 0s 67us/step - loss: 14.8280 - val_loss: 13.2640\n",
      "Epoch 377/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 15.0191 - val_loss: 13.3002\n",
      "Epoch 378/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.7212 - val_loss: 13.2964\n",
      "Epoch 379/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 15.3963 - val_loss: 13.3097\n",
      "Epoch 380/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.0248 - val_loss: 13.3050\n",
      "Epoch 381/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.0283 - val_loss: 13.3151\n",
      "Epoch 382/500\n",
      "899/899 [==============================] - 0s 62us/step - loss: 14.9613 - val_loss: 13.3016\n",
      "Epoch 383/500\n",
      "899/899 [==============================] - 0s 78us/step - loss: 14.8420 - val_loss: 13.3201\n",
      "Epoch 384/500\n",
      "899/899 [==============================] - 0s 83us/step - loss: 15.1130 - val_loss: 13.3169\n",
      "Epoch 385/500\n",
      "899/899 [==============================] - 0s 67us/step - loss: 14.7370 - val_loss: 13.3280\n",
      "Epoch 386/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.0616 - val_loss: 13.2921\n",
      "Epoch 387/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 14.7718 - val_loss: 13.2870\n",
      "Epoch 388/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.2138 - val_loss: 13.2838\n",
      "Epoch 389/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.9870 - val_loss: 13.2736\n",
      "Epoch 390/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 14.8672 - val_loss: 13.2902\n",
      "Epoch 391/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 14.9364 - val_loss: 13.3383\n",
      "Epoch 392/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 14.6168 - val_loss: 13.3427\n",
      "Epoch 393/500\n",
      "899/899 [==============================] - 0s 71us/step - loss: 15.0835 - val_loss: 13.3727\n",
      "Epoch 394/500\n",
      "899/899 [==============================] - 0s 69us/step - loss: 14.8475 - val_loss: 13.3136\n",
      "Epoch 395/500\n",
      "899/899 [==============================] - 0s 75us/step - loss: 14.7697 - val_loss: 13.3262\n",
      "Epoch 396/500\n",
      "899/899 [==============================] - 0s 60us/step - loss: 14.8876 - val_loss: 13.3261\n",
      "Epoch 397/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 15.3360 - val_loss: 13.3313\n",
      "Epoch 398/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.9504 - val_loss: 13.3029\n",
      "Epoch 399/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.9014 - val_loss: 13.2786\n",
      "Epoch 400/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 14.9872 - val_loss: 13.2822\n",
      "Epoch 401/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 14.4005 - val_loss: 13.2837\n",
      "Epoch 402/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 14.6950 - val_loss: 13.3316\n",
      "Epoch 403/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 14.6375 - val_loss: 13.2856\n",
      "Epoch 404/500\n",
      "899/899 [==============================] - 0s 51us/step - loss: 14.8036 - val_loss: 13.2819\n",
      "Epoch 405/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 14.5400 - val_loss: 13.2775\n",
      "Epoch 406/500\n",
      "899/899 [==============================] - 0s 53us/step - loss: 15.0784 - val_loss: 13.2498\n",
      "Epoch 407/500\n",
      "899/899 [==============================] - 0s 67us/step - loss: 14.7660 - val_loss: 13.2648\n",
      "Epoch 408/500\n",
      "899/899 [==============================] - 0s 76us/step - loss: 14.7824 - val_loss: 13.2766\n",
      "Epoch 409/500\n",
      "899/899 [==============================] - 0s 72us/step - loss: 14.7532 - val_loss: 13.3263\n",
      "Epoch 410/500\n",
      "899/899 [==============================] - 0s 61us/step - loss: 15.0553 - val_loss: 13.2947\n",
      "Epoch 411/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.6999 - val_loss: 13.3168\n",
      "Epoch 412/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.7876 - val_loss: 13.3295\n",
      "Epoch 413/500\n",
      "899/899 [==============================] - 0s 49us/step - loss: 15.0882 - val_loss: 13.3068\n",
      "Epoch 414/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 14.7871 - val_loss: 13.2926\n",
      "Epoch 415/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.0917 - val_loss: 13.2864\n",
      "Epoch 416/500\n",
      "899/899 [==============================] - 0s 74us/step - loss: 15.0911 - val_loss: 13.2702\n",
      "Epoch 417/500\n",
      "899/899 [==============================] - 0s 73us/step - loss: 15.1191 - val_loss: 13.2533\n",
      "Epoch 418/500\n",
      "899/899 [==============================] - 0s 72us/step - loss: 14.5432 - val_loss: 13.2518\n",
      "Epoch 419/500\n",
      "899/899 [==============================] - 0s 62us/step - loss: 14.9916 - val_loss: 13.2549\n",
      "Epoch 420/500\n",
      "899/899 [==============================] - 0s 62us/step - loss: 14.7714 - val_loss: 13.3019\n",
      "Epoch 421/500\n",
      "899/899 [==============================] - 0s 61us/step - loss: 15.2261 - val_loss: 13.2658\n",
      "Epoch 422/500\n",
      "899/899 [==============================] - 0s 60us/step - loss: 14.7028 - val_loss: 13.2671\n",
      "Epoch 423/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 15.1589 - val_loss: 13.2621\n",
      "Epoch 424/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 14.7583 - val_loss: 13.2485\n",
      "Epoch 425/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 15.0038 - val_loss: 13.2432\n",
      "Epoch 426/500\n",
      "899/899 [==============================] - 0s 50us/step - loss: 15.1961 - val_loss: 13.2531\n",
      "Epoch 427/500\n",
      "899/899 [==============================] - 0s 52us/step - loss: 14.7311 - val_loss: 13.2430\n",
      "Epoch 428/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 14.9136 - val_loss: 13.2824\n",
      "Epoch 429/500\n",
      "899/899 [==============================] - 0s 66us/step - loss: 15.0618 - val_loss: 13.2765\n",
      "Epoch 430/500\n",
      "899/899 [==============================] - 0s 71us/step - loss: 14.8614 - val_loss: 13.2523\n",
      "Epoch 431/500\n",
      "899/899 [==============================] - 0s 61us/step - loss: 15.1856 - val_loss: 13.2490\n",
      "Epoch 432/500\n",
      "899/899 [==============================] - 0s 63us/step - loss: 14.7270 - val_loss: 13.2470\n",
      "Epoch 433/500\n",
      "899/899 [==============================] - 0s 64us/step - loss: 14.5987 - val_loss: 13.2518\n",
      "Epoch 434/500\n",
      "899/899 [==============================] - 0s 61us/step - loss: 14.9477 - val_loss: 13.2361\n",
      "Epoch 435/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 14.7004 - val_loss: 13.2664\n",
      "Epoch 436/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 14.7504 - val_loss: 13.2668\n",
      "Epoch 437/500\n",
      "899/899 [==============================] - 0s 55us/step - loss: 15.2849 - val_loss: 13.2928\n",
      "Epoch 438/500\n",
      "899/899 [==============================] - 0s 63us/step - loss: 15.2407 - val_loss: 13.2818\n",
      "Epoch 439/500\n",
      "899/899 [==============================] - 0s 62us/step - loss: 14.7572 - val_loss: 13.2900\n",
      "Epoch 440/500\n",
      "899/899 [==============================] - 0s 62us/step - loss: 14.6091 - val_loss: 13.2657\n",
      "Epoch 441/500\n",
      "899/899 [==============================] - 0s 64us/step - loss: 14.7716 - val_loss: 13.2901\n",
      "Epoch 442/500\n",
      "899/899 [==============================] - 0s 64us/step - loss: 14.7841 - val_loss: 13.2826\n",
      "Epoch 443/500\n",
      "899/899 [==============================] - 0s 65us/step - loss: 15.2294 - val_loss: 13.2638\n",
      "Epoch 444/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 14.6718 - val_loss: 13.2684\n",
      "Epoch 445/500\n",
      "899/899 [==============================] - 0s 81us/step - loss: 14.6756 - val_loss: 13.3344\n",
      "Epoch 446/500\n",
      "899/899 [==============================] - 0s 75us/step - loss: 15.0986 - val_loss: 13.3516\n",
      "Epoch 447/500\n",
      "899/899 [==============================] - 0s 79us/step - loss: 14.8514 - val_loss: 13.2918\n",
      "Epoch 448/500\n",
      "899/899 [==============================] - 0s 72us/step - loss: 14.8216 - val_loss: 13.2751\n",
      "Epoch 449/500\n",
      "899/899 [==============================] - 0s 74us/step - loss: 15.1156 - val_loss: 13.2995\n",
      "Epoch 450/500\n",
      "899/899 [==============================] - 0s 65us/step - loss: 14.6335 - val_loss: 13.3037\n",
      "Epoch 451/500\n",
      "899/899 [==============================] - 0s 74us/step - loss: 14.8963 - val_loss: 13.2772\n",
      "Epoch 452/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 15.0132 - val_loss: 13.2831\n",
      "Epoch 453/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 14.9805 - val_loss: 13.2646\n",
      "Epoch 454/500\n",
      "899/899 [==============================] - 0s 72us/step - loss: 14.7659 - val_loss: 13.2706\n",
      "Epoch 455/500\n",
      "899/899 [==============================] - 0s 64us/step - loss: 15.0868 - val_loss: 13.2911\n",
      "Epoch 456/500\n",
      "899/899 [==============================] - 0s 76us/step - loss: 14.5665 - val_loss: 13.2822\n",
      "Epoch 457/500\n",
      "899/899 [==============================] - 0s 78us/step - loss: 14.9739 - val_loss: 13.2853\n",
      "Epoch 458/500\n",
      "899/899 [==============================] - 0s 69us/step - loss: 14.9163 - val_loss: 13.2799\n",
      "Epoch 459/500\n",
      "899/899 [==============================] - 0s 69us/step - loss: 15.0773 - val_loss: 13.2909\n",
      "Epoch 460/500\n",
      "899/899 [==============================] - 0s 68us/step - loss: 14.8920 - val_loss: 13.3192\n",
      "Epoch 461/500\n",
      "899/899 [==============================] - 0s 80us/step - loss: 15.0793 - val_loss: 13.3410\n",
      "Epoch 462/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 14.6574 - val_loss: 13.2996\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899/899 [==============================] - 0s 55us/step - loss: 14.8227 - val_loss: 13.2679\n",
      "Epoch 464/500\n",
      "899/899 [==============================] - 0s 54us/step - loss: 15.1550 - val_loss: 13.2861\n",
      "Epoch 465/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 14.7227 - val_loss: 13.2676\n",
      "Epoch 466/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 14.7982 - val_loss: 13.3039\n",
      "Epoch 467/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 14.8415 - val_loss: 13.2805\n",
      "Epoch 468/500\n",
      "899/899 [==============================] - 0s 57us/step - loss: 14.7728 - val_loss: 13.2868\n",
      "Epoch 469/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 15.0991 - val_loss: 13.2661\n",
      "Epoch 470/500\n",
      "899/899 [==============================] - 0s 65us/step - loss: 15.2764 - val_loss: 13.2793\n",
      "Epoch 471/500\n",
      "899/899 [==============================] - 0s 62us/step - loss: 14.6234 - val_loss: 13.2774\n",
      "Epoch 472/500\n",
      "899/899 [==============================] - 0s 61us/step - loss: 15.0659 - val_loss: 13.2852\n",
      "Epoch 473/500\n",
      "899/899 [==============================] - 0s 63us/step - loss: 14.9483 - val_loss: 13.2947\n",
      "Epoch 474/500\n",
      "899/899 [==============================] - 0s 65us/step - loss: 14.6390 - val_loss: 13.2618\n",
      "Epoch 475/500\n",
      "899/899 [==============================] - 0s 64us/step - loss: 14.9720 - val_loss: 13.2908\n",
      "Epoch 476/500\n",
      "899/899 [==============================] - 0s 60us/step - loss: 14.9268 - val_loss: 13.2768\n",
      "Epoch 477/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 14.8324 - val_loss: 13.2788\n",
      "Epoch 478/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 14.8501 - val_loss: 13.2828\n",
      "Epoch 479/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 14.8827 - val_loss: 13.2724\n",
      "Epoch 480/500\n",
      "899/899 [==============================] - 0s 56us/step - loss: 14.6395 - val_loss: 13.2395\n",
      "Epoch 481/500\n",
      "899/899 [==============================] - 0s 63us/step - loss: 14.4657 - val_loss: 13.2403\n",
      "Epoch 482/500\n",
      "899/899 [==============================] - 0s 62us/step - loss: 14.9623 - val_loss: 13.2633\n",
      "Epoch 483/500\n",
      "899/899 [==============================] - 0s 63us/step - loss: 15.2278 - val_loss: 13.2555\n",
      "Epoch 484/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 14.8258 - val_loss: 13.2385\n",
      "Epoch 485/500\n",
      "899/899 [==============================] - 0s 60us/step - loss: 15.4009 - val_loss: 13.2555\n",
      "Epoch 486/500\n",
      "899/899 [==============================] - 0s 61us/step - loss: 14.9944 - val_loss: 13.2663\n",
      "Epoch 487/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 15.1446 - val_loss: 13.2823\n",
      "Epoch 488/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 14.8481 - val_loss: 13.3117\n",
      "Epoch 489/500\n",
      "899/899 [==============================] - 0s 62us/step - loss: 14.9147 - val_loss: 13.2626\n",
      "Epoch 490/500\n",
      "899/899 [==============================] - 0s 60us/step - loss: 14.8052 - val_loss: 13.3000\n",
      "Epoch 491/500\n",
      "899/899 [==============================] - 0s 65us/step - loss: 14.9654 - val_loss: 13.3184\n",
      "Epoch 492/500\n",
      "899/899 [==============================] - 0s 58us/step - loss: 15.3305 - val_loss: 13.3181\n",
      "Epoch 493/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 14.8494 - val_loss: 13.2608\n",
      "Epoch 494/500\n",
      "899/899 [==============================] - 0s 64us/step - loss: 14.5819 - val_loss: 13.2721\n",
      "Epoch 495/500\n",
      "899/899 [==============================] - 0s 61us/step - loss: 15.0326 - val_loss: 13.2420\n",
      "Epoch 496/500\n",
      "899/899 [==============================] - 0s 59us/step - loss: 14.5910 - val_loss: 13.2347\n",
      "Epoch 497/500\n",
      "899/899 [==============================] - 0s 63us/step - loss: 14.9042 - val_loss: 13.2465\n",
      "Epoch 498/500\n",
      "899/899 [==============================] - 0s 60us/step - loss: 14.9147 - val_loss: 13.2801\n",
      "Epoch 499/500\n",
      "899/899 [==============================] - 0s 67us/step - loss: 14.7823 - val_loss: 13.2673\n",
      "Epoch 500/500\n",
      "899/899 [==============================] - 0s 63us/step - loss: 14.9363 - val_loss: 13.2476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a29798860>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = Sequential()\n",
    "\n",
    "network.add(Dense(24, activation=\"relu\", input_dim=neuralXs_train.shape[1], kernel_regularizer=regularizers.l1(.01)))\n",
    "network.add(Dropout(.5))\n",
    "network.add(Dense(576, activation=\"relu\", kernel_regularizer=regularizers.l1(.01)))\n",
    "network.add(Dropout(.5))\n",
    "network.add(Dense(24, activation=\"relu\", kernel_regularizer=regularizers.l1(.01)))\n",
    "network.add(Dropout(.5))\n",
    "network.add(Dense(1, activation=None, kernel_regularizer=regularizers.l1(.01)))\n",
    "\n",
    "network.compile(loss=\"mean_absolute_error\", optimizer=\"adam\")\n",
    "\n",
    "network.fit(neuralXs_train, neuraly_train, validation_data=(neuralXs_test, neuraly_test), epochs=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural networks are like cheating\n",
    "# the high score on drivendata is 13 MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineering weather features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>reanalysis_avg_temp_k</th>\n",
       "      <th>reanalysis_dew_point_temp_k</th>\n",
       "      <th>reanalysis_max_air_temp_k</th>\n",
       "      <th>reanalysis_min_air_temp_k</th>\n",
       "      <th>reanalysis_precip_amt_kg_per_m2</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_sat_precip_amt_mm</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>city_iq</th>\n",
       "      <th>city_sj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>18</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.103725</td>\n",
       "      <td>0.198483</td>\n",
       "      <td>0.177617</td>\n",
       "      <td>12.42</td>\n",
       "      <td>297.572857</td>\n",
       "      <td>297.742857</td>\n",
       "      <td>292.414286</td>\n",
       "      <td>299.8</td>\n",
       "      <td>295.9</td>\n",
       "      <td>32.00</td>\n",
       "      <td>73.365714</td>\n",
       "      <td>12.42</td>\n",
       "      <td>14.012857</td>\n",
       "      <td>2.628571</td>\n",
       "      <td>25.442857</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>29.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>19</td>\n",
       "      <td>0.169900</td>\n",
       "      <td>0.142175</td>\n",
       "      <td>0.162357</td>\n",
       "      <td>0.155486</td>\n",
       "      <td>22.82</td>\n",
       "      <td>298.211429</td>\n",
       "      <td>298.442857</td>\n",
       "      <td>293.951429</td>\n",
       "      <td>300.9</td>\n",
       "      <td>296.4</td>\n",
       "      <td>17.94</td>\n",
       "      <td>77.368571</td>\n",
       "      <td>22.82</td>\n",
       "      <td>15.372857</td>\n",
       "      <td>2.371429</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.371429</td>\n",
       "      <td>31.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>20</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>0.172967</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.170843</td>\n",
       "      <td>34.54</td>\n",
       "      <td>298.781429</td>\n",
       "      <td>298.878571</td>\n",
       "      <td>295.434286</td>\n",
       "      <td>300.5</td>\n",
       "      <td>297.3</td>\n",
       "      <td>26.10</td>\n",
       "      <td>82.052857</td>\n",
       "      <td>34.54</td>\n",
       "      <td>16.848571</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.485714</td>\n",
       "      <td>32.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>41.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>21</td>\n",
       "      <td>0.128633</td>\n",
       "      <td>0.245067</td>\n",
       "      <td>0.227557</td>\n",
       "      <td>0.235886</td>\n",
       "      <td>15.36</td>\n",
       "      <td>298.987143</td>\n",
       "      <td>299.228571</td>\n",
       "      <td>295.310000</td>\n",
       "      <td>301.4</td>\n",
       "      <td>297.0</td>\n",
       "      <td>13.90</td>\n",
       "      <td>80.337143</td>\n",
       "      <td>15.36</td>\n",
       "      <td>16.672857</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>27.471429</td>\n",
       "      <td>6.771429</td>\n",
       "      <td>33.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>22</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.262200</td>\n",
       "      <td>0.251200</td>\n",
       "      <td>0.247340</td>\n",
       "      <td>7.52</td>\n",
       "      <td>299.518571</td>\n",
       "      <td>299.664286</td>\n",
       "      <td>295.821429</td>\n",
       "      <td>301.9</td>\n",
       "      <td>297.5</td>\n",
       "      <td>12.20</td>\n",
       "      <td>80.460000</td>\n",
       "      <td>7.52</td>\n",
       "      <td>17.210000</td>\n",
       "      <td>3.014286</td>\n",
       "      <td>28.942857</td>\n",
       "      <td>9.371429</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  weekofyear   ndvi_ne   ndvi_nw   ndvi_se   ndvi_sw  \\\n",
       "0  1990          18  0.122600  0.103725  0.198483  0.177617   \n",
       "1  1990          19  0.169900  0.142175  0.162357  0.155486   \n",
       "2  1990          20  0.032250  0.172967  0.157200  0.170843   \n",
       "3  1990          21  0.128633  0.245067  0.227557  0.235886   \n",
       "4  1990          22  0.196200  0.262200  0.251200  0.247340   \n",
       "\n",
       "   precipitation_amt_mm  reanalysis_air_temp_k  reanalysis_avg_temp_k  \\\n",
       "0                 12.42             297.572857             297.742857   \n",
       "1                 22.82             298.211429             298.442857   \n",
       "2                 34.54             298.781429             298.878571   \n",
       "3                 15.36             298.987143             299.228571   \n",
       "4                  7.52             299.518571             299.664286   \n",
       "\n",
       "   reanalysis_dew_point_temp_k  reanalysis_max_air_temp_k  \\\n",
       "0                   292.414286                      299.8   \n",
       "1                   293.951429                      300.9   \n",
       "2                   295.434286                      300.5   \n",
       "3                   295.310000                      301.4   \n",
       "4                   295.821429                      301.9   \n",
       "\n",
       "   reanalysis_min_air_temp_k  reanalysis_precip_amt_kg_per_m2  \\\n",
       "0                      295.9                            32.00   \n",
       "1                      296.4                            17.94   \n",
       "2                      297.3                            26.10   \n",
       "3                      297.0                            13.90   \n",
       "4                      297.5                            12.20   \n",
       "\n",
       "   reanalysis_relative_humidity_percent  reanalysis_sat_precip_amt_mm  \\\n",
       "0                             73.365714                         12.42   \n",
       "1                             77.368571                         22.82   \n",
       "2                             82.052857                         34.54   \n",
       "3                             80.337143                         15.36   \n",
       "4                             80.460000                          7.52   \n",
       "\n",
       "   reanalysis_specific_humidity_g_per_kg  reanalysis_tdtr_k  \\\n",
       "0                              14.012857           2.628571   \n",
       "1                              15.372857           2.371429   \n",
       "2                              16.848571           2.300000   \n",
       "3                              16.672857           2.428571   \n",
       "4                              17.210000           3.014286   \n",
       "\n",
       "   station_avg_temp_c  station_diur_temp_rng_c  station_max_temp_c  \\\n",
       "0           25.442857                 6.900000                29.4   \n",
       "1           26.714286                 6.371429                31.7   \n",
       "2           26.714286                 6.485714                32.2   \n",
       "3           27.471429                 6.771429                33.3   \n",
       "4           28.942857                 9.371429                35.0   \n",
       "\n",
       "   station_min_temp_c  station_precip_mm  total_cases  city_iq  city_sj  \n",
       "0                20.0               16.0            4        0        1  \n",
       "1                22.2                8.6            5        0        1  \n",
       "2                22.8               41.4            4        0        1  \n",
       "3                23.3                4.0            3        0        1  \n",
       "4                23.9                5.8            6        0        1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\",50)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_weather = \"year weekofyear ndvi_ne ndvi_nw ndvi_se ndvi_sw total_cases city_iq city_sj\".split()\n",
    "weather_features = [x for x in train.columns if x not in non_weather]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['precipitation_amt_mm',\n",
       " 'reanalysis_air_temp_k',\n",
       " 'reanalysis_avg_temp_k',\n",
       " 'reanalysis_dew_point_temp_k',\n",
       " 'reanalysis_max_air_temp_k',\n",
       " 'reanalysis_min_air_temp_k',\n",
       " 'reanalysis_precip_amt_kg_per_m2',\n",
       " 'reanalysis_relative_humidity_percent',\n",
       " 'reanalysis_sat_precip_amt_mm',\n",
       " 'reanalysis_specific_humidity_g_per_kg',\n",
       " 'reanalysis_tdtr_k',\n",
       " 'station_avg_temp_c',\n",
       " 'station_diur_temp_rng_c',\n",
       " 'station_max_temp_c',\n",
       " 'station_min_temp_c',\n",
       " 'station_precip_mm']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = PolynomialFeatures(degree=2, include_bias=False)\n",
    "pf_features = pd.DataFrame(data=pf.fit_transform(train[weather_features]), columns=pf.get_feature_names(weather_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1199, 152)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ex = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ex.drop(labels=weather_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ex = train_ex.join(pf_features, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the data\n",
    "engineered_feats = [x for x in train_ex.columns if x != target]\n",
    "X2 = train_ex[engineered_feats]\n",
    "y2 = train_ex[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss2 = StandardScaler()\n",
    "X2s_train = ss2.fit_transform(X2_train)\n",
    "X2s_test = ss2.fit_transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.81979664,  0.70744439, -0.73018063, ...,  1.50168172,\n",
       "        -0.47659598, -0.28315013],\n",
       "       [-0.43980325,  0.70744439, -1.06858815, ...,  1.50168172,\n",
       "        -0.04920945, -0.21420322],\n",
       "       [-0.24980656,  0.50442487,  0.56962577, ...,  1.15369547,\n",
       "        -0.52931594, -0.28749805],\n",
       "       ...,\n",
       "       [ 0.32018353, -0.37532643,  0.3796745 , ...,  0.08855495,\n",
       "         2.12429773,  1.19128083],\n",
       "       [-1.95977682, -0.91671184,  1.03486095, ...,  0.02443326,\n",
       "        -0.28450256, -0.2498849 ],\n",
       "       [ 0.89017362,  0.84279075, -1.17216028, ...,  1.9287754 ,\n",
       "        -0.68580592, -0.29797305]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2s_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(899,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 899 samples, validate on 300 samples\n",
      "Epoch 1/500\n",
      "899/899 [==============================] - 1s 1ms/step - loss: 241.0017 - val_loss: 136.0312\n",
      "Epoch 2/500\n",
      "899/899 [==============================] - 1s 621us/step - loss: 85.8489 - val_loss: 45.8930\n",
      "Epoch 3/500\n",
      "899/899 [==============================] - 1s 664us/step - loss: 36.0821 - val_loss: 25.8683\n",
      "Epoch 4/500\n",
      "899/899 [==============================] - 0s 511us/step - loss: 24.7445 - val_loss: 20.6269\n",
      "Epoch 5/500\n",
      "899/899 [==============================] - 0s 552us/step - loss: 21.9003 - val_loss: 19.0221\n",
      "Epoch 6/500\n",
      "899/899 [==============================] - 0s 471us/step - loss: 20.6417 - val_loss: 18.1815\n",
      "Epoch 7/500\n",
      "899/899 [==============================] - 0s 488us/step - loss: 19.9815 - val_loss: 17.5656\n",
      "Epoch 8/500\n",
      "899/899 [==============================] - 0s 481us/step - loss: 19.2433 - val_loss: 17.2531\n",
      "Epoch 9/500\n",
      "899/899 [==============================] - 0s 491us/step - loss: 19.1070 - val_loss: 16.9384\n",
      "Epoch 10/500\n",
      "899/899 [==============================] - 0s 527us/step - loss: 18.9903 - val_loss: 16.6490\n",
      "Epoch 11/500\n",
      "899/899 [==============================] - 0s 529us/step - loss: 18.5422 - val_loss: 16.6029\n",
      "Epoch 12/500\n",
      "899/899 [==============================] - 0s 482us/step - loss: 18.4483 - val_loss: 16.3773\n",
      "Epoch 13/500\n",
      "899/899 [==============================] - 0s 477us/step - loss: 18.0935 - val_loss: 16.3859\n",
      "Epoch 14/500\n",
      "899/899 [==============================] - 0s 473us/step - loss: 18.1471 - val_loss: 16.0916\n",
      "Epoch 15/500\n",
      "899/899 [==============================] - 0s 468us/step - loss: 18.1826 - val_loss: 15.9790\n",
      "Epoch 16/500\n",
      "899/899 [==============================] - 0s 469us/step - loss: 18.1544 - val_loss: 16.0656\n",
      "Epoch 17/500\n",
      "899/899 [==============================] - 0s 474us/step - loss: 18.1880 - val_loss: 15.9769\n",
      "Epoch 18/500\n",
      "899/899 [==============================] - 0s 506us/step - loss: 17.9592 - val_loss: 16.2172\n",
      "Epoch 19/500\n",
      "899/899 [==============================] - 0s 491us/step - loss: 18.1500 - val_loss: 15.8052\n",
      "Epoch 20/500\n",
      "899/899 [==============================] - 0s 483us/step - loss: 17.9454 - val_loss: 15.7432\n",
      "Epoch 21/500\n",
      "899/899 [==============================] - 0s 498us/step - loss: 17.8736 - val_loss: 15.7972\n",
      "Epoch 22/500\n",
      "899/899 [==============================] - 0s 486us/step - loss: 17.4298 - val_loss: 15.8380\n",
      "Epoch 23/500\n",
      "899/899 [==============================] - 0s 498us/step - loss: 17.9464 - val_loss: 15.6593\n",
      "Epoch 24/500\n",
      "899/899 [==============================] - 0s 487us/step - loss: 17.5090 - val_loss: 15.6821\n",
      "Epoch 25/500\n",
      "899/899 [==============================] - 0s 482us/step - loss: 17.7778 - val_loss: 15.6661\n",
      "Epoch 26/500\n",
      "899/899 [==============================] - 0s 502us/step - loss: 17.7666 - val_loss: 15.8274\n",
      "Epoch 27/500\n",
      "899/899 [==============================] - 0s 488us/step - loss: 18.0336 - val_loss: 15.5954\n",
      "Epoch 28/500\n",
      "899/899 [==============================] - 0s 489us/step - loss: 17.5311 - val_loss: 15.6276\n",
      "Epoch 29/500\n",
      "899/899 [==============================] - 0s 487us/step - loss: 17.7897 - val_loss: 15.5097\n",
      "Epoch 30/500\n",
      "899/899 [==============================] - 0s 487us/step - loss: 17.5839 - val_loss: 15.5162\n",
      "Epoch 31/500\n",
      "899/899 [==============================] - 0s 492us/step - loss: 17.6834 - val_loss: 15.6511\n",
      "Epoch 32/500\n",
      "899/899 [==============================] - 0s 512us/step - loss: 17.4082 - val_loss: 15.7803\n",
      "Epoch 33/500\n",
      "899/899 [==============================] - 0s 481us/step - loss: 17.2689 - val_loss: 15.5979\n",
      "Epoch 34/500\n",
      "899/899 [==============================] - 0s 491us/step - loss: 17.2576 - val_loss: 15.5300\n",
      "Epoch 35/500\n",
      "899/899 [==============================] - 0s 481us/step - loss: 17.5049 - val_loss: 15.5060\n",
      "Epoch 36/500\n",
      "899/899 [==============================] - 0s 548us/step - loss: 17.5530 - val_loss: 15.5186\n",
      "Epoch 37/500\n",
      "899/899 [==============================] - 1s 646us/step - loss: 17.5675 - val_loss: 15.5163\n",
      "Epoch 38/500\n",
      "899/899 [==============================] - 1s 596us/step - loss: 17.4319 - val_loss: 15.4151\n",
      "Epoch 39/500\n",
      "899/899 [==============================] - 0s 525us/step - loss: 17.1665 - val_loss: 15.6646\n",
      "Epoch 40/500\n",
      "899/899 [==============================] - 0s 516us/step - loss: 17.3910 - val_loss: 15.4540\n",
      "Epoch 41/500\n",
      "899/899 [==============================] - 0s 527us/step - loss: 17.7332 - val_loss: 15.3780\n",
      "Epoch 42/500\n",
      "899/899 [==============================] - 0s 516us/step - loss: 17.5181 - val_loss: 15.4351\n",
      "Epoch 43/500\n",
      "899/899 [==============================] - 0s 518us/step - loss: 17.6026 - val_loss: 15.4649\n",
      "Epoch 44/500\n",
      "899/899 [==============================] - 0s 506us/step - loss: 17.5194 - val_loss: 15.3688\n",
      "Epoch 45/500\n",
      "899/899 [==============================] - 0s 523us/step - loss: 17.3256 - val_loss: 15.5388\n",
      "Epoch 46/500\n",
      "899/899 [==============================] - 0s 551us/step - loss: 17.4968 - val_loss: 15.3966\n",
      "Epoch 47/500\n",
      "899/899 [==============================] - 0s 531us/step - loss: 17.6979 - val_loss: 15.3637\n",
      "Epoch 48/500\n",
      "899/899 [==============================] - 0s 529us/step - loss: 17.3276 - val_loss: 15.3714\n",
      "Epoch 49/500\n",
      "899/899 [==============================] - 1s 599us/step - loss: 17.4045 - val_loss: 15.4491\n",
      "Epoch 50/500\n",
      "899/899 [==============================] - 0s 511us/step - loss: 17.2362 - val_loss: 15.3804\n",
      "Epoch 51/500\n",
      "899/899 [==============================] - 0s 525us/step - loss: 17.2577 - val_loss: 15.5216\n",
      "Epoch 52/500\n",
      "899/899 [==============================] - 0s 516us/step - loss: 17.2812 - val_loss: 15.4137\n",
      "Epoch 53/500\n",
      "899/899 [==============================] - 0s 501us/step - loss: 17.2740 - val_loss: 15.2592\n",
      "Epoch 54/500\n",
      "899/899 [==============================] - 0s 476us/step - loss: 17.2591 - val_loss: 15.3619\n",
      "Epoch 55/500\n",
      "899/899 [==============================] - 0s 470us/step - loss: 17.3920 - val_loss: 15.4745\n",
      "Epoch 56/500\n",
      "899/899 [==============================] - 0s 472us/step - loss: 17.3677 - val_loss: 15.3127\n",
      "Epoch 57/500\n",
      "899/899 [==============================] - 0s 474us/step - loss: 17.2599 - val_loss: 15.3904\n",
      "Epoch 58/500\n",
      "899/899 [==============================] - 0s 519us/step - loss: 17.2693 - val_loss: 15.3998\n",
      "Epoch 59/500\n",
      "899/899 [==============================] - 0s 545us/step - loss: 17.4345 - val_loss: 15.2985\n",
      "Epoch 60/500\n",
      "899/899 [==============================] - 0s 546us/step - loss: 17.2180 - val_loss: 15.2536\n",
      "Epoch 61/500\n",
      "899/899 [==============================] - 1s 577us/step - loss: 17.0476 - val_loss: 15.2575\n",
      "Epoch 62/500\n",
      "899/899 [==============================] - 1s 639us/step - loss: 17.4149 - val_loss: 15.2963\n",
      "Epoch 63/500\n",
      "899/899 [==============================] - 1s 562us/step - loss: 17.4901 - val_loss: 15.3361\n",
      "Epoch 64/500\n",
      "899/899 [==============================] - 1s 613us/step - loss: 17.4672 - val_loss: 15.3896\n",
      "Epoch 65/500\n",
      "899/899 [==============================] - 0s 541us/step - loss: 17.3956 - val_loss: 15.2383\n",
      "Epoch 66/500\n",
      "899/899 [==============================] - 1s 576us/step - loss: 17.1998 - val_loss: 15.2676\n",
      "Epoch 67/500\n",
      "899/899 [==============================] - 0s 549us/step - loss: 16.9098 - val_loss: 15.3563\n",
      "Epoch 68/500\n",
      "899/899 [==============================] - 0s 525us/step - loss: 17.4915 - val_loss: 15.3142\n",
      "Epoch 69/500\n",
      "899/899 [==============================] - 0s 545us/step - loss: 16.9865 - val_loss: 15.3917\n",
      "Epoch 70/500\n",
      "899/899 [==============================] - 0s 533us/step - loss: 17.2375 - val_loss: 15.2528\n",
      "Epoch 71/500\n",
      "899/899 [==============================] - 0s 528us/step - loss: 17.3144 - val_loss: 15.3215\n",
      "Epoch 72/500\n",
      "899/899 [==============================] - 0s 546us/step - loss: 17.3742 - val_loss: 15.2690\n",
      "Epoch 73/500\n",
      "899/899 [==============================] - 0s 551us/step - loss: 17.2662 - val_loss: 15.2411\n",
      "Epoch 74/500\n",
      "899/899 [==============================] - 1s 585us/step - loss: 17.3556 - val_loss: 15.2171\n",
      "Epoch 75/500\n",
      "899/899 [==============================] - 1s 686us/step - loss: 17.3749 - val_loss: 15.1688\n",
      "Epoch 76/500\n",
      "899/899 [==============================] - 0s 524us/step - loss: 16.9641 - val_loss: 15.2234\n",
      "Epoch 77/500\n",
      "899/899 [==============================] - 1s 568us/step - loss: 16.6738 - val_loss: 15.2758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "899/899 [==============================] - 0s 519us/step - loss: 17.0826 - val_loss: 15.3382\n",
      "Epoch 79/500\n",
      "899/899 [==============================] - 0s 478us/step - loss: 17.3853 - val_loss: 15.2109\n",
      "Epoch 80/500\n",
      "899/899 [==============================] - 0s 463us/step - loss: 17.1406 - val_loss: 15.3411\n",
      "Epoch 81/500\n",
      "899/899 [==============================] - 0s 463us/step - loss: 17.2063 - val_loss: 15.1793\n",
      "Epoch 82/500\n",
      "899/899 [==============================] - 0s 460us/step - loss: 17.0576 - val_loss: 15.1269\n",
      "Epoch 83/500\n",
      "899/899 [==============================] - 0s 463us/step - loss: 17.1276 - val_loss: 15.2351\n",
      "Epoch 84/500\n",
      "899/899 [==============================] - 0s 468us/step - loss: 17.2833 - val_loss: 15.2520\n",
      "Epoch 85/500\n",
      "899/899 [==============================] - 0s 478us/step - loss: 16.9151 - val_loss: 15.2728\n",
      "Epoch 86/500\n",
      "899/899 [==============================] - 0s 470us/step - loss: 17.4604 - val_loss: 15.2447\n",
      "Epoch 87/500\n",
      "899/899 [==============================] - 0s 466us/step - loss: 17.0707 - val_loss: 15.2232\n",
      "Epoch 88/500\n",
      "899/899 [==============================] - 0s 470us/step - loss: 17.2902 - val_loss: 15.1544\n",
      "Epoch 89/500\n",
      "899/899 [==============================] - 1s 578us/step - loss: 17.0909 - val_loss: 15.3436\n",
      "Epoch 90/500\n",
      "899/899 [==============================] - 0s 474us/step - loss: 17.1147 - val_loss: 15.3360\n",
      "Epoch 91/500\n",
      "899/899 [==============================] - 0s 500us/step - loss: 17.0977 - val_loss: 15.2833\n",
      "Epoch 92/500\n",
      "899/899 [==============================] - 0s 463us/step - loss: 17.1949 - val_loss: 15.3155\n",
      "Epoch 93/500\n",
      "899/899 [==============================] - 0s 464us/step - loss: 17.2389 - val_loss: 15.1881\n",
      "Epoch 94/500\n",
      "899/899 [==============================] - 0s 472us/step - loss: 17.3804 - val_loss: 15.1673\n",
      "Epoch 95/500\n",
      "899/899 [==============================] - 0s 491us/step - loss: 17.0246 - val_loss: 15.1797\n",
      "Epoch 96/500\n",
      "899/899 [==============================] - 0s 477us/step - loss: 17.0687 - val_loss: 15.1474\n",
      "Epoch 97/500\n",
      "899/899 [==============================] - 0s 469us/step - loss: 17.2178 - val_loss: 15.2137\n",
      "Epoch 98/500\n",
      "899/899 [==============================] - 0s 478us/step - loss: 16.8815 - val_loss: 15.1035\n",
      "Epoch 99/500\n",
      "899/899 [==============================] - 0s 464us/step - loss: 16.9965 - val_loss: 15.2263\n",
      "Epoch 100/500\n",
      "899/899 [==============================] - 0s 480us/step - loss: 17.0065 - val_loss: 15.0414\n",
      "Epoch 101/500\n",
      "899/899 [==============================] - 0s 473us/step - loss: 17.2706 - val_loss: 15.0859\n",
      "Epoch 102/500\n",
      "899/899 [==============================] - 0s 482us/step - loss: 16.8305 - val_loss: 15.0865\n",
      "Epoch 103/500\n",
      "899/899 [==============================] - 0s 486us/step - loss: 17.0664 - val_loss: 15.0592\n",
      "Epoch 104/500\n",
      "899/899 [==============================] - 0s 484us/step - loss: 17.0175 - val_loss: 15.1002\n",
      "Epoch 105/500\n",
      "899/899 [==============================] - 0s 484us/step - loss: 17.0991 - val_loss: 15.0649\n",
      "Epoch 106/500\n",
      "899/899 [==============================] - 0s 482us/step - loss: 16.8652 - val_loss: 15.2172\n",
      "Epoch 107/500\n",
      "899/899 [==============================] - 0s 496us/step - loss: 17.0597 - val_loss: 15.1120\n",
      "Epoch 108/500\n",
      "899/899 [==============================] - 0s 489us/step - loss: 16.9123 - val_loss: 15.1624\n",
      "Epoch 109/500\n",
      "899/899 [==============================] - 0s 489us/step - loss: 17.2491 - val_loss: 15.1142\n",
      "Epoch 110/500\n",
      "899/899 [==============================] - 0s 484us/step - loss: 17.1032 - val_loss: 15.0985\n",
      "Epoch 111/500\n",
      "899/899 [==============================] - 0s 489us/step - loss: 16.9013 - val_loss: 15.2137\n",
      "Epoch 112/500\n",
      "899/899 [==============================] - 0s 507us/step - loss: 17.2116 - val_loss: 15.0650\n",
      "Epoch 113/500\n",
      "899/899 [==============================] - 0s 507us/step - loss: 16.8833 - val_loss: 15.2065\n",
      "Epoch 114/500\n",
      "899/899 [==============================] - 0s 481us/step - loss: 17.2772 - val_loss: 15.0945\n",
      "Epoch 115/500\n",
      "899/899 [==============================] - 0s 492us/step - loss: 16.8733 - val_loss: 15.1333\n",
      "Epoch 116/500\n",
      "899/899 [==============================] - 0s 485us/step - loss: 16.8377 - val_loss: 15.0688\n",
      "Epoch 117/500\n",
      "899/899 [==============================] - 0s 487us/step - loss: 17.1798 - val_loss: 15.0069\n",
      "Epoch 118/500\n",
      "899/899 [==============================] - 0s 492us/step - loss: 16.6078 - val_loss: 15.0942\n",
      "Epoch 119/500\n",
      "899/899 [==============================] - 0s 492us/step - loss: 16.6304 - val_loss: 15.0473\n",
      "Epoch 120/500\n",
      "899/899 [==============================] - 0s 497us/step - loss: 17.3588 - val_loss: 14.9904\n",
      "Epoch 121/500\n",
      "899/899 [==============================] - 0s 475us/step - loss: 16.7791 - val_loss: 15.1467\n",
      "Epoch 122/500\n",
      "899/899 [==============================] - 0s 491us/step - loss: 16.7543 - val_loss: 15.2306\n",
      "Epoch 123/500\n",
      "899/899 [==============================] - 0s 503us/step - loss: 17.1211 - val_loss: 15.0543\n",
      "Epoch 124/500\n",
      "899/899 [==============================] - 0s 524us/step - loss: 17.1608 - val_loss: 15.1071\n",
      "Epoch 125/500\n",
      "899/899 [==============================] - 0s 477us/step - loss: 17.2180 - val_loss: 15.1613\n",
      "Epoch 126/500\n",
      "899/899 [==============================] - 0s 494us/step - loss: 17.0222 - val_loss: 15.0372\n",
      "Epoch 127/500\n",
      "899/899 [==============================] - 0s 496us/step - loss: 16.9702 - val_loss: 15.0910\n",
      "Epoch 128/500\n",
      "899/899 [==============================] - 0s 488us/step - loss: 16.7953 - val_loss: 15.1174\n",
      "Epoch 129/500\n",
      "899/899 [==============================] - 0s 485us/step - loss: 17.0708 - val_loss: 15.1053\n",
      "Epoch 130/500\n",
      "899/899 [==============================] - 0s 491us/step - loss: 16.9963 - val_loss: 15.0141\n",
      "Epoch 131/500\n",
      "899/899 [==============================] - 0s 510us/step - loss: 17.0903 - val_loss: 15.0545\n",
      "Epoch 132/500\n",
      "899/899 [==============================] - 0s 505us/step - loss: 16.8075 - val_loss: 14.9726\n",
      "Epoch 133/500\n",
      "899/899 [==============================] - 0s 509us/step - loss: 16.6492 - val_loss: 15.0841\n",
      "Epoch 134/500\n",
      "899/899 [==============================] - 0s 497us/step - loss: 16.8903 - val_loss: 15.0205\n",
      "Epoch 135/500\n",
      "899/899 [==============================] - 0s 494us/step - loss: 17.3037 - val_loss: 15.0073\n",
      "Epoch 136/500\n",
      "899/899 [==============================] - 0s 500us/step - loss: 16.7179 - val_loss: 15.3089\n",
      "Epoch 137/500\n",
      "899/899 [==============================] - 0s 554us/step - loss: 16.5821 - val_loss: 15.0503\n",
      "Epoch 138/500\n",
      "899/899 [==============================] - 1s 564us/step - loss: 16.9226 - val_loss: 15.0071\n",
      "Epoch 139/500\n",
      "899/899 [==============================] - 1s 611us/step - loss: 17.0376 - val_loss: 15.1075\n",
      "Epoch 140/500\n",
      "899/899 [==============================] - 1s 591us/step - loss: 16.8788 - val_loss: 15.0087\n",
      "Epoch 141/500\n",
      "899/899 [==============================] - 1s 596us/step - loss: 16.9792 - val_loss: 15.0333\n",
      "Epoch 142/500\n",
      "899/899 [==============================] - 1s 580us/step - loss: 17.0148 - val_loss: 14.9760\n",
      "Epoch 143/500\n",
      "899/899 [==============================] - 0s 519us/step - loss: 16.6905 - val_loss: 15.0385\n",
      "Epoch 144/500\n",
      "899/899 [==============================] - 0s 521us/step - loss: 16.8422 - val_loss: 14.9801\n",
      "Epoch 145/500\n",
      "899/899 [==============================] - 0s 535us/step - loss: 16.9359 - val_loss: 15.0033\n",
      "Epoch 146/500\n",
      "899/899 [==============================] - 0s 544us/step - loss: 16.9482 - val_loss: 14.9346\n",
      "Epoch 147/500\n",
      "899/899 [==============================] - 0s 531us/step - loss: 16.9380 - val_loss: 14.9378\n",
      "Epoch 148/500\n",
      "899/899 [==============================] - 0s 520us/step - loss: 16.5715 - val_loss: 15.0098\n",
      "Epoch 149/500\n",
      "899/899 [==============================] - 0s 509us/step - loss: 16.8786 - val_loss: 15.0502\n",
      "Epoch 150/500\n",
      "899/899 [==============================] - 0s 517us/step - loss: 17.3479 - val_loss: 14.9957\n",
      "Epoch 151/500\n",
      "899/899 [==============================] - 0s 510us/step - loss: 16.6898 - val_loss: 14.9644\n",
      "Epoch 152/500\n",
      "899/899 [==============================] - 0s 523us/step - loss: 16.6245 - val_loss: 14.9554\n",
      "Epoch 153/500\n",
      "899/899 [==============================] - 0s 530us/step - loss: 16.9314 - val_loss: 14.9746\n",
      "Epoch 154/500\n",
      "899/899 [==============================] - 0s 534us/step - loss: 16.6853 - val_loss: 14.9179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/500\n",
      "899/899 [==============================] - 0s 497us/step - loss: 16.8979 - val_loss: 14.8987\n",
      "Epoch 156/500\n",
      "899/899 [==============================] - 0s 462us/step - loss: 16.8551 - val_loss: 15.0058\n",
      "Epoch 157/500\n",
      "899/899 [==============================] - 0s 452us/step - loss: 16.6568 - val_loss: 14.9832\n",
      "Epoch 158/500\n",
      "899/899 [==============================] - 0s 455us/step - loss: 16.8685 - val_loss: 14.9273\n",
      "Epoch 159/500\n",
      "899/899 [==============================] - 0s 463us/step - loss: 16.8184 - val_loss: 15.0716\n",
      "Epoch 160/500\n",
      "899/899 [==============================] - 0s 463us/step - loss: 17.0072 - val_loss: 15.0069\n",
      "Epoch 161/500\n",
      "899/899 [==============================] - 0s 467us/step - loss: 16.6374 - val_loss: 14.9428\n",
      "Epoch 162/500\n",
      "899/899 [==============================] - 0s 464us/step - loss: 16.7606 - val_loss: 14.9852\n",
      "Epoch 163/500\n",
      "899/899 [==============================] - 0s 459us/step - loss: 16.7193 - val_loss: 14.9466\n",
      "Epoch 164/500\n",
      "899/899 [==============================] - 0s 467us/step - loss: 17.1025 - val_loss: 14.9806\n",
      "Epoch 165/500\n",
      "899/899 [==============================] - 0s 466us/step - loss: 16.8551 - val_loss: 14.8702\n",
      "Epoch 166/500\n",
      "899/899 [==============================] - 0s 469us/step - loss: 16.7276 - val_loss: 14.9877\n",
      "Epoch 167/500\n",
      "899/899 [==============================] - 1s 589us/step - loss: 16.8503 - val_loss: 14.9966\n",
      "Epoch 168/500\n",
      "899/899 [==============================] - 1s 572us/step - loss: 16.6872 - val_loss: 14.8623\n",
      "Epoch 169/500\n",
      "899/899 [==============================] - 0s 502us/step - loss: 16.5328 - val_loss: 15.0282\n",
      "Epoch 170/500\n",
      "899/899 [==============================] - 0s 530us/step - loss: 16.5757 - val_loss: 15.1422\n",
      "Epoch 171/500\n",
      "899/899 [==============================] - 0s 486us/step - loss: 17.0955 - val_loss: 14.9421\n",
      "Epoch 172/500\n",
      "899/899 [==============================] - 0s 536us/step - loss: 17.0510 - val_loss: 14.8878\n",
      "Epoch 173/500\n",
      "899/899 [==============================] - 0s 544us/step - loss: 16.7555 - val_loss: 14.8760\n",
      "Epoch 174/500\n",
      "899/899 [==============================] - 0s 522us/step - loss: 16.7313 - val_loss: 14.9794\n",
      "Epoch 175/500\n",
      "899/899 [==============================] - 0s 541us/step - loss: 16.5296 - val_loss: 15.0057\n",
      "Epoch 176/500\n",
      "899/899 [==============================] - 0s 512us/step - loss: 16.9885 - val_loss: 14.9107\n",
      "Epoch 177/500\n",
      "899/899 [==============================] - 1s 619us/step - loss: 16.6802 - val_loss: 14.8842\n",
      "Epoch 178/500\n",
      "899/899 [==============================] - 1s 560us/step - loss: 16.7923 - val_loss: 15.0237\n",
      "Epoch 179/500\n",
      "899/899 [==============================] - 1s 571us/step - loss: 16.8989 - val_loss: 14.9409\n",
      "Epoch 180/500\n",
      "899/899 [==============================] - 1s 594us/step - loss: 16.8871 - val_loss: 14.8953\n",
      "Epoch 181/500\n",
      "899/899 [==============================] - 1s 606us/step - loss: 17.1294 - val_loss: 14.9814\n",
      "Epoch 182/500\n",
      "899/899 [==============================] - 1s 576us/step - loss: 17.0330 - val_loss: 14.9645\n",
      "Epoch 183/500\n",
      "899/899 [==============================] - 1s 670us/step - loss: 16.5574 - val_loss: 14.9519\n",
      "Epoch 184/500\n",
      "899/899 [==============================] - 1s 588us/step - loss: 16.6985 - val_loss: 14.9505\n",
      "Epoch 185/500\n",
      "899/899 [==============================] - 1s 585us/step - loss: 16.5257 - val_loss: 14.9440\n",
      "Epoch 186/500\n",
      "899/899 [==============================] - 1s 576us/step - loss: 16.6153 - val_loss: 14.9710\n",
      "Epoch 187/500\n",
      "899/899 [==============================] - 1s 631us/step - loss: 16.8110 - val_loss: 14.9229\n",
      "Epoch 188/500\n",
      "899/899 [==============================] - 1s 607us/step - loss: 16.8111 - val_loss: 14.9028\n",
      "Epoch 189/500\n",
      "899/899 [==============================] - ETA: 0s - loss: 17.11 - 1s 570us/step - loss: 16.8998 - val_loss: 14.9267\n",
      "Epoch 190/500\n",
      "899/899 [==============================] - 0s 544us/step - loss: 16.8230 - val_loss: 15.0440\n",
      "Epoch 191/500\n",
      "899/899 [==============================] - 0s 552us/step - loss: 16.6347 - val_loss: 15.0459\n",
      "Epoch 192/500\n",
      "899/899 [==============================] - 1s 739us/step - loss: 16.3188 - val_loss: 15.0071\n",
      "Epoch 193/500\n",
      "899/899 [==============================] - 1s 632us/step - loss: 16.6658 - val_loss: 15.0714\n",
      "Epoch 194/500\n",
      "899/899 [==============================] - 1s 557us/step - loss: 16.7616 - val_loss: 15.0142\n",
      "Epoch 195/500\n",
      "899/899 [==============================] - 1s 619us/step - loss: 16.8199 - val_loss: 15.0064\n",
      "Epoch 196/500\n",
      "899/899 [==============================] - 1s 632us/step - loss: 16.6031 - val_loss: 14.9336\n",
      "Epoch 197/500\n",
      "899/899 [==============================] - 0s 541us/step - loss: 17.0015 - val_loss: 14.9014\n",
      "Epoch 198/500\n",
      "899/899 [==============================] - 0s 554us/step - loss: 16.7974 - val_loss: 15.0497\n",
      "Epoch 199/500\n",
      "899/899 [==============================] - 0s 551us/step - loss: 16.7847 - val_loss: 14.8426\n",
      "Epoch 200/500\n",
      "899/899 [==============================] - 1s 564us/step - loss: 16.7598 - val_loss: 14.9757\n",
      "Epoch 201/500\n",
      "899/899 [==============================] - 0s 546us/step - loss: 16.6745 - val_loss: 14.8472\n",
      "Epoch 202/500\n",
      "899/899 [==============================] - 1s 576us/step - loss: 16.7805 - val_loss: 14.8330\n",
      "Epoch 203/500\n",
      "899/899 [==============================] - 1s 575us/step - loss: 16.7272 - val_loss: 14.8740\n",
      "Epoch 204/500\n",
      "899/899 [==============================] - 0s 542us/step - loss: 16.8244 - val_loss: 14.8512\n",
      "Epoch 205/500\n",
      "899/899 [==============================] - 1s 604us/step - loss: 16.6741 - val_loss: 14.8928\n",
      "Epoch 206/500\n",
      "899/899 [==============================] - 1s 640us/step - loss: 16.6804 - val_loss: 14.8681\n",
      "Epoch 207/500\n",
      "899/899 [==============================] - 1s 603us/step - loss: 16.5034 - val_loss: 14.8738\n",
      "Epoch 208/500\n",
      "899/899 [==============================] - 1s 569us/step - loss: 16.5598 - val_loss: 14.8842\n",
      "Epoch 209/500\n",
      "899/899 [==============================] - 1s 578us/step - loss: 16.7979 - val_loss: 14.9017\n",
      "Epoch 210/500\n",
      "899/899 [==============================] - 1s 599us/step - loss: 16.9656 - val_loss: 14.8972\n",
      "Epoch 211/500\n",
      "899/899 [==============================] - 1s 589us/step - loss: 17.1025 - val_loss: 14.8771\n",
      "Epoch 212/500\n",
      "899/899 [==============================] - 0s 544us/step - loss: 16.7495 - val_loss: 14.8647\n",
      "Epoch 213/500\n",
      "899/899 [==============================] - 1s 559us/step - loss: 16.6228 - val_loss: 14.9072\n",
      "Epoch 214/500\n",
      "899/899 [==============================] - 0s 553us/step - loss: 16.8574 - val_loss: 14.8889\n",
      "Epoch 215/500\n",
      "899/899 [==============================] - 0s 544us/step - loss: 17.0069 - val_loss: 14.8371\n",
      "Epoch 216/500\n",
      "899/899 [==============================] - 0s 546us/step - loss: 16.6579 - val_loss: 14.8809\n",
      "Epoch 217/500\n",
      "899/899 [==============================] - 0s 548us/step - loss: 16.7694 - val_loss: 14.8210\n",
      "Epoch 218/500\n",
      "899/899 [==============================] - 0s 549us/step - loss: 16.8406 - val_loss: 14.9495\n",
      "Epoch 219/500\n",
      "899/899 [==============================] - 0s 546us/step - loss: 16.8586 - val_loss: 14.7588\n",
      "Epoch 220/500\n",
      "899/899 [==============================] - 0s 554us/step - loss: 16.6611 - val_loss: 14.7923\n",
      "Epoch 221/500\n",
      "899/899 [==============================] - 0s 545us/step - loss: 16.5069 - val_loss: 14.7576\n",
      "Epoch 222/500\n",
      "899/899 [==============================] - 0s 535us/step - loss: 16.7385 - val_loss: 14.7862\n",
      "Epoch 223/500\n",
      "899/899 [==============================] - 0s 540us/step - loss: 16.6638 - val_loss: 14.8239\n",
      "Epoch 224/500\n",
      "899/899 [==============================] - 1s 571us/step - loss: 16.6436 - val_loss: 15.0278\n",
      "Epoch 225/500\n",
      "899/899 [==============================] - 0s 551us/step - loss: 16.6707 - val_loss: 15.0398\n",
      "Epoch 226/500\n",
      "899/899 [==============================] - 1s 559us/step - loss: 16.6304 - val_loss: 14.9144\n",
      "Epoch 227/500\n",
      "899/899 [==============================] - 0s 528us/step - loss: 16.7790 - val_loss: 14.8801\n",
      "Epoch 228/500\n",
      "899/899 [==============================] - 0s 528us/step - loss: 16.4926 - val_loss: 14.8520\n",
      "Epoch 229/500\n",
      "899/899 [==============================] - 0s 553us/step - loss: 16.8167 - val_loss: 14.9077\n",
      "Epoch 230/500\n",
      "899/899 [==============================] - 0s 547us/step - loss: 16.7613 - val_loss: 14.9139\n",
      "Epoch 231/500\n",
      "899/899 [==============================] - 0s 521us/step - loss: 16.5066 - val_loss: 14.8957\n",
      "Epoch 232/500\n",
      "899/899 [==============================] - 0s 499us/step - loss: 16.6040 - val_loss: 14.8944\n",
      "Epoch 233/500\n",
      "899/899 [==============================] - 0s 493us/step - loss: 16.3598 - val_loss: 15.1000\n",
      "Epoch 234/500\n",
      "899/899 [==============================] - 0s 490us/step - loss: 17.2857 - val_loss: 14.9285\n",
      "Epoch 235/500\n",
      "899/899 [==============================] - 0s 487us/step - loss: 16.8978 - val_loss: 14.8613\n",
      "Epoch 236/500\n",
      "899/899 [==============================] - 0s 521us/step - loss: 16.7873 - val_loss: 14.8195\n",
      "Epoch 237/500\n",
      "899/899 [==============================] - 0s 497us/step - loss: 16.7182 - val_loss: 14.8602\n",
      "Epoch 238/500\n",
      "899/899 [==============================] - 0s 499us/step - loss: 16.4333 - val_loss: 14.8375\n",
      "Epoch 239/500\n",
      "899/899 [==============================] - 0s 505us/step - loss: 16.4935 - val_loss: 14.8833\n",
      "Epoch 240/500\n",
      "899/899 [==============================] - 0s 501us/step - loss: 16.5215 - val_loss: 14.8490\n",
      "Epoch 241/500\n",
      "899/899 [==============================] - 0s 500us/step - loss: 16.6865 - val_loss: 14.8159\n",
      "Epoch 242/500\n",
      "899/899 [==============================] - 0s 502us/step - loss: 16.5257 - val_loss: 14.7505\n",
      "Epoch 243/500\n",
      "899/899 [==============================] - 0s 502us/step - loss: 16.5247 - val_loss: 15.0977\n",
      "Epoch 244/500\n",
      "899/899 [==============================] - 0s 503us/step - loss: 16.9503 - val_loss: 14.8103\n",
      "Epoch 245/500\n",
      "899/899 [==============================] - 0s 511us/step - loss: 16.7305 - val_loss: 14.8953\n",
      "Epoch 246/500\n",
      "899/899 [==============================] - 0s 504us/step - loss: 16.5853 - val_loss: 14.8953\n",
      "Epoch 247/500\n",
      "899/899 [==============================] - 0s 525us/step - loss: 16.8538 - val_loss: 14.8602\n",
      "Epoch 248/500\n",
      "899/899 [==============================] - 0s 517us/step - loss: 16.6918 - val_loss: 14.8635\n",
      "Epoch 249/500\n",
      "899/899 [==============================] - 0s 508us/step - loss: 16.6627 - val_loss: 14.9707\n",
      "Epoch 250/500\n",
      "899/899 [==============================] - 0s 545us/step - loss: 16.7757 - val_loss: 14.8815\n",
      "Epoch 251/500\n",
      "899/899 [==============================] - 1s 566us/step - loss: 16.6036 - val_loss: 14.8611\n",
      "Epoch 252/500\n",
      "899/899 [==============================] - 0s 547us/step - loss: 16.4933 - val_loss: 14.7551\n",
      "Epoch 253/500\n",
      "899/899 [==============================] - 1s 645us/step - loss: 16.9014 - val_loss: 14.8249\n",
      "Epoch 254/500\n",
      "899/899 [==============================] - 1s 618us/step - loss: 16.7007 - val_loss: 14.8229\n",
      "Epoch 255/500\n",
      "899/899 [==============================] - 1s 642us/step - loss: 16.8153 - val_loss: 14.7095\n",
      "Epoch 256/500\n",
      "899/899 [==============================] - 1s 587us/step - loss: 16.3636 - val_loss: 14.8008\n",
      "Epoch 257/500\n",
      "899/899 [==============================] - 1s 568us/step - loss: 16.6255 - val_loss: 14.7673\n",
      "Epoch 258/500\n",
      "899/899 [==============================] - 0s 550us/step - loss: 16.6928 - val_loss: 14.7932\n",
      "Epoch 259/500\n",
      "899/899 [==============================] - 0s 553us/step - loss: 16.5605 - val_loss: 14.7929\n",
      "Epoch 260/500\n",
      "899/899 [==============================] - 0s 541us/step - loss: 16.5394 - val_loss: 14.9133\n",
      "Epoch 261/500\n",
      "899/899 [==============================] - 0s 553us/step - loss: 16.4580 - val_loss: 14.7122\n",
      "Epoch 262/500\n",
      "899/899 [==============================] - 1s 589us/step - loss: 16.6319 - val_loss: 14.8325\n",
      "Epoch 263/500\n",
      "899/899 [==============================] - 1s 664us/step - loss: 16.7698 - val_loss: 14.8361\n",
      "Epoch 264/500\n",
      "899/899 [==============================] - 0s 449us/step - loss: 16.7070 - val_loss: 14.8150\n",
      "Epoch 265/500\n",
      "899/899 [==============================] - 0s 476us/step - loss: 16.6367 - val_loss: 14.7337\n",
      "Epoch 266/500\n",
      "899/899 [==============================] - 0s 406us/step - loss: 16.4518 - val_loss: 14.7316\n",
      "Epoch 267/500\n",
      "899/899 [==============================] - 0s 405us/step - loss: 16.7986 - val_loss: 14.7112\n",
      "Epoch 268/500\n",
      "899/899 [==============================] - 0s 409us/step - loss: 16.8351 - val_loss: 14.7989\n",
      "Epoch 269/500\n",
      "899/899 [==============================] - 0s 404us/step - loss: 16.3565 - val_loss: 15.0723\n",
      "Epoch 270/500\n",
      "899/899 [==============================] - 0s 407us/step - loss: 16.7012 - val_loss: 14.8899\n",
      "Epoch 271/500\n",
      "899/899 [==============================] - 0s 403us/step - loss: 16.5772 - val_loss: 14.8650\n",
      "Epoch 272/500\n",
      "899/899 [==============================] - 0s 408us/step - loss: 16.7667 - val_loss: 15.1120\n",
      "Epoch 273/500\n",
      "899/899 [==============================] - 0s 406us/step - loss: 16.6862 - val_loss: 14.8729\n",
      "Epoch 274/500\n",
      "899/899 [==============================] - 0s 404us/step - loss: 16.8405 - val_loss: 14.8887\n",
      "Epoch 275/500\n",
      "899/899 [==============================] - 0s 406us/step - loss: 16.4987 - val_loss: 15.0071\n",
      "Epoch 276/500\n",
      "899/899 [==============================] - 0s 405us/step - loss: 16.5717 - val_loss: 14.7997\n",
      "Epoch 277/500\n",
      "899/899 [==============================] - 0s 407us/step - loss: 16.6787 - val_loss: 14.9423\n",
      "Epoch 278/500\n",
      "899/899 [==============================] - 0s 406us/step - loss: 16.9011 - val_loss: 14.7904\n",
      "Epoch 279/500\n",
      "899/899 [==============================] - 0s 430us/step - loss: 16.5971 - val_loss: 14.7936\n",
      "Epoch 280/500\n",
      "899/899 [==============================] - 0s 528us/step - loss: 16.5498 - val_loss: 14.9042\n",
      "Epoch 281/500\n",
      "899/899 [==============================] - 0s 482us/step - loss: 16.6382 - val_loss: 14.8549\n",
      "Epoch 282/500\n",
      "899/899 [==============================] - 0s 409us/step - loss: 16.3696 - val_loss: 14.9223\n",
      "Epoch 283/500\n",
      "899/899 [==============================] - 0s 452us/step - loss: 16.6905 - val_loss: 14.8251\n",
      "Epoch 284/500\n",
      "899/899 [==============================] - 0s 451us/step - loss: 16.5266 - val_loss: 14.8449\n",
      "Epoch 285/500\n",
      "899/899 [==============================] - 0s 464us/step - loss: 16.7619 - val_loss: 14.9498\n",
      "Epoch 286/500\n",
      "899/899 [==============================] - 0s 463us/step - loss: 16.6166 - val_loss: 14.9258\n",
      "Epoch 287/500\n",
      "899/899 [==============================] - 0s 415us/step - loss: 16.4654 - val_loss: 14.7977\n",
      "Epoch 288/500\n",
      "899/899 [==============================] - 0s 447us/step - loss: 16.7506 - val_loss: 14.8165\n",
      "Epoch 289/500\n",
      "899/899 [==============================] - 0s 454us/step - loss: 16.8668 - val_loss: 14.8913\n",
      "Epoch 290/500\n",
      "899/899 [==============================] - 0s 428us/step - loss: 16.7002 - val_loss: 14.8783\n",
      "Epoch 291/500\n",
      "899/899 [==============================] - 0s 473us/step - loss: 16.4770 - val_loss: 14.8801\n",
      "Epoch 292/500\n",
      "899/899 [==============================] - 0s 409us/step - loss: 17.0380 - val_loss: 14.7637\n",
      "Epoch 293/500\n",
      "899/899 [==============================] - 0s 428us/step - loss: 16.5467 - val_loss: 14.8352\n",
      "Epoch 294/500\n",
      "899/899 [==============================] - 0s 441us/step - loss: 16.4760 - val_loss: 14.7431\n",
      "Epoch 295/500\n",
      "899/899 [==============================] - 1s 603us/step - loss: 16.7596 - val_loss: 14.7359\n",
      "Epoch 296/500\n",
      "899/899 [==============================] - 1s 662us/step - loss: 16.7197 - val_loss: 14.7615\n",
      "Epoch 297/500\n",
      "899/899 [==============================] - 1s 582us/step - loss: 16.7520 - val_loss: 15.0335\n",
      "Epoch 298/500\n",
      "899/899 [==============================] - 1s 656us/step - loss: 16.7559 - val_loss: 14.6899\n",
      "Epoch 299/500\n",
      "899/899 [==============================] - 1s 630us/step - loss: 16.9320 - val_loss: 14.7883\n",
      "Epoch 300/500\n",
      "899/899 [==============================] - 1s 575us/step - loss: 16.5432 - val_loss: 14.8154\n",
      "Epoch 301/500\n",
      "899/899 [==============================] - 1s 613us/step - loss: 16.6037 - val_loss: 14.6826\n",
      "Epoch 302/500\n",
      "899/899 [==============================] - 1s 657us/step - loss: 16.6728 - val_loss: 14.7385\n",
      "Epoch 303/500\n",
      "899/899 [==============================] - 0s 532us/step - loss: 16.4673 - val_loss: 14.7603\n",
      "Epoch 304/500\n",
      "899/899 [==============================] - 1s 566us/step - loss: 16.8984 - val_loss: 14.8078\n",
      "Epoch 305/500\n",
      "899/899 [==============================] - 1s 560us/step - loss: 16.6684 - val_loss: 14.8119\n",
      "Epoch 306/500\n",
      "899/899 [==============================] - 1s 587us/step - loss: 16.6891 - val_loss: 14.8240\n",
      "Epoch 307/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899/899 [==============================] - 0s 543us/step - loss: 16.5783 - val_loss: 14.6968\n",
      "Epoch 308/500\n",
      "899/899 [==============================] - 0s 507us/step - loss: 16.4402 - val_loss: 15.0000\n",
      "Epoch 309/500\n",
      "899/899 [==============================] - 0s 491us/step - loss: 16.4347 - val_loss: 14.6986\n",
      "Epoch 310/500\n",
      "899/899 [==============================] - 0s 482us/step - loss: 16.7020 - val_loss: 14.8194\n",
      "Epoch 311/500\n",
      "899/899 [==============================] - 0s 484us/step - loss: 16.5542 - val_loss: 14.8154\n",
      "Epoch 312/500\n",
      "899/899 [==============================] - 0s 484us/step - loss: 16.7822 - val_loss: 14.6630\n",
      "Epoch 313/500\n",
      "899/899 [==============================] - 0s 515us/step - loss: 16.8396 - val_loss: 14.6844\n",
      "Epoch 314/500\n",
      "899/899 [==============================] - 0s 476us/step - loss: 16.8640 - val_loss: 14.9096\n",
      "Epoch 315/500\n",
      "899/899 [==============================] - 0s 488us/step - loss: 16.1879 - val_loss: 14.7728\n",
      "Epoch 316/500\n",
      "899/899 [==============================] - 0s 490us/step - loss: 16.6207 - val_loss: 14.7581\n",
      "Epoch 317/500\n",
      "899/899 [==============================] - 0s 487us/step - loss: 16.6417 - val_loss: 14.7699\n",
      "Epoch 318/500\n",
      "899/899 [==============================] - 0s 487us/step - loss: 16.3707 - val_loss: 14.8021\n",
      "Epoch 319/500\n",
      "899/899 [==============================] - 0s 485us/step - loss: 16.2184 - val_loss: 14.5749\n",
      "Epoch 320/500\n",
      "899/899 [==============================] - 0s 501us/step - loss: 16.4262 - val_loss: 14.6851\n",
      "Epoch 321/500\n",
      "899/899 [==============================] - 0s 493us/step - loss: 16.4783 - val_loss: 14.6981\n",
      "Epoch 322/500\n",
      "899/899 [==============================] - 0s 487us/step - loss: 16.6532 - val_loss: 14.7124\n",
      "Epoch 323/500\n",
      "899/899 [==============================] - 0s 490us/step - loss: 16.5159 - val_loss: 14.8244\n",
      "Epoch 324/500\n",
      "899/899 [==============================] - 0s 508us/step - loss: 16.6992 - val_loss: 14.6153\n",
      "Epoch 325/500\n",
      "899/899 [==============================] - 0s 501us/step - loss: 16.2563 - val_loss: 14.7415\n",
      "Epoch 326/500\n",
      "899/899 [==============================] - 0s 507us/step - loss: 16.7159 - val_loss: 14.7399\n",
      "Epoch 327/500\n",
      "899/899 [==============================] - 0s 534us/step - loss: 16.7705 - val_loss: 14.6478\n",
      "Epoch 328/500\n",
      "899/899 [==============================] - 0s 510us/step - loss: 16.6583 - val_loss: 14.6673\n",
      "Epoch 329/500\n",
      "899/899 [==============================] - 0s 507us/step - loss: 16.4077 - val_loss: 14.6577\n",
      "Epoch 330/500\n",
      "899/899 [==============================] - 0s 516us/step - loss: 16.4931 - val_loss: 14.6486\n",
      "Epoch 331/500\n",
      "899/899 [==============================] - 0s 513us/step - loss: 16.3254 - val_loss: 14.7481\n",
      "Epoch 332/500\n",
      "899/899 [==============================] - 0s 510us/step - loss: 16.3332 - val_loss: 14.7708\n",
      "Epoch 333/500\n",
      "899/899 [==============================] - 0s 507us/step - loss: 16.3376 - val_loss: 14.6090\n",
      "Epoch 334/500\n",
      "899/899 [==============================] - 0s 507us/step - loss: 16.4877 - val_loss: 14.7894\n",
      "Epoch 335/500\n",
      "899/899 [==============================] - 0s 505us/step - loss: 16.3629 - val_loss: 14.7989\n",
      "Epoch 336/500\n",
      "899/899 [==============================] - 0s 513us/step - loss: 16.4424 - val_loss: 14.7380\n",
      "Epoch 337/500\n",
      "899/899 [==============================] - 0s 518us/step - loss: 16.9169 - val_loss: 14.6289\n",
      "Epoch 338/500\n",
      "899/899 [==============================] - 0s 525us/step - loss: 16.3609 - val_loss: 14.5993\n",
      "Epoch 339/500\n",
      "899/899 [==============================] - 0s 525us/step - loss: 16.7140 - val_loss: 14.7407\n",
      "Epoch 340/500\n",
      "899/899 [==============================] - 0s 508us/step - loss: 16.4328 - val_loss: 14.7156\n",
      "Epoch 341/500\n",
      "899/899 [==============================] - 0s 514us/step - loss: 16.6574 - val_loss: 14.7439\n",
      "Epoch 342/500\n",
      "899/899 [==============================] - 1s 561us/step - loss: 16.5990 - val_loss: 14.6137\n",
      "Epoch 343/500\n",
      "899/899 [==============================] - 1s 655us/step - loss: 16.4624 - val_loss: 14.6672\n",
      "Epoch 344/500\n",
      "899/899 [==============================] - 1s 576us/step - loss: 16.7238 - val_loss: 14.6513\n",
      "Epoch 345/500\n",
      "899/899 [==============================] - 0s 497us/step - loss: 16.7437 - val_loss: 14.7026\n",
      "Epoch 346/500\n",
      "899/899 [==============================] - 0s 499us/step - loss: 16.5389 - val_loss: 14.7293\n",
      "Epoch 347/500\n",
      "899/899 [==============================] - 0s 484us/step - loss: 16.4070 - val_loss: 14.8153\n",
      "Epoch 348/500\n",
      "899/899 [==============================] - 0s 476us/step - loss: 16.4345 - val_loss: 14.8714\n",
      "Epoch 349/500\n",
      "899/899 [==============================] - 0s 483us/step - loss: 16.2047 - val_loss: 14.7438\n",
      "Epoch 350/500\n",
      "899/899 [==============================] - 0s 486us/step - loss: 16.7836 - val_loss: 14.7313\n",
      "Epoch 351/500\n",
      "899/899 [==============================] - 0s 481us/step - loss: 16.6632 - val_loss: 14.7690\n",
      "Epoch 352/500\n",
      "899/899 [==============================] - 0s 484us/step - loss: 16.7234 - val_loss: 14.5620\n",
      "Epoch 353/500\n",
      "899/899 [==============================] - 0s 485us/step - loss: 16.4960 - val_loss: 14.7043\n",
      "Epoch 354/500\n",
      "899/899 [==============================] - 0s 484us/step - loss: 16.3643 - val_loss: 14.7997\n",
      "Epoch 355/500\n",
      "899/899 [==============================] - 0s 483us/step - loss: 16.4341 - val_loss: 14.7589\n",
      "Epoch 356/500\n",
      "899/899 [==============================] - 0s 490us/step - loss: 16.7204 - val_loss: 14.6619\n",
      "Epoch 357/500\n",
      "899/899 [==============================] - 0s 490us/step - loss: 16.4955 - val_loss: 14.7218\n",
      "Epoch 358/500\n",
      "899/899 [==============================] - 0s 493us/step - loss: 16.5894 - val_loss: 14.6062\n",
      "Epoch 359/500\n",
      "899/899 [==============================] - 0s 509us/step - loss: 16.4075 - val_loss: 14.6177\n",
      "Epoch 360/500\n",
      "899/899 [==============================] - 0s 492us/step - loss: 16.4889 - val_loss: 14.5726\n",
      "Epoch 361/500\n",
      "899/899 [==============================] - 0s 492us/step - loss: 16.5532 - val_loss: 14.6393\n",
      "Epoch 362/500\n",
      "899/899 [==============================] - 0s 484us/step - loss: 16.6604 - val_loss: 14.7866\n",
      "Epoch 363/500\n",
      "899/899 [==============================] - 0s 492us/step - loss: 16.5768 - val_loss: 14.6343\n",
      "Epoch 364/500\n",
      "899/899 [==============================] - 0s 479us/step - loss: 16.3551 - val_loss: 14.6209\n",
      "Epoch 365/500\n",
      "899/899 [==============================] - 0s 499us/step - loss: 16.6123 - val_loss: 14.7306\n",
      "Epoch 366/500\n",
      "899/899 [==============================] - 0s 486us/step - loss: 16.5262 - val_loss: 14.6521\n",
      "Epoch 367/500\n",
      "899/899 [==============================] - 0s 497us/step - loss: 16.4456 - val_loss: 14.6473\n",
      "Epoch 368/500\n",
      "899/899 [==============================] - 0s 494us/step - loss: 16.4669 - val_loss: 14.8347\n",
      "Epoch 369/500\n",
      "899/899 [==============================] - 0s 505us/step - loss: 16.6513 - val_loss: 14.5860\n",
      "Epoch 370/500\n",
      "899/899 [==============================] - 0s 546us/step - loss: 16.3742 - val_loss: 14.6108\n",
      "Epoch 371/500\n",
      "899/899 [==============================] - 0s 516us/step - loss: 16.4636 - val_loss: 14.5863\n",
      "Epoch 372/500\n",
      "899/899 [==============================] - 0s 488us/step - loss: 16.7027 - val_loss: 14.9243\n",
      "Epoch 373/500\n",
      "899/899 [==============================] - 0s 500us/step - loss: 16.8333 - val_loss: 14.6811\n",
      "Epoch 374/500\n",
      "899/899 [==============================] - 0s 508us/step - loss: 16.5773 - val_loss: 14.6684\n",
      "Epoch 375/500\n",
      "899/899 [==============================] - 0s 519us/step - loss: 16.2858 - val_loss: 14.6451\n",
      "Epoch 376/500\n",
      "899/899 [==============================] - 1s 757us/step - loss: 16.5407 - val_loss: 14.8272\n",
      "Epoch 377/500\n",
      "899/899 [==============================] - 1s 622us/step - loss: 16.6354 - val_loss: 14.6632\n",
      "Epoch 378/500\n",
      "899/899 [==============================] - 0s 552us/step - loss: 15.9363 - val_loss: 15.0176\n",
      "Epoch 379/500\n",
      "899/899 [==============================] - 0s 520us/step - loss: 16.3928 - val_loss: 14.7055\n",
      "Epoch 380/500\n",
      "899/899 [==============================] - 0s 536us/step - loss: 16.9199 - val_loss: 14.7085\n",
      "Epoch 381/500\n",
      "899/899 [==============================] - 0s 508us/step - loss: 16.5094 - val_loss: 14.7258\n",
      "Epoch 382/500\n",
      "899/899 [==============================] - 0s 507us/step - loss: 16.3943 - val_loss: 14.7985\n",
      "Epoch 383/500\n",
      "899/899 [==============================] - 0s 520us/step - loss: 16.5313 - val_loss: 14.6765\n",
      "Epoch 384/500\n",
      "899/899 [==============================] - 0s 479us/step - loss: 17.0173 - val_loss: 14.6483\n",
      "Epoch 385/500\n",
      "899/899 [==============================] - 0s 471us/step - loss: 16.6754 - val_loss: 14.8161\n",
      "Epoch 386/500\n",
      "899/899 [==============================] - 0s 468us/step - loss: 16.6518 - val_loss: 14.6964\n",
      "Epoch 387/500\n",
      "899/899 [==============================] - 0s 474us/step - loss: 16.6325 - val_loss: 14.6960\n",
      "Epoch 388/500\n",
      "899/899 [==============================] - 0s 476us/step - loss: 16.3562 - val_loss: 15.0475\n",
      "Epoch 389/500\n",
      "899/899 [==============================] - 0s 475us/step - loss: 16.2797 - val_loss: 14.9736\n",
      "Epoch 390/500\n",
      "899/899 [==============================] - 0s 471us/step - loss: 16.7453 - val_loss: 14.6466\n",
      "Epoch 391/500\n",
      "899/899 [==============================] - 0s 473us/step - loss: 16.3749 - val_loss: 14.7171\n",
      "Epoch 392/500\n",
      "899/899 [==============================] - 0s 469us/step - loss: 16.8075 - val_loss: 14.7425\n",
      "Epoch 393/500\n",
      "899/899 [==============================] - 0s 472us/step - loss: 16.5696 - val_loss: 14.6925\n",
      "Epoch 394/500\n",
      "899/899 [==============================] - 0s 473us/step - loss: 16.4223 - val_loss: 14.8617\n",
      "Epoch 395/500\n",
      "899/899 [==============================] - 0s 475us/step - loss: 16.5984 - val_loss: 14.7808\n",
      "Epoch 396/500\n",
      "899/899 [==============================] - 0s 479us/step - loss: 16.4333 - val_loss: 14.9138\n",
      "Epoch 397/500\n",
      "899/899 [==============================] - 0s 473us/step - loss: 16.1652 - val_loss: 14.6420\n",
      "Epoch 398/500\n",
      "899/899 [==============================] - 0s 475us/step - loss: 16.4888 - val_loss: 14.8901\n",
      "Epoch 399/500\n",
      "899/899 [==============================] - 0s 475us/step - loss: 16.9165 - val_loss: 14.7907\n",
      "Epoch 400/500\n",
      "899/899 [==============================] - 0s 478us/step - loss: 16.4234 - val_loss: 14.5981\n",
      "Epoch 401/500\n",
      "899/899 [==============================] - 0s 483us/step - loss: 16.2445 - val_loss: 14.7229\n",
      "Epoch 402/500\n",
      "899/899 [==============================] - 0s 477us/step - loss: 16.3142 - val_loss: 14.7916\n",
      "Epoch 403/500\n",
      "899/899 [==============================] - 0s 491us/step - loss: 16.4753 - val_loss: 14.6554\n",
      "Epoch 404/500\n",
      "899/899 [==============================] - 0s 476us/step - loss: 16.3677 - val_loss: 14.8645\n",
      "Epoch 405/500\n",
      "899/899 [==============================] - 0s 492us/step - loss: 16.6528 - val_loss: 14.6300\n",
      "Epoch 406/500\n",
      "899/899 [==============================] - 0s 478us/step - loss: 16.8698 - val_loss: 14.5087\n",
      "Epoch 407/500\n",
      "899/899 [==============================] - 0s 478us/step - loss: 16.3972 - val_loss: 14.6610\n",
      "Epoch 408/500\n",
      "899/899 [==============================] - 0s 476us/step - loss: 16.4893 - val_loss: 14.6425\n",
      "Epoch 409/500\n",
      "899/899 [==============================] - 0s 488us/step - loss: 16.3876 - val_loss: 14.7048\n",
      "Epoch 410/500\n",
      "899/899 [==============================] - 0s 482us/step - loss: 16.4540 - val_loss: 14.6343\n",
      "Epoch 411/500\n",
      "899/899 [==============================] - 0s 484us/step - loss: 16.2294 - val_loss: 14.8178\n",
      "Epoch 412/500\n",
      "899/899 [==============================] - 0s 480us/step - loss: 16.2950 - val_loss: 14.8992\n",
      "Epoch 413/500\n",
      "899/899 [==============================] - 0s 483us/step - loss: 16.5613 - val_loss: 14.8795\n",
      "Epoch 414/500\n",
      "899/899 [==============================] - 0s 485us/step - loss: 16.6315 - val_loss: 14.7063\n",
      "Epoch 415/500\n",
      "899/899 [==============================] - 0s 512us/step - loss: 16.5950 - val_loss: 14.6366\n",
      "Epoch 416/500\n",
      "899/899 [==============================] - 0s 504us/step - loss: 16.2257 - val_loss: 14.7846\n",
      "Epoch 417/500\n",
      "899/899 [==============================] - 0s 487us/step - loss: 16.5639 - val_loss: 14.6204\n",
      "Epoch 418/500\n",
      "899/899 [==============================] - 0s 491us/step - loss: 16.6233 - val_loss: 14.7888\n",
      "Epoch 419/500\n",
      "899/899 [==============================] - 0s 487us/step - loss: 16.3646 - val_loss: 14.5226\n",
      "Epoch 420/500\n",
      "899/899 [==============================] - 0s 482us/step - loss: 16.5455 - val_loss: 14.6481\n",
      "Epoch 421/500\n",
      "899/899 [==============================] - 0s 487us/step - loss: 16.5378 - val_loss: 14.6134\n",
      "Epoch 422/500\n",
      "899/899 [==============================] - 0s 471us/step - loss: 16.5046 - val_loss: 14.7223\n",
      "Epoch 423/500\n",
      "899/899 [==============================] - 0s 468us/step - loss: 16.3257 - val_loss: 14.5670\n",
      "Epoch 424/500\n",
      "899/899 [==============================] - 0s 542us/step - loss: 16.4324 - val_loss: 14.8020\n",
      "Epoch 425/500\n",
      "899/899 [==============================] - 0s 545us/step - loss: 16.6397 - val_loss: 14.6700\n",
      "Epoch 426/500\n",
      "899/899 [==============================] - 0s 510us/step - loss: 16.3951 - val_loss: 14.5638\n",
      "Epoch 427/500\n",
      "899/899 [==============================] - 1s 558us/step - loss: 16.5208 - val_loss: 14.8004\n",
      "Epoch 428/500\n",
      "899/899 [==============================] - 0s 484us/step - loss: 16.5371 - val_loss: 14.5104\n",
      "Epoch 429/500\n",
      "899/899 [==============================] - 0s 482us/step - loss: 16.1949 - val_loss: 14.6975\n",
      "Epoch 430/500\n",
      "899/899 [==============================] - 0s 485us/step - loss: 16.1260 - val_loss: 14.5836\n",
      "Epoch 431/500\n",
      "899/899 [==============================] - 0s 480us/step - loss: 16.2114 - val_loss: 14.6806\n",
      "Epoch 432/500\n",
      "899/899 [==============================] - 0s 488us/step - loss: 16.2509 - val_loss: 14.5363\n",
      "Epoch 433/500\n",
      "899/899 [==============================] - 0s 485us/step - loss: 16.3820 - val_loss: 14.6701\n",
      "Epoch 434/500\n",
      "899/899 [==============================] - 0s 483us/step - loss: 16.8542 - val_loss: 14.6304\n",
      "Epoch 435/500\n",
      "899/899 [==============================] - 0s 490us/step - loss: 16.5481 - val_loss: 14.6656\n",
      "Epoch 436/500\n",
      "899/899 [==============================] - 0s 508us/step - loss: 16.2760 - val_loss: 14.5963\n",
      "Epoch 437/500\n",
      "899/899 [==============================] - 0s 505us/step - loss: 17.1098 - val_loss: 14.5315\n",
      "Epoch 438/500\n",
      "899/899 [==============================] - 0s 505us/step - loss: 16.2439 - val_loss: 14.7703\n",
      "Epoch 439/500\n",
      "899/899 [==============================] - 0s 490us/step - loss: 16.7395 - val_loss: 14.6088\n",
      "Epoch 440/500\n",
      "899/899 [==============================] - 0s 514us/step - loss: 16.3438 - val_loss: 14.6359\n",
      "Epoch 441/500\n",
      "899/899 [==============================] - 0s 520us/step - loss: 16.3712 - val_loss: 14.6804\n",
      "Epoch 442/500\n",
      "899/899 [==============================] - 0s 519us/step - loss: 16.1555 - val_loss: 14.5405\n",
      "Epoch 443/500\n",
      "899/899 [==============================] - 0s 522us/step - loss: 16.6434 - val_loss: 14.6973\n",
      "Epoch 444/500\n",
      "899/899 [==============================] - 0s 496us/step - loss: 16.4500 - val_loss: 14.6493\n",
      "Epoch 445/500\n",
      "899/899 [==============================] - 0s 512us/step - loss: 16.2075 - val_loss: 14.7261\n",
      "Epoch 446/500\n",
      "899/899 [==============================] - 0s 552us/step - loss: 16.7993 - val_loss: 14.6688\n",
      "Epoch 447/500\n",
      "899/899 [==============================] - 0s 532us/step - loss: 16.4676 - val_loss: 14.8210\n",
      "Epoch 448/500\n",
      "899/899 [==============================] - 1s 663us/step - loss: 16.5756 - val_loss: 14.5512\n",
      "Epoch 449/500\n",
      "899/899 [==============================] - 1s 557us/step - loss: 16.1858 - val_loss: 14.6073\n",
      "Epoch 450/500\n",
      "899/899 [==============================] - 0s 511us/step - loss: 16.7096 - val_loss: 14.5827\n",
      "Epoch 451/500\n",
      "899/899 [==============================] - 0s 497us/step - loss: 16.9387 - val_loss: 14.5953\n",
      "Epoch 452/500\n",
      "899/899 [==============================] - 0s 493us/step - loss: 16.6044 - val_loss: 14.7293\n",
      "Epoch 453/500\n",
      "899/899 [==============================] - 0s 497us/step - loss: 16.7810 - val_loss: 14.6011\n",
      "Epoch 454/500\n",
      "899/899 [==============================] - 0s 494us/step - loss: 16.3561 - val_loss: 14.5997\n",
      "Epoch 455/500\n",
      "899/899 [==============================] - 0s 501us/step - loss: 16.5712 - val_loss: 14.5289\n",
      "Epoch 456/500\n",
      "899/899 [==============================] - 0s 503us/step - loss: 16.3232 - val_loss: 14.6497\n",
      "Epoch 457/500\n",
      "899/899 [==============================] - 0s 496us/step - loss: 16.2792 - val_loss: 14.4877\n",
      "Epoch 458/500\n",
      "899/899 [==============================] - 0s 498us/step - loss: 16.5772 - val_loss: 14.5379\n",
      "Epoch 459/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899/899 [==============================] - 0s 486us/step - loss: 16.3883 - val_loss: 14.5373\n",
      "Epoch 460/500\n",
      "899/899 [==============================] - 0s 466us/step - loss: 16.4871 - val_loss: 14.4469\n",
      "Epoch 461/500\n",
      "899/899 [==============================] - 0s 479us/step - loss: 16.5779 - val_loss: 14.5610\n",
      "Epoch 462/500\n",
      "899/899 [==============================] - 0s 467us/step - loss: 16.5000 - val_loss: 14.6015\n",
      "Epoch 463/500\n",
      "899/899 [==============================] - 0s 472us/step - loss: 16.1020 - val_loss: 14.7980\n",
      "Epoch 464/500\n",
      "899/899 [==============================] - 0s 464us/step - loss: 16.3474 - val_loss: 14.7338\n",
      "Epoch 465/500\n",
      "899/899 [==============================] - 0s 468us/step - loss: 16.6673 - val_loss: 14.6236\n",
      "Epoch 466/500\n",
      "899/899 [==============================] - 0s 466us/step - loss: 16.5602 - val_loss: 14.9717\n",
      "Epoch 467/500\n",
      "899/899 [==============================] - 0s 468us/step - loss: 16.5172 - val_loss: 14.5289\n",
      "Epoch 468/500\n",
      "899/899 [==============================] - 0s 471us/step - loss: 16.3915 - val_loss: 14.7303\n",
      "Epoch 469/500\n",
      "899/899 [==============================] - 0s 472us/step - loss: 16.2362 - val_loss: 14.4472\n",
      "Epoch 470/500\n",
      "899/899 [==============================] - 0s 476us/step - loss: 16.7105 - val_loss: 14.6390\n",
      "Epoch 471/500\n",
      "899/899 [==============================] - 0s 465us/step - loss: 16.8544 - val_loss: 14.4782\n",
      "Epoch 472/500\n",
      "899/899 [==============================] - 0s 468us/step - loss: 16.5905 - val_loss: 14.5642\n",
      "Epoch 473/500\n",
      "899/899 [==============================] - 0s 490us/step - loss: 16.2918 - val_loss: 14.6034\n",
      "Epoch 474/500\n",
      "899/899 [==============================] - 0s 510us/step - loss: 15.8812 - val_loss: 14.6878\n",
      "Epoch 475/500\n",
      "899/899 [==============================] - 0s 485us/step - loss: 15.9870 - val_loss: 14.7222\n",
      "Epoch 476/500\n",
      "899/899 [==============================] - 0s 472us/step - loss: 16.3007 - val_loss: 14.6060\n",
      "Epoch 477/500\n",
      "899/899 [==============================] - 0s 544us/step - loss: 16.2416 - val_loss: 14.5842\n",
      "Epoch 478/500\n",
      "899/899 [==============================] - 0s 510us/step - loss: 16.5564 - val_loss: 14.5940\n",
      "Epoch 479/500\n",
      "899/899 [==============================] - 0s 481us/step - loss: 16.0598 - val_loss: 14.6162\n",
      "Epoch 480/500\n",
      "899/899 [==============================] - 0s 480us/step - loss: 16.4306 - val_loss: 14.5717\n",
      "Epoch 481/500\n",
      "899/899 [==============================] - 0s 477us/step - loss: 16.7001 - val_loss: 14.6657\n",
      "Epoch 482/500\n",
      "899/899 [==============================] - 0s 483us/step - loss: 16.4883 - val_loss: 14.6133\n",
      "Epoch 483/500\n",
      "899/899 [==============================] - 0s 479us/step - loss: 16.4832 - val_loss: 14.5170\n",
      "Epoch 484/500\n",
      "899/899 [==============================] - 0s 476us/step - loss: 16.3186 - val_loss: 14.5912\n",
      "Epoch 485/500\n",
      "899/899 [==============================] - 0s 470us/step - loss: 16.2998 - val_loss: 14.6504\n",
      "Epoch 486/500\n",
      "899/899 [==============================] - 0s 476us/step - loss: 16.4538 - val_loss: 14.5738\n",
      "Epoch 487/500\n",
      "899/899 [==============================] - 0s 474us/step - loss: 16.3434 - val_loss: 14.5609\n",
      "Epoch 488/500\n",
      "899/899 [==============================] - 0s 484us/step - loss: 15.8175 - val_loss: 14.6816\n",
      "Epoch 489/500\n",
      "899/899 [==============================] - 0s 484us/step - loss: 16.4597 - val_loss: 14.5393\n",
      "Epoch 490/500\n",
      "899/899 [==============================] - 0s 475us/step - loss: 16.3151 - val_loss: 14.6922\n",
      "Epoch 491/500\n",
      "899/899 [==============================] - 0s 477us/step - loss: 16.6230 - val_loss: 14.5385\n",
      "Epoch 492/500\n",
      "899/899 [==============================] - 0s 491us/step - loss: 15.9274 - val_loss: 14.6111\n",
      "Epoch 493/500\n",
      "899/899 [==============================] - 0s 505us/step - loss: 16.1415 - val_loss: 14.5223\n",
      "Epoch 494/500\n",
      "899/899 [==============================] - 0s 540us/step - loss: 16.4321 - val_loss: 14.5925\n",
      "Epoch 495/500\n",
      "899/899 [==============================] - 1s 680us/step - loss: 16.3545 - val_loss: 14.5623\n",
      "Epoch 496/500\n",
      "899/899 [==============================] - 0s 520us/step - loss: 16.2090 - val_loss: 14.6026\n",
      "Epoch 497/500\n",
      "899/899 [==============================] - 0s 499us/step - loss: 16.5043 - val_loss: 14.6904\n",
      "Epoch 498/500\n",
      "899/899 [==============================] - 0s 490us/step - loss: 16.6358 - val_loss: 14.5600\n",
      "Epoch 499/500\n",
      "899/899 [==============================] - 0s 490us/step - loss: 16.3920 - val_loss: 14.7341\n",
      "Epoch 500/500\n",
      "899/899 [==============================] - 0s 489us/step - loss: 16.3932 - val_loss: 14.7560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2a801898>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network2 = Sequential()\n",
    "\n",
    "network2.add(Dense(976, activation=\"relu\", input_dim=X2s_train.shape[1], kernel_regularizer=regularizers.l1(.01)))\n",
    "network2.add(Dropout(.5))\n",
    "network2.add(Dense(976, activation=\"relu\", kernel_regularizer=regularizers.l1(.01)))\n",
    "network2.add(Dropout(.5))\n",
    "network2.add(Dense(31, activation=\"relu\", kernel_regularizer=regularizers.l1(.01)))\n",
    "network2.add(Dropout(.5))\n",
    "network2.add(Dense(1, activation=None, kernel_regularizer=regularizers.l1(.01)))\n",
    "\n",
    "network2.compile(loss=\"mean_absolute_error\", optimizer=\"adam\")\n",
    "\n",
    "network2.fit(X2s_train, y2_train, validation_data=(X2s_test, y2_test), epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = \"./data/dengue_features_test.csv\"\n",
    "test = pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(\"week_start_date\", axis=1, inplace=True)\n",
    "test.dropna(inplace=True)\n",
    "test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_test = pf.transform(test[weather_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.86000000e+01, 2.98492857e+02, 2.98550000e+02, ...,\n",
       "        4.70890000e+02, 1.63184000e+03, 5.65504000e+03],\n",
       "       [1.25600000e+01, 2.98475714e+02, 2.98557143e+02, ...,\n",
       "        4.92840000e+02, 7.61460000e+02, 1.17649000e+03],\n",
       "       [7.60000000e-01, 2.99780000e+02, 2.99671429e+02, ...,\n",
       "        5.42890000e+02, 1.95953000e+03, 7.07281000e+03],\n",
       "       ...,\n",
       "       [7.89600000e+01, 2.95831429e+02, 2.96607143e+02, ...,\n",
       "        4.66560000e+02, 2.01312000e+03, 8.68624000e+03],\n",
       "       [3.95400000e+01, 2.95778571e+02, 2.97400000e+02, ...,\n",
       "        4.75240000e+02, 7.43380000e+02, 1.16281000e+03],\n",
       "       [5.18000000e+01, 2.97372857e+02, 2.99000000e+02, ...,\n",
       "        4.84000000e+02, 3.27800000e+02, 2.22010000e+02]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weather = pd.DataFrame(data=pf_test, columns=pf.get_feature_names(weather_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>reanalysis_avg_temp_k</th>\n",
       "      <th>reanalysis_dew_point_temp_k</th>\n",
       "      <th>reanalysis_max_air_temp_k</th>\n",
       "      <th>reanalysis_min_air_temp_k</th>\n",
       "      <th>reanalysis_precip_amt_kg_per_m2</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_sat_precip_amt_mm</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "      <th>city_iq</th>\n",
       "      <th>city_sj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.0189</td>\n",
       "      <td>-0.018900</td>\n",
       "      <td>0.102729</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>78.60</td>\n",
       "      <td>298.492857</td>\n",
       "      <td>298.550000</td>\n",
       "      <td>294.527143</td>\n",
       "      <td>301.1</td>\n",
       "      <td>296.4</td>\n",
       "      <td>25.37</td>\n",
       "      <td>78.781429</td>\n",
       "      <td>78.60</td>\n",
       "      <td>15.918571</td>\n",
       "      <td>3.128571</td>\n",
       "      <td>26.528571</td>\n",
       "      <td>7.057143</td>\n",
       "      <td>33.3</td>\n",
       "      <td>21.7</td>\n",
       "      <td>75.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.0180</td>\n",
       "      <td>-0.012400</td>\n",
       "      <td>0.082043</td>\n",
       "      <td>0.072314</td>\n",
       "      <td>12.56</td>\n",
       "      <td>298.475714</td>\n",
       "      <td>298.557143</td>\n",
       "      <td>294.395714</td>\n",
       "      <td>300.8</td>\n",
       "      <td>296.7</td>\n",
       "      <td>21.83</td>\n",
       "      <td>78.230000</td>\n",
       "      <td>12.56</td>\n",
       "      <td>15.791429</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>26.071429</td>\n",
       "      <td>5.557143</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>34.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>0.039833</td>\n",
       "      <td>0.062267</td>\n",
       "      <td>0.075914</td>\n",
       "      <td>0.76</td>\n",
       "      <td>299.780000</td>\n",
       "      <td>299.671429</td>\n",
       "      <td>294.760000</td>\n",
       "      <td>302.3</td>\n",
       "      <td>297.3</td>\n",
       "      <td>4.36</td>\n",
       "      <td>74.084286</td>\n",
       "      <td>0.76</td>\n",
       "      <td>16.137143</td>\n",
       "      <td>3.542857</td>\n",
       "      <td>27.614286</td>\n",
       "      <td>7.085714</td>\n",
       "      <td>33.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>84.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.0440</td>\n",
       "      <td>-0.030467</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.083529</td>\n",
       "      <td>71.17</td>\n",
       "      <td>299.768571</td>\n",
       "      <td>299.728571</td>\n",
       "      <td>295.314286</td>\n",
       "      <td>301.9</td>\n",
       "      <td>297.6</td>\n",
       "      <td>22.55</td>\n",
       "      <td>76.557143</td>\n",
       "      <td>71.17</td>\n",
       "      <td>16.667143</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>5.171429</td>\n",
       "      <td>32.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2008</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.0443</td>\n",
       "      <td>-0.024925</td>\n",
       "      <td>0.132271</td>\n",
       "      <td>0.159157</td>\n",
       "      <td>48.99</td>\n",
       "      <td>300.062857</td>\n",
       "      <td>300.007143</td>\n",
       "      <td>295.650000</td>\n",
       "      <td>302.4</td>\n",
       "      <td>297.5</td>\n",
       "      <td>13.10</td>\n",
       "      <td>76.844286</td>\n",
       "      <td>48.99</td>\n",
       "      <td>17.010000</td>\n",
       "      <td>3.157143</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>6.042857</td>\n",
       "      <td>31.1</td>\n",
       "      <td>23.3</td>\n",
       "      <td>91.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  weekofyear  ndvi_ne   ndvi_nw   ndvi_se   ndvi_sw  \\\n",
       "0  2008          18  -0.0189 -0.018900  0.102729  0.091200   \n",
       "1  2008          19  -0.0180 -0.012400  0.082043  0.072314   \n",
       "4  2008          22   0.0568  0.039833  0.062267  0.075914   \n",
       "5  2008          23  -0.0440 -0.030467  0.132000  0.083529   \n",
       "6  2008          24  -0.0443 -0.024925  0.132271  0.159157   \n",
       "\n",
       "   precipitation_amt_mm  reanalysis_air_temp_k  reanalysis_avg_temp_k  \\\n",
       "0                 78.60             298.492857             298.550000   \n",
       "1                 12.56             298.475714             298.557143   \n",
       "4                  0.76             299.780000             299.671429   \n",
       "5                 71.17             299.768571             299.728571   \n",
       "6                 48.99             300.062857             300.007143   \n",
       "\n",
       "   reanalysis_dew_point_temp_k  reanalysis_max_air_temp_k  \\\n",
       "0                   294.527143                      301.1   \n",
       "1                   294.395714                      300.8   \n",
       "4                   294.760000                      302.3   \n",
       "5                   295.314286                      301.9   \n",
       "6                   295.650000                      302.4   \n",
       "\n",
       "   reanalysis_min_air_temp_k  reanalysis_precip_amt_kg_per_m2  \\\n",
       "0                      296.4                            25.37   \n",
       "1                      296.7                            21.83   \n",
       "4                      297.3                             4.36   \n",
       "5                      297.6                            22.55   \n",
       "6                      297.5                            13.10   \n",
       "\n",
       "   reanalysis_relative_humidity_percent  reanalysis_sat_precip_amt_mm  \\\n",
       "0                             78.781429                         78.60   \n",
       "1                             78.230000                         12.56   \n",
       "4                             74.084286                          0.76   \n",
       "5                             76.557143                         71.17   \n",
       "6                             76.844286                         48.99   \n",
       "\n",
       "   reanalysis_specific_humidity_g_per_kg  reanalysis_tdtr_k  \\\n",
       "0                              15.918571           3.128571   \n",
       "1                              15.791429           2.571429   \n",
       "4                              16.137143           3.542857   \n",
       "5                              16.667143           2.857143   \n",
       "6                              17.010000           3.157143   \n",
       "\n",
       "   station_avg_temp_c  station_diur_temp_rng_c  station_max_temp_c  \\\n",
       "0           26.528571                 7.057143                33.3   \n",
       "1           26.071429                 5.557143                30.0   \n",
       "4           27.614286                 7.085714                33.3   \n",
       "5           28.000000                 5.171429                32.8   \n",
       "6           27.400000                 6.042857                31.1   \n",
       "\n",
       "   station_min_temp_c  station_precip_mm  city_iq  city_sj  \n",
       "0                21.7               75.2        0        1  \n",
       "1                22.2               34.3        0        1  \n",
       "4                23.3               84.1        0        1  \n",
       "5                25.0               27.7        0        1  \n",
       "6                23.3               91.7        0        1  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(labels=weather_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353, 8)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353, 152)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.reset_index(drop=True, inplace=True)\n",
    "test_weather.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test['id'] = test.index\n",
    "test_weather['id'] = test_weather.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353, 153)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353, 9)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ex = test.merge(test_weather, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ex.drop(\"id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353, 160)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ex = ss2.transform(test_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.20659642, -0.54858183, -1.18023178, ..., -0.23140573,\n",
       "         0.8027309 ,  0.26303983],\n",
       "       [ 1.20659642, -0.48288341, -1.17392203, ...,  0.11581201,\n",
       "        -0.10552695, -0.26871775],\n",
       "       [ 1.20659642, -0.28578814, -0.64951201, ...,  0.90753174,\n",
       "         1.14468156,  0.43137779],\n",
       "       ...,\n",
       "       [ 2.10302765, -0.15439129,  0.62595831, ..., -0.29990017,\n",
       "         1.20060373,  0.6229473 ],\n",
       "       [ 2.10302765, -0.08869287,  1.12863475, ..., -0.16259492,\n",
       "        -0.12439377, -0.27034204],\n",
       "       [ 2.10302765, -0.02299445,  1.33221591, ..., -0.0240242 ,\n",
       "        -0.55805929, -0.38204729]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2_preds = network2.predict(test_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(network2_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'city'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'city'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-af2f298f53ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork2_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"city\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'city'"
     ]
    }
   ],
   "source": [
    "network2_df = pd.DataFrame(test[\"city\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2_df[\"year\"] = pd.DataFrame(test[\"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2_df[\"weekofyear\"] = pd.DataFrame(test[\"weekofyear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-ddc02b9da752>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork2_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"total_cases\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork2_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3117\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3390\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3391\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3393\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m   3999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4000\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4001\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of '\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4003\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "network2_df[\"total_cases\"] = network2_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im going to pipeline this because it's making me want to explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = \"./data/dengue_features_test.csv\"\n",
    "test = pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 416 entries, 0 to 415\n",
      "Data columns (total 24 columns):\n",
      "city                                     416 non-null object\n",
      "year                                     416 non-null int64\n",
      "weekofyear                               416 non-null int64\n",
      "week_start_date                          416 non-null object\n",
      "ndvi_ne                                  373 non-null float64\n",
      "ndvi_nw                                  405 non-null float64\n",
      "ndvi_se                                  415 non-null float64\n",
      "ndvi_sw                                  415 non-null float64\n",
      "precipitation_amt_mm                     414 non-null float64\n",
      "reanalysis_air_temp_k                    414 non-null float64\n",
      "reanalysis_avg_temp_k                    414 non-null float64\n",
      "reanalysis_dew_point_temp_k              414 non-null float64\n",
      "reanalysis_max_air_temp_k                414 non-null float64\n",
      "reanalysis_min_air_temp_k                414 non-null float64\n",
      "reanalysis_precip_amt_kg_per_m2          414 non-null float64\n",
      "reanalysis_relative_humidity_percent     414 non-null float64\n",
      "reanalysis_sat_precip_amt_mm             414 non-null float64\n",
      "reanalysis_specific_humidity_g_per_kg    414 non-null float64\n",
      "reanalysis_tdtr_k                        414 non-null float64\n",
      "station_avg_temp_c                       404 non-null float64\n",
      "station_diur_temp_rng_c                  404 non-null float64\n",
      "station_max_temp_c                       413 non-null float64\n",
      "station_min_temp_c                       407 non-null float64\n",
      "station_precip_mm                        411 non-null float64\n",
      "dtypes: float64(20), int64(2), object(2)\n",
      "memory usage: 78.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_maker(test_set, model, csv_name, polyfunc=None, scalerfunc=None):\n",
    "    # preliminary preparation of test set\n",
    "    test_set.dropna(inplace=True)\n",
    "    test_set.drop(\"week_start_date\", axis=1, inplace=True)\n",
    "    \n",
    "    # this is to pull from for later in the prediction dataframe\n",
    "    city_df = test_set[\"city\"]\n",
    "    year_df = test_set[\"year\"]\n",
    "    weekofyear_df = test_set[\"weekofyear\"]\n",
    "    \n",
    "    #dummying cities\n",
    "    test_set = pd.get_dummies(test_set)\n",
    "    \n",
    "    # prepping weather features\n",
    "    non_weather = \"year weekofyear ndvi_ne ndvi_nw ndvi_se ndvi_sw total_cases city_iq city_sj\".split()\n",
    "    weather_features = [x for x in test_set.columns if x not in non_weather]\n",
    "    \n",
    "    # if there is a polynomial features function\n",
    "    if polyfunc is not None:\n",
    "        # calling the func and making a dataframe\n",
    "        pf_test = polyfunc.transform(test_set[weather_features])\n",
    "        test_weather = pd.DataFrame(data=pf_test, columns=pf.get_feature_names(weather_features))\n",
    "        \n",
    "        test_set.drop(labels=weather_features, axis=1, inplace=True)\n",
    "        \n",
    "        # fixing the indices\n",
    "        test_set.reset_index(drop=True, inplace=True)\n",
    "        test_weather.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        test_set['id'] = test_set.index\n",
    "        test_weather['id'] = test_weather.index\n",
    "        \n",
    "        #merging dataframes\n",
    "        test_set = test_set.merge(test_weather, how='left', on='id')\n",
    "        test_set.drop(\"id\", axis=1, inplace=True)\n",
    "        \n",
    "    # if there is a scaler function\n",
    "    if scalerfunc is not None:\n",
    "        test_set = scalerfunc.transform(test_set)\n",
    "    \n",
    "    # making predictions\n",
    "    pred_array = model.predict(test_set)\n",
    "    \n",
    "    #setting up prediction dataframe\n",
    "    pred_df = pd.DataFrame()\n",
    "    pred_df[\"city\"] = city_df\n",
    "    pred_df[\"year\"] = year_df\n",
    "    pred_df[\"weekofyear\"] = weekofyear_df\n",
    "    pred_df[\"total_cases\"] = pred_array\n",
    "    \n",
    "    pred_df.to_csv(\"./submissions/\"+csv_name, index=False)\n",
    "    \n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_test = pred_maker(test, network2, \"weather_poly_nn\", pf, ss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>18</td>\n",
       "      <td>4.894512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>19</td>\n",
       "      <td>5.421768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>22</td>\n",
       "      <td>5.312186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>23</td>\n",
       "      <td>8.374026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>24</td>\n",
       "      <td>8.558281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>26</td>\n",
       "      <td>12.078225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>27</td>\n",
       "      <td>16.812138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>28</td>\n",
       "      <td>12.495796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>30</td>\n",
       "      <td>18.654673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>31</td>\n",
       "      <td>19.560387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>32</td>\n",
       "      <td>18.822950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>34</td>\n",
       "      <td>20.314224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>37</td>\n",
       "      <td>23.227476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>38</td>\n",
       "      <td>25.469440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>39</td>\n",
       "      <td>16.274172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>40</td>\n",
       "      <td>20.355625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>41</td>\n",
       "      <td>26.217596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>42</td>\n",
       "      <td>19.163588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>43</td>\n",
       "      <td>19.445601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>44</td>\n",
       "      <td>25.458702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>45</td>\n",
       "      <td>27.724447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>46</td>\n",
       "      <td>25.044987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>48</td>\n",
       "      <td>21.949036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>49</td>\n",
       "      <td>19.491180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>50</td>\n",
       "      <td>18.505005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>51</td>\n",
       "      <td>16.476509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>52</td>\n",
       "      <td>13.125508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>sj</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>6.087416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sj</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>5.179739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>sj</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>4.920085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>iq</td>\n",
       "      <td>2012</td>\n",
       "      <td>48</td>\n",
       "      <td>7.957047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>iq</td>\n",
       "      <td>2012</td>\n",
       "      <td>49</td>\n",
       "      <td>6.833158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>iq</td>\n",
       "      <td>2012</td>\n",
       "      <td>50</td>\n",
       "      <td>6.313826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>iq</td>\n",
       "      <td>2012</td>\n",
       "      <td>51</td>\n",
       "      <td>7.244306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>7.520406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>4.886528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>4.986525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>8.334662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>6.708908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>9.482939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>8.739619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>8.529925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>5.737147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>6.748386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>7.623878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>9.647140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>13</td>\n",
       "      <td>9.518655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>14</td>\n",
       "      <td>7.636234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>15</td>\n",
       "      <td>6.847644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>16</td>\n",
       "      <td>7.864273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>17</td>\n",
       "      <td>6.569549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>18</td>\n",
       "      <td>4.883949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>19</td>\n",
       "      <td>7.538529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>20</td>\n",
       "      <td>5.202606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>21</td>\n",
       "      <td>5.052454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>22</td>\n",
       "      <td>4.967712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>23</td>\n",
       "      <td>4.892053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>24</td>\n",
       "      <td>4.882641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>25</td>\n",
       "      <td>4.885653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>iq</td>\n",
       "      <td>2013</td>\n",
       "      <td>26</td>\n",
       "      <td>4.883684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    city  year  weekofyear  total_cases\n",
       "0     sj  2008          18     4.894512\n",
       "1     sj  2008          19     5.421768\n",
       "4     sj  2008          22     5.312186\n",
       "5     sj  2008          23     8.374026\n",
       "6     sj  2008          24     8.558281\n",
       "8     sj  2008          26    12.078225\n",
       "9     sj  2008          27    16.812138\n",
       "10    sj  2008          28    12.495796\n",
       "12    sj  2008          30    18.654673\n",
       "13    sj  2008          31    19.560387\n",
       "14    sj  2008          32    18.822950\n",
       "16    sj  2008          34    20.314224\n",
       "19    sj  2008          37    23.227476\n",
       "20    sj  2008          38    25.469440\n",
       "21    sj  2008          39    16.274172\n",
       "22    sj  2008          40    20.355625\n",
       "23    sj  2008          41    26.217596\n",
       "24    sj  2008          42    19.163588\n",
       "25    sj  2008          43    19.445601\n",
       "26    sj  2008          44    25.458702\n",
       "27    sj  2008          45    27.724447\n",
       "28    sj  2008          46    25.044987\n",
       "30    sj  2008          48    21.949036\n",
       "31    sj  2008          49    19.491180\n",
       "32    sj  2008          50    18.505005\n",
       "33    sj  2008          51    16.476509\n",
       "34    sj  2008          52    13.125508\n",
       "36    sj  2009           2     6.087416\n",
       "37    sj  2009           3     5.179739\n",
       "38    sj  2009           4     4.920085\n",
       "..   ...   ...         ...          ...\n",
       "386   iq  2012          48     7.957047\n",
       "387   iq  2012          49     6.833158\n",
       "388   iq  2012          50     6.313826\n",
       "389   iq  2012          51     7.244306\n",
       "390   iq  2013           1     7.520406\n",
       "391   iq  2013           2     4.886528\n",
       "392   iq  2013           3     4.986525\n",
       "393   iq  2013           4     8.334662\n",
       "394   iq  2013           5     6.708908\n",
       "395   iq  2013           6     9.482939\n",
       "396   iq  2013           7     8.739619\n",
       "397   iq  2013           8     8.529925\n",
       "398   iq  2013           9     5.737147\n",
       "399   iq  2013          10     6.748386\n",
       "400   iq  2013          11     7.623878\n",
       "401   iq  2013          12     9.647140\n",
       "402   iq  2013          13     9.518655\n",
       "403   iq  2013          14     7.636234\n",
       "404   iq  2013          15     6.847644\n",
       "405   iq  2013          16     7.864273\n",
       "406   iq  2013          17     6.569549\n",
       "407   iq  2013          18     4.883949\n",
       "408   iq  2013          19     7.538529\n",
       "409   iq  2013          20     5.202606\n",
       "410   iq  2013          21     5.052454\n",
       "411   iq  2013          22     4.967712\n",
       "412   iq  2013          23     4.892053\n",
       "413   iq  2013          24     4.882641\n",
       "414   iq  2013          25     4.885653\n",
       "415   iq  2013          26     4.883684\n",
       "\n",
       "[353 rows x 4 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
