{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianconnor/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_maker(test_set, model, csv_name, polyfunc=None, scalerfunc=None, city=None):\n",
    "    \n",
    "    if city is not None:\n",
    "        if city == \"sj\":\n",
    "            test_set = test_set[test_set[\"city\"]==\"sj\"].copy()\n",
    "#             test_set.drop(\"city\", axis=1, inplace=True)\n",
    "        if city == \"iq\":\n",
    "            test_set = test_set[test_set[\"city\"]==\"iq\"].copy()\n",
    "#             test_set.drop(\"city\", axis=1, inplace=True)\n",
    "\n",
    "    # preliminary preparation of test set\n",
    "    test_set.drop(\"week_start_date\", axis=1, inplace=True)\n",
    "    test_set.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "    \n",
    "    # this is to pull from for later in the prediction dataframe\n",
    "#     if city is None:\n",
    "    city_df = test_set[\"city\"].copy()\n",
    "    year_df = test_set[\"year\"].copy()\n",
    "    weekofyear_df = test_set[\"weekofyear\"].copy()\n",
    "    \n",
    "    #dummying cities\n",
    "    test_set = pd.get_dummies(test_set)\n",
    "    \n",
    "    # prepping weather features\n",
    "    test_non_weather = \"year weekofyear ndvi_ne ndvi_nw ndvi_se ndvi_sw city_iq city_sj\".split()\n",
    "    test_weather_features = [x for x in test_set.columns if x not in test_non_weather]\n",
    "    \n",
    "    # if there is a polynomial features function\n",
    "    if polyfunc is not None:\n",
    "        # calling the func and making a dataframe\n",
    "        pf_test = polyfunc.transform(test_set[test_weather_features])\n",
    "        test_weather = pd.DataFrame(data=pf_test, columns=polyfunc.get_feature_names(test_weather_features))\n",
    "        \n",
    "        test_set.drop(labels=weather_features, axis=1, inplace=True)\n",
    "        \n",
    "        # fixing the indices\n",
    "        test_set.reset_index(drop=True, inplace=True)\n",
    "        test_weather.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        test_set['id'] = test_set.index\n",
    "        test_weather['id'] = test_weather.index\n",
    "        \n",
    "        #merging dataframes\n",
    "        test_set = test_set.merge(test_weather, how='left', on='id')\n",
    "        test_set.drop(\"id\", axis=1, inplace=True)\n",
    "        \n",
    "    # if there is a scaler function\n",
    "    if scalerfunc is not None:\n",
    "        test_set = scalerfunc.transform(test_set)\n",
    "    \n",
    "    # making predictions\n",
    "    pred_array = model.predict(test_set)\n",
    "    \n",
    "    #setting up prediction dataframe\n",
    "    pred_df = pd.DataFrame()\n",
    "#     if city is None:\n",
    "    pred_df[\"city\"] = city_df\n",
    "    pred_df[\"year\"] = year_df\n",
    "    pred_df[\"weekofyear\"] = weekofyear_df\n",
    "    pred_df[\"total_cases\"] = pred_array\n",
    "    \n",
    "    pred_df = pred_df.round({\"total_cases\":0})\n",
    "    \n",
    "#     pred_df.to_csv(\"./submissions/\"+csv_name, index=False)\n",
    "\n",
    "    if city is None:\n",
    "        #taking their sample submission...\n",
    "        sample_csv = \"./data/submission_format.csv\"\n",
    "        sample = pd.read_csv(sample_csv)\n",
    "    \n",
    "        #... and making it my own\n",
    "        sample.total_cases = pred_array\n",
    "        pred_df = sample.copy()\n",
    "        pred_df[\"total_cases\"] = pred_df[\"total_cases\"].astype(\"int64\")\n",
    "    \n",
    "        pred_df.to_csv(\"./submissions/\"+csv_name, index=False)\n",
    "    \n",
    "        return pred_df\n",
    "    \n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = \"./data/cleaned_train.csv\"\n",
    "train = pd.read_csv(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop([\"Unnamed: 0\", \"week_start_date\"], axis=1, inplace=True)\n",
    "train = pd.get_dummies(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>reanalysis_avg_temp_k</th>\n",
       "      <th>reanalysis_dew_point_temp_k</th>\n",
       "      <th>...</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>city_iq</th>\n",
       "      <th>city_sj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>18</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.103725</td>\n",
       "      <td>0.198483</td>\n",
       "      <td>0.177617</td>\n",
       "      <td>12.42</td>\n",
       "      <td>297.572857</td>\n",
       "      <td>297.742857</td>\n",
       "      <td>292.414286</td>\n",
       "      <td>...</td>\n",
       "      <td>14.012857</td>\n",
       "      <td>2.628571</td>\n",
       "      <td>25.442857</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>29.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>19</td>\n",
       "      <td>0.169900</td>\n",
       "      <td>0.142175</td>\n",
       "      <td>0.162357</td>\n",
       "      <td>0.155486</td>\n",
       "      <td>22.82</td>\n",
       "      <td>298.211429</td>\n",
       "      <td>298.442857</td>\n",
       "      <td>293.951429</td>\n",
       "      <td>...</td>\n",
       "      <td>15.372857</td>\n",
       "      <td>2.371429</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.371429</td>\n",
       "      <td>31.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>20</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>0.172967</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.170843</td>\n",
       "      <td>34.54</td>\n",
       "      <td>298.781429</td>\n",
       "      <td>298.878571</td>\n",
       "      <td>295.434286</td>\n",
       "      <td>...</td>\n",
       "      <td>16.848571</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.485714</td>\n",
       "      <td>32.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>41.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>21</td>\n",
       "      <td>0.128633</td>\n",
       "      <td>0.245067</td>\n",
       "      <td>0.227557</td>\n",
       "      <td>0.235886</td>\n",
       "      <td>15.36</td>\n",
       "      <td>298.987143</td>\n",
       "      <td>299.228571</td>\n",
       "      <td>295.310000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.672857</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>27.471429</td>\n",
       "      <td>6.771429</td>\n",
       "      <td>33.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>22</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.262200</td>\n",
       "      <td>0.251200</td>\n",
       "      <td>0.247340</td>\n",
       "      <td>7.52</td>\n",
       "      <td>299.518571</td>\n",
       "      <td>299.664286</td>\n",
       "      <td>295.821429</td>\n",
       "      <td>...</td>\n",
       "      <td>17.210000</td>\n",
       "      <td>3.014286</td>\n",
       "      <td>28.942857</td>\n",
       "      <td>9.371429</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  weekofyear   ndvi_ne   ndvi_nw   ndvi_se   ndvi_sw  \\\n",
       "0  1990          18  0.122600  0.103725  0.198483  0.177617   \n",
       "1  1990          19  0.169900  0.142175  0.162357  0.155486   \n",
       "2  1990          20  0.032250  0.172967  0.157200  0.170843   \n",
       "3  1990          21  0.128633  0.245067  0.227557  0.235886   \n",
       "4  1990          22  0.196200  0.262200  0.251200  0.247340   \n",
       "\n",
       "   precipitation_amt_mm  reanalysis_air_temp_k  reanalysis_avg_temp_k  \\\n",
       "0                 12.42             297.572857             297.742857   \n",
       "1                 22.82             298.211429             298.442857   \n",
       "2                 34.54             298.781429             298.878571   \n",
       "3                 15.36             298.987143             299.228571   \n",
       "4                  7.52             299.518571             299.664286   \n",
       "\n",
       "   reanalysis_dew_point_temp_k   ...     \\\n",
       "0                   292.414286   ...      \n",
       "1                   293.951429   ...      \n",
       "2                   295.434286   ...      \n",
       "3                   295.310000   ...      \n",
       "4                   295.821429   ...      \n",
       "\n",
       "   reanalysis_specific_humidity_g_per_kg  reanalysis_tdtr_k  \\\n",
       "0                              14.012857           2.628571   \n",
       "1                              15.372857           2.371429   \n",
       "2                              16.848571           2.300000   \n",
       "3                              16.672857           2.428571   \n",
       "4                              17.210000           3.014286   \n",
       "\n",
       "   station_avg_temp_c  station_diur_temp_rng_c  station_max_temp_c  \\\n",
       "0           25.442857                 6.900000                29.4   \n",
       "1           26.714286                 6.371429                31.7   \n",
       "2           26.714286                 6.485714                32.2   \n",
       "3           27.471429                 6.771429                33.3   \n",
       "4           28.942857                 9.371429                35.0   \n",
       "\n",
       "   station_min_temp_c  station_precip_mm  total_cases  city_iq  city_sj  \n",
       "0                20.0               16.0            4        0        1  \n",
       "1                22.2                8.6            5        0        1  \n",
       "2                22.8               41.4            4        0        1  \n",
       "3                23.3                4.0            3        0        1  \n",
       "4                23.9                5.8            6        0        1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_weather = \"year weekofyear ndvi_ne ndvi_nw ndvi_se ndvi_sw total_cases city_sj city_iq\".split()\n",
    "weather_features = [x for x in train.columns if x not in non_weather]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = PolynomialFeatures(degree=2, include_bias=False)\n",
    "pf_feat = pd.DataFrame(data=pf.fit_transform(train[weather_features]), columns=pf.get_feature_names(weather_features))\n",
    "\n",
    "train_weather = train.copy()\n",
    "train_weather.drop(labels=weather_features, axis=1, inplace=True)\n",
    "train_weather = train_weather.join(pf_feat, how=\"outer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. first parameter optimization NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"total_cases\"\n",
    "feats = [x for x in train_weather.columns if x != target]\n",
    "X = train_weather[feats]\n",
    "y = train_weather[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "Xs_train = ss.fit_transform(X_train)\n",
    "Xs_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 946 samples, validate on 316 samples\n",
      "Epoch 1/1000\n",
      "946/946 [==============================] - 0s 523us/step - loss: 25.6349 - val_loss: 24.5375\n",
      "Epoch 2/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 21.9466 - val_loss: 22.7547\n",
      "Epoch 3/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 20.1303 - val_loss: 21.6752\n",
      "Epoch 4/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 19.0070 - val_loss: 20.7653\n",
      "Epoch 5/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 18.0903 - val_loss: 19.9263\n",
      "Epoch 6/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 17.4207 - val_loss: 19.3736\n",
      "Epoch 7/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 16.8704 - val_loss: 18.8245\n",
      "Epoch 8/1000\n",
      "946/946 [==============================] - 0s 54us/step - loss: 16.4783 - val_loss: 18.4908\n",
      "Epoch 9/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 15.9730 - val_loss: 18.1596\n",
      "Epoch 10/1000\n",
      "946/946 [==============================] - 0s 53us/step - loss: 15.6149 - val_loss: 17.8883\n",
      "Epoch 11/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 15.3865 - val_loss: 17.5579\n",
      "Epoch 12/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 15.1785 - val_loss: 17.3314\n",
      "Epoch 13/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 14.8456 - val_loss: 17.1080\n",
      "Epoch 14/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 14.7822 - val_loss: 17.0215\n",
      "Epoch 15/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 14.6439 - val_loss: 16.7510\n",
      "Epoch 16/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 14.4920 - val_loss: 16.6512\n",
      "Epoch 17/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 14.3562 - val_loss: 16.5636\n",
      "Epoch 18/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 14.3421 - val_loss: 16.5435\n",
      "Epoch 19/1000\n",
      "946/946 [==============================] - 0s 57us/step - loss: 14.2020 - val_loss: 16.4782\n",
      "Epoch 20/1000\n",
      "946/946 [==============================] - 0s 56us/step - loss: 14.0532 - val_loss: 16.3369\n",
      "Epoch 21/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 14.1153 - val_loss: 16.2732\n",
      "Epoch 22/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 14.0288 - val_loss: 16.3161\n",
      "Epoch 23/1000\n",
      "946/946 [==============================] - 0s 53us/step - loss: 14.0217 - val_loss: 16.2133\n",
      "Epoch 24/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 13.9039 - val_loss: 16.2604\n",
      "Epoch 25/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 13.9154 - val_loss: 16.1795\n",
      "Epoch 26/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 13.7676 - val_loss: 16.3083\n",
      "Epoch 27/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 14.0474 - val_loss: 16.2161\n",
      "Epoch 28/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 13.8903 - val_loss: 16.0843\n",
      "Epoch 29/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 13.6526 - val_loss: 16.1019\n",
      "Epoch 30/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.6869 - val_loss: 16.0287\n",
      "Epoch 31/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.6907 - val_loss: 15.9468\n",
      "Epoch 32/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 13.5862 - val_loss: 16.0079\n",
      "Epoch 33/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 13.5490 - val_loss: 16.0372\n",
      "Epoch 34/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 13.6710 - val_loss: 16.1187\n",
      "Epoch 35/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 13.6112 - val_loss: 16.0692\n",
      "Epoch 36/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 13.5889 - val_loss: 15.8610\n",
      "Epoch 37/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 13.5161 - val_loss: 15.8259\n",
      "Epoch 38/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 13.5021 - val_loss: 15.9425\n",
      "Epoch 39/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 13.4607 - val_loss: 15.8434\n",
      "Epoch 40/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 13.5764 - val_loss: 15.8409\n",
      "Epoch 41/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.5248 - val_loss: 15.8197\n",
      "Epoch 42/1000\n",
      "946/946 [==============================] - 0s 56us/step - loss: 13.4526 - val_loss: 15.9774\n",
      "Epoch 43/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 13.4475 - val_loss: 15.8379\n",
      "Epoch 44/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 13.4253 - val_loss: 15.8389\n",
      "Epoch 45/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 13.4025 - val_loss: 15.7723\n",
      "Epoch 46/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.3648 - val_loss: 15.9781\n",
      "Epoch 47/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 13.4687 - val_loss: 15.9721\n",
      "Epoch 48/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 13.4530 - val_loss: 15.7091\n",
      "Epoch 49/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.4372 - val_loss: 15.7133\n",
      "Epoch 50/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.4582 - val_loss: 15.6871\n",
      "Epoch 51/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 13.3726 - val_loss: 15.7889\n",
      "Epoch 52/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 13.4775 - val_loss: 15.6789\n",
      "Epoch 53/1000\n",
      "946/946 [==============================] - 0s 60us/step - loss: 13.3026 - val_loss: 15.7167\n",
      "Epoch 54/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 13.2534 - val_loss: 15.7678\n",
      "Epoch 55/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 13.3089 - val_loss: 15.7267\n",
      "Epoch 56/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 13.3989 - val_loss: 15.9347\n",
      "Epoch 57/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 13.3629 - val_loss: 15.5516\n",
      "Epoch 58/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 13.3048 - val_loss: 15.6284\n",
      "Epoch 59/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 13.1770 - val_loss: 15.6322\n",
      "Epoch 60/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 13.2043 - val_loss: 15.7063\n",
      "Epoch 61/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 13.2695 - val_loss: 15.6199\n",
      "Epoch 62/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.2541 - val_loss: 15.5909\n",
      "Epoch 63/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 13.3051 - val_loss: 15.7476\n",
      "Epoch 64/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.2538 - val_loss: 15.6030\n",
      "Epoch 65/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 13.3034 - val_loss: 15.5666\n",
      "Epoch 66/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.1886 - val_loss: 15.5694\n",
      "Epoch 67/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.1218 - val_loss: 15.6209\n",
      "Epoch 68/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 13.2651 - val_loss: 15.5198\n",
      "Epoch 69/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 13.2180 - val_loss: 15.5965\n",
      "Epoch 70/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 13.3264 - val_loss: 15.5035\n",
      "Epoch 71/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 13.1745 - val_loss: 15.5151\n",
      "Epoch 72/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.2964 - val_loss: 15.4977\n",
      "Epoch 73/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 13.1189 - val_loss: 15.7290\n",
      "Epoch 74/1000\n",
      "946/946 [==============================] - 0s 54us/step - loss: 13.1910 - val_loss: 15.5474\n",
      "Epoch 75/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 13.2027 - val_loss: 15.5130\n",
      "Epoch 76/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.1104 - val_loss: 15.4765\n",
      "Epoch 77/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 13.2019 - val_loss: 15.4526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 13.0803 - val_loss: 15.5525\n",
      "Epoch 79/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 13.0673 - val_loss: 15.6313\n",
      "Epoch 80/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.1148 - val_loss: 15.5247\n",
      "Epoch 81/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.2133 - val_loss: 15.8620\n",
      "Epoch 82/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.1083 - val_loss: 15.5138\n",
      "Epoch 83/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 13.1545 - val_loss: 15.4932\n",
      "Epoch 84/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 13.0701 - val_loss: 15.4527\n",
      "Epoch 85/1000\n",
      "946/946 [==============================] - 0s 60us/step - loss: 13.1756 - val_loss: 15.3966\n",
      "Epoch 86/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.0801 - val_loss: 15.4598\n",
      "Epoch 87/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 13.1151 - val_loss: 15.4397\n",
      "Epoch 88/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 13.2156 - val_loss: 15.4060\n",
      "Epoch 89/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.3307 - val_loss: 15.4782\n",
      "Epoch 90/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.2082 - val_loss: 15.5609\n",
      "Epoch 91/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 13.0569 - val_loss: 15.5658\n",
      "Epoch 92/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.1499 - val_loss: 15.4221\n",
      "Epoch 93/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 13.0950 - val_loss: 15.6651\n",
      "Epoch 94/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 13.0762 - val_loss: 15.4824\n",
      "Epoch 95/1000\n",
      "946/946 [==============================] - 0s 53us/step - loss: 13.1519 - val_loss: 15.8127\n",
      "Epoch 96/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 13.0664 - val_loss: 15.4770\n",
      "Epoch 97/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 13.1749 - val_loss: 15.4322\n",
      "Epoch 98/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 13.0671 - val_loss: 15.5625\n",
      "Epoch 99/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 13.1136 - val_loss: 15.3840\n",
      "Epoch 100/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.0985 - val_loss: 15.3551\n",
      "Epoch 101/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.1233 - val_loss: 15.4457\n",
      "Epoch 102/1000\n",
      "946/946 [==============================] - 0s 56us/step - loss: 12.9763 - val_loss: 15.3629\n",
      "Epoch 103/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 13.0967 - val_loss: 15.4353\n",
      "Epoch 104/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.1238 - val_loss: 15.4386\n",
      "Epoch 105/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 13.1042 - val_loss: 15.3581\n",
      "Epoch 106/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 13.0062 - val_loss: 15.2945\n",
      "Epoch 107/1000\n",
      "946/946 [==============================] - 0s 52us/step - loss: 13.0416 - val_loss: 15.2925\n",
      "Epoch 108/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.9122 - val_loss: 15.2846\n",
      "Epoch 109/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.0766 - val_loss: 15.2843\n",
      "Epoch 110/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 13.0076 - val_loss: 15.2356\n",
      "Epoch 111/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 13.0516 - val_loss: 15.4288\n",
      "Epoch 112/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.0996 - val_loss: 15.3011\n",
      "Epoch 113/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.9902 - val_loss: 15.5008\n",
      "Epoch 114/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.0751 - val_loss: 15.3480\n",
      "Epoch 115/1000\n",
      "946/946 [==============================] - 0s 52us/step - loss: 13.0285 - val_loss: 15.4694\n",
      "Epoch 116/1000\n",
      "946/946 [==============================] - 0s 55us/step - loss: 13.0718 - val_loss: 15.1815\n",
      "Epoch 117/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.0593 - val_loss: 15.3035\n",
      "Epoch 118/1000\n",
      "946/946 [==============================] - 0s 52us/step - loss: 13.0068 - val_loss: 15.3069\n",
      "Epoch 119/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 13.0368 - val_loss: 15.3838\n",
      "Epoch 120/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.0893 - val_loss: 15.2678\n",
      "Epoch 121/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.9749 - val_loss: 15.3082\n",
      "Epoch 122/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 13.0839 - val_loss: 15.3276\n",
      "Epoch 123/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.0438 - val_loss: 15.2674\n",
      "Epoch 124/1000\n",
      "946/946 [==============================] - 0s 52us/step - loss: 13.1144 - val_loss: 15.2301\n",
      "Epoch 125/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 13.0856 - val_loss: 15.2256\n",
      "Epoch 126/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 13.0306 - val_loss: 15.2205\n",
      "Epoch 127/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 13.0652 - val_loss: 15.2465\n",
      "Epoch 128/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 13.0493 - val_loss: 15.3915\n",
      "Epoch 129/1000\n",
      "946/946 [==============================] - 0s 53us/step - loss: 13.0573 - val_loss: 15.2476\n",
      "Epoch 130/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 13.1128 - val_loss: 15.1736\n",
      "Epoch 131/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.9312 - val_loss: 15.1759\n",
      "Epoch 132/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.9325 - val_loss: 15.3036\n",
      "Epoch 133/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.0538 - val_loss: 15.2938\n",
      "Epoch 134/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.0442 - val_loss: 15.3629\n",
      "Epoch 135/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 12.9693 - val_loss: 15.2312\n",
      "Epoch 136/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.9657 - val_loss: 15.2736\n",
      "Epoch 137/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.9001 - val_loss: 15.1798\n",
      "Epoch 138/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.8751 - val_loss: 15.1604\n",
      "Epoch 139/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.9653 - val_loss: 15.0737\n",
      "Epoch 140/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 13.0444 - val_loss: 15.4631\n",
      "Epoch 141/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.0432 - val_loss: 15.2422\n",
      "Epoch 142/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.9600 - val_loss: 15.1499\n",
      "Epoch 143/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.9006 - val_loss: 15.1329\n",
      "Epoch 144/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.9907 - val_loss: 15.2230\n",
      "Epoch 145/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.9618 - val_loss: 15.1572\n",
      "Epoch 146/1000\n",
      "946/946 [==============================] - 0s 52us/step - loss: 12.9411 - val_loss: 15.2261\n",
      "Epoch 147/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.9398 - val_loss: 15.0781\n",
      "Epoch 148/1000\n",
      "946/946 [==============================] - 0s 53us/step - loss: 12.9236 - val_loss: 15.2287\n",
      "Epoch 149/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.9980 - val_loss: 15.1181\n",
      "Epoch 150/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.8111 - val_loss: 15.2501\n",
      "Epoch 151/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.8800 - val_loss: 15.2005\n",
      "Epoch 152/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.0136 - val_loss: 15.0693\n",
      "Epoch 153/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.9639 - val_loss: 15.0912\n",
      "Epoch 154/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.9524 - val_loss: 15.1517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.9693 - val_loss: 15.0371\n",
      "Epoch 156/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 13.0113 - val_loss: 15.3545\n",
      "Epoch 157/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.1069 - val_loss: 15.0040\n",
      "Epoch 158/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.8952 - val_loss: 15.1415\n",
      "Epoch 159/1000\n",
      "946/946 [==============================] - 0s 53us/step - loss: 12.9581 - val_loss: 15.1187\n",
      "Epoch 160/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.9963 - val_loss: 15.0347\n",
      "Epoch 161/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.8728 - val_loss: 15.2859\n",
      "Epoch 162/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.8669 - val_loss: 15.1493\n",
      "Epoch 163/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.9111 - val_loss: 15.0608\n",
      "Epoch 164/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.9117 - val_loss: 15.0508\n",
      "Epoch 165/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.9393 - val_loss: 15.1403\n",
      "Epoch 166/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.8799 - val_loss: 14.9442\n",
      "Epoch 167/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.8871 - val_loss: 15.0861\n",
      "Epoch 168/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.8545 - val_loss: 15.0534\n",
      "Epoch 169/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 12.7698 - val_loss: 15.0748\n",
      "Epoch 170/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.8598 - val_loss: 15.0053\n",
      "Epoch 171/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.9391 - val_loss: 15.0300\n",
      "Epoch 172/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.9743 - val_loss: 15.0996\n",
      "Epoch 173/1000\n",
      "946/946 [==============================] - 0s 53us/step - loss: 12.9777 - val_loss: 14.9827\n",
      "Epoch 174/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.8492 - val_loss: 15.3146\n",
      "Epoch 175/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 12.8927 - val_loss: 15.0384\n",
      "Epoch 176/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 12.8586 - val_loss: 15.1246\n",
      "Epoch 177/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.8573 - val_loss: 15.0292\n",
      "Epoch 178/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.9173 - val_loss: 14.9678\n",
      "Epoch 179/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.8367 - val_loss: 15.0910\n",
      "Epoch 180/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.8693 - val_loss: 15.1004\n",
      "Epoch 181/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.9071 - val_loss: 15.1815\n",
      "Epoch 182/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.9610 - val_loss: 14.9862\n",
      "Epoch 183/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.8720 - val_loss: 15.0797\n",
      "Epoch 184/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 13.0460 - val_loss: 15.3348\n",
      "Epoch 185/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.7224 - val_loss: 15.0419\n",
      "Epoch 186/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.8847 - val_loss: 15.1171\n",
      "Epoch 187/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.7763 - val_loss: 15.1254\n",
      "Epoch 188/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.8873 - val_loss: 14.9309\n",
      "Epoch 189/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.8551 - val_loss: 15.1300\n",
      "Epoch 190/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 12.8322 - val_loss: 14.9553\n",
      "Epoch 191/1000\n",
      "946/946 [==============================] - 0s 54us/step - loss: 12.7472 - val_loss: 14.9808\n",
      "Epoch 192/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.7950 - val_loss: 15.0245\n",
      "Epoch 193/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.9361 - val_loss: 14.9839\n",
      "Epoch 194/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.8475 - val_loss: 15.0008\n",
      "Epoch 195/1000\n",
      "946/946 [==============================] - 0s 53us/step - loss: 12.9263 - val_loss: 14.9751\n",
      "Epoch 196/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.8235 - val_loss: 15.0264\n",
      "Epoch 197/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.8806 - val_loss: 15.0203\n",
      "Epoch 198/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.7686 - val_loss: 14.9644\n",
      "Epoch 199/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.7734 - val_loss: 15.0083\n",
      "Epoch 200/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.7388 - val_loss: 14.9152\n",
      "Epoch 201/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.7634 - val_loss: 14.8996\n",
      "Epoch 202/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.6941 - val_loss: 14.9113\n",
      "Epoch 203/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.8419 - val_loss: 14.9186\n",
      "Epoch 204/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.7978 - val_loss: 14.9582\n",
      "Epoch 205/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.8293 - val_loss: 15.0284\n",
      "Epoch 206/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.8075 - val_loss: 14.8488\n",
      "Epoch 207/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.8396 - val_loss: 15.0951\n",
      "Epoch 208/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.7907 - val_loss: 14.8814\n",
      "Epoch 209/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 12.8969 - val_loss: 14.8487\n",
      "Epoch 210/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.7832 - val_loss: 14.9674\n",
      "Epoch 211/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.8349 - val_loss: 14.8802\n",
      "Epoch 212/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.7888 - val_loss: 14.8624\n",
      "Epoch 213/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 12.7716 - val_loss: 14.8714\n",
      "Epoch 214/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.9793 - val_loss: 14.9092\n",
      "Epoch 215/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.6974 - val_loss: 14.9369\n",
      "Epoch 216/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.7288 - val_loss: 15.0001\n",
      "Epoch 217/1000\n",
      "946/946 [==============================] - 0s 52us/step - loss: 12.6703 - val_loss: 14.8734\n",
      "Epoch 218/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.7938 - val_loss: 15.1486\n",
      "Epoch 219/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.6677 - val_loss: 14.8267\n",
      "Epoch 220/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.8203 - val_loss: 14.9861\n",
      "Epoch 221/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.9902 - val_loss: 15.0182\n",
      "Epoch 222/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 12.7417 - val_loss: 14.8588\n",
      "Epoch 223/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.9626 - val_loss: 14.8980\n",
      "Epoch 224/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 12.8169 - val_loss: 15.0063\n",
      "Epoch 225/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.7649 - val_loss: 14.8763\n",
      "Epoch 226/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.8019 - val_loss: 14.9771\n",
      "Epoch 227/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.6603 - val_loss: 14.8677\n",
      "Epoch 228/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.8859 - val_loss: 14.8331\n",
      "Epoch 229/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.7661 - val_loss: 15.0504\n",
      "Epoch 230/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.7019 - val_loss: 15.0235\n",
      "Epoch 231/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.7366 - val_loss: 14.9327\n",
      "Epoch 232/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.7274 - val_loss: 14.8609\n",
      "Epoch 233/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.8838 - val_loss: 14.8946\n",
      "Epoch 234/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 12.5549 - val_loss: 14.8776\n",
      "Epoch 235/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.7324 - val_loss: 14.9171\n",
      "Epoch 236/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.9092 - val_loss: 15.0226\n",
      "Epoch 237/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.8583 - val_loss: 14.8447\n",
      "Epoch 238/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.8200 - val_loss: 14.9790\n",
      "Epoch 239/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.7023 - val_loss: 14.8500\n",
      "Epoch 240/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.7631 - val_loss: 14.8651\n",
      "Epoch 241/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.7500 - val_loss: 14.9059\n",
      "Epoch 242/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.8189 - val_loss: 14.8569\n",
      "Epoch 243/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.7759 - val_loss: 14.8474\n",
      "Epoch 244/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.7284 - val_loss: 14.8480\n",
      "Epoch 245/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.7088 - val_loss: 14.8463\n",
      "Epoch 246/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.7646 - val_loss: 14.8476\n",
      "Epoch 247/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.7580 - val_loss: 14.9100\n",
      "Epoch 248/1000\n",
      "946/946 [==============================] - 0s 52us/step - loss: 12.7021 - val_loss: 14.8623\n",
      "Epoch 249/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.8164 - val_loss: 14.8212\n",
      "Epoch 250/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.6823 - val_loss: 14.8775\n",
      "Epoch 251/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.6310 - val_loss: 14.7925\n",
      "Epoch 252/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.7210 - val_loss: 14.9089\n",
      "Epoch 253/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 12.6315 - val_loss: 14.7060\n",
      "Epoch 254/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.7326 - val_loss: 14.8078\n",
      "Epoch 255/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.6852 - val_loss: 14.7967\n",
      "Epoch 256/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.6694 - val_loss: 15.2227\n",
      "Epoch 257/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.7215 - val_loss: 14.7506\n",
      "Epoch 258/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.6619 - val_loss: 15.0001\n",
      "Epoch 259/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.5760 - val_loss: 14.7845\n",
      "Epoch 260/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.6020 - val_loss: 14.7723\n",
      "Epoch 261/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.6978 - val_loss: 14.7933\n",
      "Epoch 262/1000\n",
      "946/946 [==============================] - 0s 35us/step - loss: 12.6515 - val_loss: 14.6665\n",
      "Epoch 263/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.7749 - val_loss: 14.9101\n",
      "Epoch 264/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.7999 - val_loss: 14.7348\n",
      "Epoch 265/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.7238 - val_loss: 14.7613\n",
      "Epoch 266/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.7006 - val_loss: 15.0921\n",
      "Epoch 267/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.8007 - val_loss: 14.8677\n",
      "Epoch 268/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.6472 - val_loss: 14.7891\n",
      "Epoch 269/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.7580 - val_loss: 14.8511\n",
      "Epoch 270/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.6121 - val_loss: 14.9146\n",
      "Epoch 271/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.7252 - val_loss: 15.0056\n",
      "Epoch 272/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.8202 - val_loss: 14.6939\n",
      "Epoch 273/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5698 - val_loss: 14.8761\n",
      "Epoch 274/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.6855 - val_loss: 14.8468\n",
      "Epoch 275/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.6854 - val_loss: 14.8521\n",
      "Epoch 276/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.7626 - val_loss: 14.8105\n",
      "Epoch 277/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.6888 - val_loss: 15.0077\n",
      "Epoch 278/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.7075 - val_loss: 14.8633\n",
      "Epoch 279/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.6640 - val_loss: 14.9177\n",
      "Epoch 280/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.7354 - val_loss: 14.8412\n",
      "Epoch 281/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.4677 - val_loss: 14.6896\n",
      "Epoch 282/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.6927 - val_loss: 14.7841\n",
      "Epoch 283/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.7422 - val_loss: 14.8234\n",
      "Epoch 284/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.6112 - val_loss: 14.7920\n",
      "Epoch 285/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5558 - val_loss: 14.7497\n",
      "Epoch 286/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.6264 - val_loss: 14.8325\n",
      "Epoch 287/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.6571 - val_loss: 14.7253\n",
      "Epoch 288/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.6432 - val_loss: 14.7252\n",
      "Epoch 289/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.6131 - val_loss: 14.8071\n",
      "Epoch 290/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.6280 - val_loss: 14.6900\n",
      "Epoch 291/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.6093 - val_loss: 14.7766\n",
      "Epoch 292/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.7913 - val_loss: 14.8658\n",
      "Epoch 293/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.7717 - val_loss: 14.7898\n",
      "Epoch 294/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.6788 - val_loss: 14.8425\n",
      "Epoch 295/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.6832 - val_loss: 14.7980\n",
      "Epoch 296/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.7223 - val_loss: 14.6477\n",
      "Epoch 297/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5988 - val_loss: 14.8999\n",
      "Epoch 298/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.7516 - val_loss: 14.7546\n",
      "Epoch 299/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.7504 - val_loss: 14.7887\n",
      "Epoch 300/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5773 - val_loss: 14.6955\n",
      "Epoch 301/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.7378 - val_loss: 14.6983\n",
      "Epoch 302/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.7553 - val_loss: 14.6671\n",
      "Epoch 303/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.8243 - val_loss: 14.7969\n",
      "Epoch 304/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.6672 - val_loss: 14.7702\n",
      "Epoch 305/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.6800 - val_loss: 14.8973\n",
      "Epoch 306/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.7273 - val_loss: 14.7253\n",
      "Epoch 307/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946/946 [==============================] - 0s 44us/step - loss: 12.5927 - val_loss: 14.8480\n",
      "Epoch 308/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5757 - val_loss: 14.8103\n",
      "Epoch 309/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.6157 - val_loss: 14.7401\n",
      "Epoch 310/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.7960 - val_loss: 14.7392\n",
      "Epoch 311/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.6377 - val_loss: 14.9936\n",
      "Epoch 312/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.7164 - val_loss: 14.6571\n",
      "Epoch 313/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.6152 - val_loss: 14.7501\n",
      "Epoch 314/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.5095 - val_loss: 14.7762\n",
      "Epoch 315/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.6516 - val_loss: 14.7230\n",
      "Epoch 316/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.7389 - val_loss: 14.6942\n",
      "Epoch 317/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.6561 - val_loss: 14.7780\n",
      "Epoch 318/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5546 - val_loss: 14.7089\n",
      "Epoch 319/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.5601 - val_loss: 14.7430\n",
      "Epoch 320/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5937 - val_loss: 14.7296\n",
      "Epoch 321/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5585 - val_loss: 14.7115\n",
      "Epoch 322/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.6244 - val_loss: 14.6440\n",
      "Epoch 323/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.7000 - val_loss: 14.6616\n",
      "Epoch 324/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.7440 - val_loss: 14.7765\n",
      "Epoch 325/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5809 - val_loss: 14.6386\n",
      "Epoch 326/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.6677 - val_loss: 14.7735\n",
      "Epoch 327/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.7291 - val_loss: 14.8989\n",
      "Epoch 328/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.7483 - val_loss: 14.6114\n",
      "Epoch 329/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.7354 - val_loss: 14.6084\n",
      "Epoch 330/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.7099 - val_loss: 14.6616\n",
      "Epoch 331/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.8017 - val_loss: 14.6827\n",
      "Epoch 332/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.6603 - val_loss: 14.6601\n",
      "Epoch 333/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5738 - val_loss: 14.6682\n",
      "Epoch 334/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4155 - val_loss: 14.7470\n",
      "Epoch 335/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.8455 - val_loss: 14.7655\n",
      "Epoch 336/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.7435 - val_loss: 14.6641\n",
      "Epoch 337/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.8093 - val_loss: 14.6310\n",
      "Epoch 338/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.5924 - val_loss: 14.7243\n",
      "Epoch 339/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.6902 - val_loss: 14.7691\n",
      "Epoch 340/1000\n",
      "946/946 [==============================] - 0s 36us/step - loss: 12.5429 - val_loss: 14.7445\n",
      "Epoch 341/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5079 - val_loss: 14.6693\n",
      "Epoch 342/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4958 - val_loss: 14.6068\n",
      "Epoch 343/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4573 - val_loss: 14.6394\n",
      "Epoch 344/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5924 - val_loss: 14.6647\n",
      "Epoch 345/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.7217 - val_loss: 14.5476\n",
      "Epoch 346/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5576 - val_loss: 14.8685\n",
      "Epoch 347/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.6247 - val_loss: 14.6349\n",
      "Epoch 348/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.6143 - val_loss: 14.6656\n",
      "Epoch 349/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.6129 - val_loss: 14.5734\n",
      "Epoch 350/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5140 - val_loss: 14.6617\n",
      "Epoch 351/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.6822 - val_loss: 14.6386\n",
      "Epoch 352/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5297 - val_loss: 14.8025\n",
      "Epoch 353/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.6168 - val_loss: 14.7169\n",
      "Epoch 354/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.7381 - val_loss: 14.6992\n",
      "Epoch 355/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.6933 - val_loss: 14.5896\n",
      "Epoch 356/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.6325 - val_loss: 14.7338\n",
      "Epoch 357/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5906 - val_loss: 14.6259\n",
      "Epoch 358/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5434 - val_loss: 14.7273\n",
      "Epoch 359/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5528 - val_loss: 14.7011\n",
      "Epoch 360/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.6836 - val_loss: 14.6802\n",
      "Epoch 361/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.6585 - val_loss: 14.6967\n",
      "Epoch 362/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5240 - val_loss: 14.5822\n",
      "Epoch 363/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.7119 - val_loss: 14.6572\n",
      "Epoch 364/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.6738 - val_loss: 14.6011\n",
      "Epoch 365/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.6078 - val_loss: 14.7000\n",
      "Epoch 366/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.6783 - val_loss: 14.5650\n",
      "Epoch 367/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5157 - val_loss: 14.5784\n",
      "Epoch 368/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.6957 - val_loss: 14.6568\n",
      "Epoch 369/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5681 - val_loss: 14.7716\n",
      "Epoch 370/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.6768 - val_loss: 14.6422\n",
      "Epoch 371/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4615 - val_loss: 14.6522\n",
      "Epoch 372/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5901 - val_loss: 14.6958\n",
      "Epoch 373/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.5481 - val_loss: 14.6379\n",
      "Epoch 374/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5317 - val_loss: 14.7909\n",
      "Epoch 375/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.6736 - val_loss: 14.6962\n",
      "Epoch 376/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5151 - val_loss: 14.5609\n",
      "Epoch 377/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5689 - val_loss: 14.7998\n",
      "Epoch 378/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.6523 - val_loss: 14.7812\n",
      "Epoch 379/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.4024 - val_loss: 14.6258\n",
      "Epoch 380/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5770 - val_loss: 14.7166\n",
      "Epoch 381/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5895 - val_loss: 14.6275\n",
      "Epoch 382/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.7938 - val_loss: 14.6300\n",
      "Epoch 383/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.7149 - val_loss: 14.6286\n",
      "Epoch 384/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4824 - val_loss: 14.6461\n",
      "Epoch 385/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 12.7211 - val_loss: 14.7400\n",
      "Epoch 386/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5294 - val_loss: 14.6800\n",
      "Epoch 387/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4236 - val_loss: 14.5645\n",
      "Epoch 388/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4352 - val_loss: 14.7358\n",
      "Epoch 389/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5946 - val_loss: 14.7221\n",
      "Epoch 390/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.4984 - val_loss: 14.7182\n",
      "Epoch 391/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5347 - val_loss: 14.6706\n",
      "Epoch 392/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.6664 - val_loss: 14.5579\n",
      "Epoch 393/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.6582 - val_loss: 14.6348\n",
      "Epoch 394/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5823 - val_loss: 14.6720\n",
      "Epoch 395/1000\n",
      "946/946 [==============================] - 0s 36us/step - loss: 12.5243 - val_loss: 14.5874\n",
      "Epoch 396/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5970 - val_loss: 14.7222\n",
      "Epoch 397/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 12.5727 - val_loss: 14.6506\n",
      "Epoch 398/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.4122 - val_loss: 14.6986\n",
      "Epoch 399/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5745 - val_loss: 14.5634\n",
      "Epoch 400/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.6141 - val_loss: 14.6451\n",
      "Epoch 401/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4957 - val_loss: 14.6278\n",
      "Epoch 402/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.4906 - val_loss: 14.5682\n",
      "Epoch 403/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5950 - val_loss: 14.5958\n",
      "Epoch 404/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.4577 - val_loss: 14.6841\n",
      "Epoch 405/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.6193 - val_loss: 14.6784\n",
      "Epoch 406/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5679 - val_loss: 14.5922\n",
      "Epoch 407/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4939 - val_loss: 14.5623\n",
      "Epoch 408/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4549 - val_loss: 14.6381\n",
      "Epoch 409/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.5876 - val_loss: 14.6508\n",
      "Epoch 410/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.7073 - val_loss: 14.6686\n",
      "Epoch 411/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5993 - val_loss: 14.6058\n",
      "Epoch 412/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.6197 - val_loss: 14.8618\n",
      "Epoch 413/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5995 - val_loss: 14.6038\n",
      "Epoch 414/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5888 - val_loss: 14.7217\n",
      "Epoch 415/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4787 - val_loss: 14.5698\n",
      "Epoch 416/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.6617 - val_loss: 14.7015\n",
      "Epoch 417/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5715 - val_loss: 14.6418\n",
      "Epoch 418/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.6375 - val_loss: 14.5662\n",
      "Epoch 419/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5270 - val_loss: 14.6821\n",
      "Epoch 420/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.6638 - val_loss: 14.5335\n",
      "Epoch 421/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5802 - val_loss: 14.5947\n",
      "Epoch 422/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4571 - val_loss: 14.6351\n",
      "Epoch 423/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5094 - val_loss: 14.6193\n",
      "Epoch 424/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.6812 - val_loss: 14.5532\n",
      "Epoch 425/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5632 - val_loss: 14.4861\n",
      "Epoch 426/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.7019 - val_loss: 14.5158\n",
      "Epoch 427/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5937 - val_loss: 14.5645\n",
      "Epoch 428/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5034 - val_loss: 14.6870\n",
      "Epoch 429/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4994 - val_loss: 14.6556\n",
      "Epoch 430/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.6365 - val_loss: 14.6165\n",
      "Epoch 431/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.6967 - val_loss: 14.4705\n",
      "Epoch 432/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4192 - val_loss: 14.6270\n",
      "Epoch 433/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.5571 - val_loss: 14.5283\n",
      "Epoch 434/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3157 - val_loss: 14.7161\n",
      "Epoch 435/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4936 - val_loss: 14.5586\n",
      "Epoch 436/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.4874 - val_loss: 14.6605\n",
      "Epoch 437/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5054 - val_loss: 14.7035\n",
      "Epoch 438/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3599 - val_loss: 14.5266\n",
      "Epoch 439/1000\n",
      "946/946 [==============================] - 0s 36us/step - loss: 12.4878 - val_loss: 14.5719\n",
      "Epoch 440/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5933 - val_loss: 14.6996\n",
      "Epoch 441/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5336 - val_loss: 14.5553\n",
      "Epoch 442/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5173 - val_loss: 14.6289\n",
      "Epoch 443/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5178 - val_loss: 14.5870\n",
      "Epoch 444/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.6662 - val_loss: 14.5687\n",
      "Epoch 445/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5573 - val_loss: 14.5958\n",
      "Epoch 446/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4579 - val_loss: 14.5769\n",
      "Epoch 447/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5306 - val_loss: 14.6539\n",
      "Epoch 448/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.6957 - val_loss: 14.5528\n",
      "Epoch 449/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.6135 - val_loss: 14.6579\n",
      "Epoch 450/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5536 - val_loss: 14.6754\n",
      "Epoch 451/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5060 - val_loss: 14.6290\n",
      "Epoch 452/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4356 - val_loss: 14.5136\n",
      "Epoch 453/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.5229 - val_loss: 14.5896\n",
      "Epoch 454/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5515 - val_loss: 14.5808\n",
      "Epoch 455/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.5078 - val_loss: 14.4651\n",
      "Epoch 456/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4040 - val_loss: 14.6469\n",
      "Epoch 457/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.5754 - val_loss: 14.6226\n",
      "Epoch 458/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.3854 - val_loss: 14.5850\n",
      "Epoch 459/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946/946 [==============================] - 0s 42us/step - loss: 12.4665 - val_loss: 14.4658\n",
      "Epoch 460/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.4677 - val_loss: 14.6237\n",
      "Epoch 461/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4952 - val_loss: 14.5183\n",
      "Epoch 462/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5184 - val_loss: 14.5431\n",
      "Epoch 463/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5500 - val_loss: 14.5771\n",
      "Epoch 464/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5208 - val_loss: 14.5925\n",
      "Epoch 465/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4727 - val_loss: 14.4541\n",
      "Epoch 466/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.7080 - val_loss: 14.6484\n",
      "Epoch 467/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4371 - val_loss: 14.5581\n",
      "Epoch 468/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.6717 - val_loss: 14.7681\n",
      "Epoch 469/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5647 - val_loss: 14.4629\n",
      "Epoch 470/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5186 - val_loss: 14.5651\n",
      "Epoch 471/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.6674 - val_loss: 14.5154\n",
      "Epoch 472/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.4954 - val_loss: 14.6380\n",
      "Epoch 473/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5138 - val_loss: 14.5775\n",
      "Epoch 474/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4342 - val_loss: 14.5199\n",
      "Epoch 475/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.6959 - val_loss: 14.5678\n",
      "Epoch 476/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4057 - val_loss: 14.7056\n",
      "Epoch 477/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.7288 - val_loss: 14.7067\n",
      "Epoch 478/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5718 - val_loss: 14.5464\n",
      "Epoch 479/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.6245 - val_loss: 14.4982\n",
      "Epoch 480/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4019 - val_loss: 14.5302\n",
      "Epoch 481/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.4848 - val_loss: 14.5629\n",
      "Epoch 482/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.4448 - val_loss: 14.5208\n",
      "Epoch 483/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.4328 - val_loss: 14.5300\n",
      "Epoch 484/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5181 - val_loss: 14.4503\n",
      "Epoch 485/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5077 - val_loss: 14.5036\n",
      "Epoch 486/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4434 - val_loss: 14.6046\n",
      "Epoch 487/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3986 - val_loss: 14.5305\n",
      "Epoch 488/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5554 - val_loss: 14.5161\n",
      "Epoch 489/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5016 - val_loss: 14.5522\n",
      "Epoch 490/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.4393 - val_loss: 14.5093\n",
      "Epoch 491/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4503 - val_loss: 14.5794\n",
      "Epoch 492/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.6040 - val_loss: 14.5987\n",
      "Epoch 493/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5039 - val_loss: 14.6174\n",
      "Epoch 494/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4417 - val_loss: 14.7279\n",
      "Epoch 495/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.6832 - val_loss: 14.4011\n",
      "Epoch 496/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5460 - val_loss: 14.5471\n",
      "Epoch 497/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.4351 - val_loss: 14.6585\n",
      "Epoch 498/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3814 - val_loss: 14.5821\n",
      "Epoch 499/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5018 - val_loss: 14.6050\n",
      "Epoch 500/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.3331 - val_loss: 14.5533\n",
      "Epoch 501/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.6996 - val_loss: 14.5526\n",
      "Epoch 502/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4102 - val_loss: 14.5892\n",
      "Epoch 503/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.6157 - val_loss: 14.6343\n",
      "Epoch 504/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4852 - val_loss: 14.5877\n",
      "Epoch 505/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3752 - val_loss: 14.5947\n",
      "Epoch 506/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5116 - val_loss: 14.5400\n",
      "Epoch 507/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5368 - val_loss: 14.4083\n",
      "Epoch 508/1000\n",
      "946/946 [==============================] - 0s 35us/step - loss: 12.5392 - val_loss: 14.5482\n",
      "Epoch 509/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.3971 - val_loss: 14.4336\n",
      "Epoch 510/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4996 - val_loss: 14.5215\n",
      "Epoch 511/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.4055 - val_loss: 14.6058\n",
      "Epoch 512/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5145 - val_loss: 14.5889\n",
      "Epoch 513/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.6358 - val_loss: 14.5279\n",
      "Epoch 514/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5799 - val_loss: 14.7046\n",
      "Epoch 515/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5328 - val_loss: 14.6398\n",
      "Epoch 516/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.3979 - val_loss: 14.5164\n",
      "Epoch 517/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5067 - val_loss: 14.5444\n",
      "Epoch 518/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4863 - val_loss: 14.5406\n",
      "Epoch 519/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4562 - val_loss: 14.5909\n",
      "Epoch 520/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5051 - val_loss: 14.6523\n",
      "Epoch 521/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5177 - val_loss: 14.6193\n",
      "Epoch 522/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5694 - val_loss: 14.4966\n",
      "Epoch 523/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5506 - val_loss: 14.5534\n",
      "Epoch 524/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4206 - val_loss: 14.5860\n",
      "Epoch 525/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5889 - val_loss: 14.4769\n",
      "Epoch 526/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4719 - val_loss: 14.4966\n",
      "Epoch 527/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.5001 - val_loss: 14.5491\n",
      "Epoch 528/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5352 - val_loss: 14.5707\n",
      "Epoch 529/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5477 - val_loss: 14.4925\n",
      "Epoch 530/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.4000 - val_loss: 14.4550\n",
      "Epoch 531/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5655 - val_loss: 14.4433\n",
      "Epoch 532/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.5021 - val_loss: 14.6854\n",
      "Epoch 533/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.4296 - val_loss: 14.5098\n",
      "Epoch 534/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5230 - val_loss: 14.6484\n",
      "Epoch 535/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3983 - val_loss: 14.4156\n",
      "Epoch 536/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4442 - val_loss: 14.4708\n",
      "Epoch 537/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.3584 - val_loss: 14.5944\n",
      "Epoch 538/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4781 - val_loss: 14.6404\n",
      "Epoch 539/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.4099 - val_loss: 14.5163\n",
      "Epoch 540/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4737 - val_loss: 14.4592\n",
      "Epoch 541/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5348 - val_loss: 14.6009\n",
      "Epoch 542/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.3823 - val_loss: 14.6478\n",
      "Epoch 543/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.6593 - val_loss: 14.4185\n",
      "Epoch 544/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4398 - val_loss: 14.5186\n",
      "Epoch 545/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.4188 - val_loss: 14.4537\n",
      "Epoch 546/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4482 - val_loss: 14.4969\n",
      "Epoch 547/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5960 - val_loss: 14.6723\n",
      "Epoch 548/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.3644 - val_loss: 14.4541\n",
      "Epoch 549/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4321 - val_loss: 14.4956\n",
      "Epoch 550/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 12.5192 - val_loss: 14.4522\n",
      "Epoch 551/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.7383 - val_loss: 14.5757\n",
      "Epoch 552/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.7110 - val_loss: 14.4333\n",
      "Epoch 553/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4179 - val_loss: 14.5153\n",
      "Epoch 554/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.5704 - val_loss: 14.5392\n",
      "Epoch 555/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4050 - val_loss: 14.5996\n",
      "Epoch 556/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4056 - val_loss: 14.5148\n",
      "Epoch 557/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5011 - val_loss: 14.5234\n",
      "Epoch 558/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.6783 - val_loss: 14.6259\n",
      "Epoch 559/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5774 - val_loss: 14.4990\n",
      "Epoch 560/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5553 - val_loss: 14.7279\n",
      "Epoch 561/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4905 - val_loss: 14.6070\n",
      "Epoch 562/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.4204 - val_loss: 14.5312\n",
      "Epoch 563/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.4187 - val_loss: 14.5008\n",
      "Epoch 564/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3401 - val_loss: 14.5117\n",
      "Epoch 565/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.4621 - val_loss: 14.4787\n",
      "Epoch 566/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.6313 - val_loss: 14.3564\n",
      "Epoch 567/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5949 - val_loss: 14.4654\n",
      "Epoch 568/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.4618 - val_loss: 14.6140\n",
      "Epoch 569/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4701 - val_loss: 14.4311\n",
      "Epoch 570/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3353 - val_loss: 14.6864\n",
      "Epoch 571/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.4720 - val_loss: 14.4845\n",
      "Epoch 572/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5740 - val_loss: 14.5132\n",
      "Epoch 573/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.3740 - val_loss: 14.5316\n",
      "Epoch 574/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3862 - val_loss: 14.4724\n",
      "Epoch 575/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5106 - val_loss: 14.4797\n",
      "Epoch 576/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4379 - val_loss: 14.5658\n",
      "Epoch 577/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4923 - val_loss: 14.4366\n",
      "Epoch 578/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3213 - val_loss: 14.4821\n",
      "Epoch 579/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 12.4524 - val_loss: 14.4286\n",
      "Epoch 580/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.6054 - val_loss: 14.6145\n",
      "Epoch 581/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.4534 - val_loss: 14.4818\n",
      "Epoch 582/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4475 - val_loss: 14.4694\n",
      "Epoch 583/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.3613 - val_loss: 14.5002\n",
      "Epoch 584/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4039 - val_loss: 14.6246\n",
      "Epoch 585/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.5030 - val_loss: 14.5596\n",
      "Epoch 586/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.4670 - val_loss: 14.4277\n",
      "Epoch 587/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4345 - val_loss: 14.4499\n",
      "Epoch 588/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.6889 - val_loss: 14.6489\n",
      "Epoch 589/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.4272 - val_loss: 14.4389\n",
      "Epoch 590/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.6536 - val_loss: 14.5063\n",
      "Epoch 591/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5702 - val_loss: 14.4961\n",
      "Epoch 592/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.4958 - val_loss: 14.5595\n",
      "Epoch 593/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.5155 - val_loss: 14.5174\n",
      "Epoch 594/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4220 - val_loss: 14.5866\n",
      "Epoch 595/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5994 - val_loss: 14.4593\n",
      "Epoch 596/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.4161 - val_loss: 14.4920\n",
      "Epoch 597/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.4477 - val_loss: 14.5430\n",
      "Epoch 598/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.6828 - val_loss: 14.4900\n",
      "Epoch 599/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.6778 - val_loss: 14.5000\n",
      "Epoch 600/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4187 - val_loss: 14.4225\n",
      "Epoch 601/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.6068 - val_loss: 14.3885\n",
      "Epoch 602/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.5884 - val_loss: 14.4356\n",
      "Epoch 603/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5880 - val_loss: 14.4283\n",
      "Epoch 604/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5132 - val_loss: 14.5140\n",
      "Epoch 605/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4155 - val_loss: 14.4284\n",
      "Epoch 606/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5507 - val_loss: 14.4906\n",
      "Epoch 607/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.3818 - val_loss: 14.4163\n",
      "Epoch 608/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5497 - val_loss: 14.4935\n",
      "Epoch 609/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4900 - val_loss: 14.5558\n",
      "Epoch 610/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5432 - val_loss: 14.4739\n",
      "Epoch 611/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946/946 [==============================] - 0s 43us/step - loss: 12.5078 - val_loss: 14.4904\n",
      "Epoch 612/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4805 - val_loss: 14.3927\n",
      "Epoch 613/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.2585 - val_loss: 14.4664\n",
      "Epoch 614/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4208 - val_loss: 14.4771\n",
      "Epoch 615/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5754 - val_loss: 14.4179\n",
      "Epoch 616/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5180 - val_loss: 14.4681\n",
      "Epoch 617/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4975 - val_loss: 14.5170\n",
      "Epoch 618/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4189 - val_loss: 14.5343\n",
      "Epoch 619/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.6128 - val_loss: 14.6727\n",
      "Epoch 620/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.4153 - val_loss: 14.4525\n",
      "Epoch 621/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5346 - val_loss: 14.5240\n",
      "Epoch 622/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4472 - val_loss: 14.4981\n",
      "Epoch 623/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3367 - val_loss: 14.5059\n",
      "Epoch 624/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4208 - val_loss: 14.4842\n",
      "Epoch 625/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3390 - val_loss: 14.4990\n",
      "Epoch 626/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5144 - val_loss: 14.4293\n",
      "Epoch 627/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3579 - val_loss: 14.5272\n",
      "Epoch 628/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 12.4063 - val_loss: 14.4646\n",
      "Epoch 629/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.4552 - val_loss: 14.3327\n",
      "Epoch 630/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5082 - val_loss: 14.4525\n",
      "Epoch 631/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4355 - val_loss: 14.4052\n",
      "Epoch 632/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.3361 - val_loss: 14.3919\n",
      "Epoch 633/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5165 - val_loss: 14.6492\n",
      "Epoch 634/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.4192 - val_loss: 14.4130\n",
      "Epoch 635/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4797 - val_loss: 14.4330\n",
      "Epoch 636/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5075 - val_loss: 14.4972\n",
      "Epoch 637/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.2859 - val_loss: 14.4771\n",
      "Epoch 638/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.3947 - val_loss: 14.4396\n",
      "Epoch 639/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5680 - val_loss: 14.4598\n",
      "Epoch 640/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4523 - val_loss: 14.4855\n",
      "Epoch 641/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4984 - val_loss: 14.5184\n",
      "Epoch 642/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3940 - val_loss: 14.5299\n",
      "Epoch 643/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.4190 - val_loss: 14.4619\n",
      "Epoch 644/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.5926 - val_loss: 14.5287\n",
      "Epoch 645/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5697 - val_loss: 14.4790\n",
      "Epoch 646/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3400 - val_loss: 14.4320\n",
      "Epoch 647/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.2823 - val_loss: 14.6361\n",
      "Epoch 648/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.4899 - val_loss: 14.4394\n",
      "Epoch 649/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5797 - val_loss: 14.5830\n",
      "Epoch 650/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.6274 - val_loss: 14.4815\n",
      "Epoch 651/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5320 - val_loss: 14.4172\n",
      "Epoch 652/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.4127 - val_loss: 14.3564\n",
      "Epoch 653/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3976 - val_loss: 14.3939\n",
      "Epoch 654/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.5139 - val_loss: 14.5163\n",
      "Epoch 655/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4324 - val_loss: 14.5624\n",
      "Epoch 656/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5165 - val_loss: 14.4480\n",
      "Epoch 657/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.6489 - val_loss: 14.4831\n",
      "Epoch 658/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5094 - val_loss: 14.3796\n",
      "Epoch 659/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.5324 - val_loss: 14.5551\n",
      "Epoch 660/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3956 - val_loss: 14.5250\n",
      "Epoch 661/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.5878 - val_loss: 14.5997\n",
      "Epoch 662/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.4504 - val_loss: 14.4783\n",
      "Epoch 663/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.5093 - val_loss: 14.5191\n",
      "Epoch 664/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5245 - val_loss: 14.4162\n",
      "Epoch 665/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4548 - val_loss: 14.5137\n",
      "Epoch 666/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5614 - val_loss: 14.5394\n",
      "Epoch 667/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 12.4275 - val_loss: 14.5413\n",
      "Epoch 668/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.5355 - val_loss: 14.4180\n",
      "Epoch 669/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5164 - val_loss: 14.3990\n",
      "Epoch 670/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3593 - val_loss: 14.5493\n",
      "Epoch 671/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5233 - val_loss: 14.4052\n",
      "Epoch 672/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.5530 - val_loss: 14.5071\n",
      "Epoch 673/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.4968 - val_loss: 14.5146\n",
      "Epoch 674/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4513 - val_loss: 14.5000\n",
      "Epoch 675/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5633 - val_loss: 14.3322\n",
      "Epoch 676/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4418 - val_loss: 14.4433\n",
      "Epoch 677/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4814 - val_loss: 14.5059\n",
      "Epoch 678/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4053 - val_loss: 14.4464\n",
      "Epoch 679/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4387 - val_loss: 14.5388\n",
      "Epoch 680/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.2601 - val_loss: 14.3634\n",
      "Epoch 681/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5006 - val_loss: 14.5091\n",
      "Epoch 682/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.4346 - val_loss: 14.3888\n",
      "Epoch 683/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5430 - val_loss: 14.3991\n",
      "Epoch 684/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4297 - val_loss: 14.3866\n",
      "Epoch 685/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3796 - val_loss: 14.6140\n",
      "Epoch 686/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5189 - val_loss: 14.3594\n",
      "Epoch 687/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5154 - val_loss: 14.5383\n",
      "Epoch 688/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4253 - val_loss: 14.6732\n",
      "Epoch 689/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4063 - val_loss: 14.6261\n",
      "Epoch 690/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4736 - val_loss: 14.6005\n",
      "Epoch 691/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5632 - val_loss: 14.6228\n",
      "Epoch 692/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5376 - val_loss: 14.3603\n",
      "Epoch 693/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.6380 - val_loss: 14.4286\n",
      "Epoch 694/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5660 - val_loss: 14.4736\n",
      "Epoch 695/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3872 - val_loss: 14.4255\n",
      "Epoch 696/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4549 - val_loss: 14.4159\n",
      "Epoch 697/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4777 - val_loss: 14.4342\n",
      "Epoch 698/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3704 - val_loss: 14.4927\n",
      "Epoch 699/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5605 - val_loss: 14.3978\n",
      "Epoch 700/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5491 - val_loss: 14.4618\n",
      "Epoch 701/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.6032 - val_loss: 14.3928\n",
      "Epoch 702/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 12.4328 - val_loss: 14.4405\n",
      "Epoch 703/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4680 - val_loss: 14.4433\n",
      "Epoch 704/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.4434 - val_loss: 14.4110\n",
      "Epoch 705/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5572 - val_loss: 14.4118\n",
      "Epoch 706/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4045 - val_loss: 14.5480\n",
      "Epoch 707/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4737 - val_loss: 14.4359\n",
      "Epoch 708/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.2911 - val_loss: 14.4829\n",
      "Epoch 709/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4205 - val_loss: 14.4497\n",
      "Epoch 710/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.6388 - val_loss: 14.4941\n",
      "Epoch 711/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.3396 - val_loss: 14.4133\n",
      "Epoch 712/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5044 - val_loss: 14.4290\n",
      "Epoch 713/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 12.5066 - val_loss: 14.5545\n",
      "Epoch 714/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4549 - val_loss: 14.4706\n",
      "Epoch 715/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5483 - val_loss: 14.4947\n",
      "Epoch 716/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5314 - val_loss: 14.4094\n",
      "Epoch 717/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4607 - val_loss: 14.4172\n",
      "Epoch 718/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3051 - val_loss: 14.4631\n",
      "Epoch 719/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4222 - val_loss: 14.5591\n",
      "Epoch 720/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4521 - val_loss: 14.4065\n",
      "Epoch 721/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3452 - val_loss: 14.4199\n",
      "Epoch 722/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3221 - val_loss: 14.3487\n",
      "Epoch 723/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.5242 - val_loss: 14.4358\n",
      "Epoch 724/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.3214 - val_loss: 14.3892\n",
      "Epoch 725/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5618 - val_loss: 14.5468\n",
      "Epoch 726/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4868 - val_loss: 14.4241\n",
      "Epoch 727/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4497 - val_loss: 14.4886\n",
      "Epoch 728/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.4956 - val_loss: 14.6012\n",
      "Epoch 729/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5400 - val_loss: 14.5374\n",
      "Epoch 730/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.3853 - val_loss: 14.4392\n",
      "Epoch 731/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.3191 - val_loss: 14.3227\n",
      "Epoch 732/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3771 - val_loss: 14.3922\n",
      "Epoch 733/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4647 - val_loss: 14.4219\n",
      "Epoch 734/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5025 - val_loss: 14.4937\n",
      "Epoch 735/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.5164 - val_loss: 14.5000\n",
      "Epoch 736/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4903 - val_loss: 14.5296\n",
      "Epoch 737/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4198 - val_loss: 14.4780\n",
      "Epoch 738/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3312 - val_loss: 14.4558\n",
      "Epoch 739/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5030 - val_loss: 14.5335\n",
      "Epoch 740/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4605 - val_loss: 14.5404\n",
      "Epoch 741/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.3403 - val_loss: 14.5473\n",
      "Epoch 742/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4080 - val_loss: 14.3632\n",
      "Epoch 743/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.3217 - val_loss: 14.4142\n",
      "Epoch 744/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4071 - val_loss: 14.4394\n",
      "Epoch 745/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4435 - val_loss: 14.4658\n",
      "Epoch 746/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5581 - val_loss: 14.3414\n",
      "Epoch 747/1000\n",
      "946/946 [==============================] - 0s 52us/step - loss: 12.3838 - val_loss: 14.3161\n",
      "Epoch 748/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 12.4457 - val_loss: 14.4290\n",
      "Epoch 749/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4255 - val_loss: 14.3800\n",
      "Epoch 750/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4329 - val_loss: 14.4470\n",
      "Epoch 751/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5268 - val_loss: 14.4569\n",
      "Epoch 752/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.3759 - val_loss: 14.4366\n",
      "Epoch 753/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4595 - val_loss: 14.3772\n",
      "Epoch 754/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4285 - val_loss: 14.4542\n",
      "Epoch 755/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5649 - val_loss: 14.5008\n",
      "Epoch 756/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4692 - val_loss: 14.4955\n",
      "Epoch 757/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.2469 - val_loss: 14.4099\n",
      "Epoch 758/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5119 - val_loss: 14.4801\n",
      "Epoch 759/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5418 - val_loss: 14.4398\n",
      "Epoch 760/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.3257 - val_loss: 14.4527\n",
      "Epoch 761/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.5109 - val_loss: 14.6429\n",
      "Epoch 762/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4261 - val_loss: 14.4200\n",
      "Epoch 763/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946/946 [==============================] - 0s 41us/step - loss: 12.4719 - val_loss: 14.6889\n",
      "Epoch 764/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4768 - val_loss: 14.5002\n",
      "Epoch 765/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3843 - val_loss: 14.6342\n",
      "Epoch 766/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3322 - val_loss: 14.4082\n",
      "Epoch 767/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3527 - val_loss: 14.3852\n",
      "Epoch 768/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5110 - val_loss: 14.5138\n",
      "Epoch 769/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.1502 - val_loss: 14.3161\n",
      "Epoch 770/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3296 - val_loss: 14.4754\n",
      "Epoch 771/1000\n",
      "946/946 [==============================] - 0s 52us/step - loss: 12.4023 - val_loss: 14.3887\n",
      "Epoch 772/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3670 - val_loss: 14.4174\n",
      "Epoch 773/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5289 - val_loss: 14.3718\n",
      "Epoch 774/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3206 - val_loss: 14.3780\n",
      "Epoch 775/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4345 - val_loss: 14.4245\n",
      "Epoch 776/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.4011 - val_loss: 14.3563\n",
      "Epoch 777/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.2917 - val_loss: 14.5882\n",
      "Epoch 778/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4959 - val_loss: 14.3660\n",
      "Epoch 779/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.3220 - val_loss: 14.4439\n",
      "Epoch 780/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.3868 - val_loss: 14.5445\n",
      "Epoch 781/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.3393 - val_loss: 14.3938\n",
      "Epoch 782/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.3813 - val_loss: 14.4800\n",
      "Epoch 783/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4770 - val_loss: 14.4358\n",
      "Epoch 784/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.5890 - val_loss: 14.4204\n",
      "Epoch 785/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.3072 - val_loss: 14.3983\n",
      "Epoch 786/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4482 - val_loss: 14.3357\n",
      "Epoch 787/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5935 - val_loss: 14.4855\n",
      "Epoch 788/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4941 - val_loss: 14.3742\n",
      "Epoch 789/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5774 - val_loss: 14.4039\n",
      "Epoch 790/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.4166 - val_loss: 14.4420\n",
      "Epoch 791/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.6202 - val_loss: 14.6063\n",
      "Epoch 792/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5421 - val_loss: 14.4459\n",
      "Epoch 793/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3732 - val_loss: 14.4500\n",
      "Epoch 794/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4178 - val_loss: 14.4380\n",
      "Epoch 795/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.3843 - val_loss: 14.4654\n",
      "Epoch 796/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4465 - val_loss: 14.2962\n",
      "Epoch 797/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4273 - val_loss: 14.3976\n",
      "Epoch 798/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.4323 - val_loss: 14.3451\n",
      "Epoch 799/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3884 - val_loss: 14.5410\n",
      "Epoch 800/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5582 - val_loss: 14.4800\n",
      "Epoch 801/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5152 - val_loss: 14.4624\n",
      "Epoch 802/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4148 - val_loss: 14.4561\n",
      "Epoch 803/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.4866 - val_loss: 14.3956\n",
      "Epoch 804/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5546 - val_loss: 14.4237\n",
      "Epoch 805/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3662 - val_loss: 14.3617\n",
      "Epoch 806/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.3887 - val_loss: 14.4602\n",
      "Epoch 807/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3421 - val_loss: 14.5772\n",
      "Epoch 808/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.4660 - val_loss: 14.3129\n",
      "Epoch 809/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4713 - val_loss: 14.4014\n",
      "Epoch 810/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4426 - val_loss: 14.3847\n",
      "Epoch 811/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3850 - val_loss: 14.3984\n",
      "Epoch 812/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3776 - val_loss: 14.4508\n",
      "Epoch 813/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3737 - val_loss: 14.6668\n",
      "Epoch 814/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.4900 - val_loss: 14.4403\n",
      "Epoch 815/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4370 - val_loss: 14.5049\n",
      "Epoch 816/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.4820 - val_loss: 14.3405\n",
      "Epoch 817/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.2867 - val_loss: 14.5493\n",
      "Epoch 818/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.4295 - val_loss: 14.5790\n",
      "Epoch 819/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.4311 - val_loss: 14.4114\n",
      "Epoch 820/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.4870 - val_loss: 14.4381\n",
      "Epoch 821/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4807 - val_loss: 14.5043\n",
      "Epoch 822/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4258 - val_loss: 14.5207\n",
      "Epoch 823/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3333 - val_loss: 14.5951\n",
      "Epoch 824/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3328 - val_loss: 14.3903\n",
      "Epoch 825/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4616 - val_loss: 14.5810\n",
      "Epoch 826/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.3363 - val_loss: 14.4444\n",
      "Epoch 827/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3467 - val_loss: 14.4254\n",
      "Epoch 828/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4186 - val_loss: 14.4378\n",
      "Epoch 829/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.2901 - val_loss: 14.6327\n",
      "Epoch 830/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.3602 - val_loss: 14.3499\n",
      "Epoch 831/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.3735 - val_loss: 14.3335\n",
      "Epoch 832/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.3594 - val_loss: 14.5010\n",
      "Epoch 833/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.3599 - val_loss: 14.3252\n",
      "Epoch 834/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.3285 - val_loss: 14.3702\n",
      "Epoch 835/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.6005 - val_loss: 14.4885\n",
      "Epoch 836/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5141 - val_loss: 14.5038\n",
      "Epoch 837/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5588 - val_loss: 14.3952\n",
      "Epoch 838/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4237 - val_loss: 14.4637\n",
      "Epoch 839/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.3466 - val_loss: 14.3705\n",
      "Epoch 840/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4291 - val_loss: 14.4397\n",
      "Epoch 841/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4813 - val_loss: 14.3905\n",
      "Epoch 842/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.3347 - val_loss: 14.3917\n",
      "Epoch 843/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5546 - val_loss: 14.4752\n",
      "Epoch 844/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.5397 - val_loss: 14.3569\n",
      "Epoch 845/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4917 - val_loss: 14.4827\n",
      "Epoch 846/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.3151 - val_loss: 14.4599\n",
      "Epoch 847/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.4181 - val_loss: 14.4459\n",
      "Epoch 848/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4443 - val_loss: 14.5155\n",
      "Epoch 849/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4160 - val_loss: 14.5773\n",
      "Epoch 850/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.4587 - val_loss: 14.3743\n",
      "Epoch 851/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4268 - val_loss: 14.4814\n",
      "Epoch 852/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4777 - val_loss: 14.3869\n",
      "Epoch 853/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5969 - val_loss: 14.4180\n",
      "Epoch 854/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.3990 - val_loss: 14.3350\n",
      "Epoch 855/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4767 - val_loss: 14.3622\n",
      "Epoch 856/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3409 - val_loss: 14.3910\n",
      "Epoch 857/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4222 - val_loss: 14.3966\n",
      "Epoch 858/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3675 - val_loss: 14.5586\n",
      "Epoch 859/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5070 - val_loss: 14.4450\n",
      "Epoch 860/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.2889 - val_loss: 14.3207\n",
      "Epoch 861/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.3864 - val_loss: 14.3574\n",
      "Epoch 862/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3134 - val_loss: 14.3844\n",
      "Epoch 863/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.2013 - val_loss: 14.5798\n",
      "Epoch 864/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4109 - val_loss: 14.3336\n",
      "Epoch 865/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5387 - val_loss: 14.4636\n",
      "Epoch 866/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.3375 - val_loss: 14.4585\n",
      "Epoch 867/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5807 - val_loss: 14.3889\n",
      "Epoch 868/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.5107 - val_loss: 14.4493\n",
      "Epoch 869/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3895 - val_loss: 14.5378\n",
      "Epoch 870/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5239 - val_loss: 14.3841\n",
      "Epoch 871/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3690 - val_loss: 14.4342\n",
      "Epoch 872/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4130 - val_loss: 14.5084\n",
      "Epoch 873/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.2801 - val_loss: 14.4508\n",
      "Epoch 874/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.3692 - val_loss: 14.3888\n",
      "Epoch 875/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.3719 - val_loss: 14.5210\n",
      "Epoch 876/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.3800 - val_loss: 14.4593\n",
      "Epoch 877/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.3824 - val_loss: 14.4340\n",
      "Epoch 878/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.2255 - val_loss: 14.4880\n",
      "Epoch 879/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3737 - val_loss: 14.3610\n",
      "Epoch 880/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5210 - val_loss: 14.4820\n",
      "Epoch 881/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5262 - val_loss: 14.5717\n",
      "Epoch 882/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.6383 - val_loss: 14.4460\n",
      "Epoch 883/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.4477 - val_loss: 14.5026\n",
      "Epoch 884/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5180 - val_loss: 14.3969\n",
      "Epoch 885/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4880 - val_loss: 14.5123\n",
      "Epoch 886/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4018 - val_loss: 14.5270\n",
      "Epoch 887/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.4070 - val_loss: 14.5278\n",
      "Epoch 888/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4953 - val_loss: 14.4621\n",
      "Epoch 889/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.3305 - val_loss: 14.3389\n",
      "Epoch 890/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.4302 - val_loss: 14.4722\n",
      "Epoch 891/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.2937 - val_loss: 14.4132\n",
      "Epoch 892/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.3163 - val_loss: 14.3808\n",
      "Epoch 893/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3498 - val_loss: 14.4187\n",
      "Epoch 894/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4020 - val_loss: 14.4964\n",
      "Epoch 895/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.5280 - val_loss: 14.4143\n",
      "Epoch 896/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5037 - val_loss: 14.4561\n",
      "Epoch 897/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3970 - val_loss: 14.4610\n",
      "Epoch 898/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3415 - val_loss: 14.4071\n",
      "Epoch 899/1000\n",
      "946/946 [==============================] - 0s 36us/step - loss: 12.5316 - val_loss: 14.4877\n",
      "Epoch 900/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.2735 - val_loss: 14.4499\n",
      "Epoch 901/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.3539 - val_loss: 14.5172\n",
      "Epoch 902/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3741 - val_loss: 14.3713\n",
      "Epoch 903/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.3533 - val_loss: 14.4049\n",
      "Epoch 904/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4812 - val_loss: 14.5381\n",
      "Epoch 905/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.4190 - val_loss: 14.3869\n",
      "Epoch 906/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3350 - val_loss: 14.4496\n",
      "Epoch 907/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4763 - val_loss: 14.4289\n",
      "Epoch 908/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.1388 - val_loss: 14.4616\n",
      "Epoch 909/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4780 - val_loss: 14.4019\n",
      "Epoch 910/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4272 - val_loss: 14.3598\n",
      "Epoch 911/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4427 - val_loss: 14.4850\n",
      "Epoch 912/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.3236 - val_loss: 14.3536\n",
      "Epoch 913/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5213 - val_loss: 14.4934\n",
      "Epoch 914/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4869 - val_loss: 14.3092\n",
      "Epoch 915/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946/946 [==============================] - 0s 46us/step - loss: 12.3515 - val_loss: 14.3403\n",
      "Epoch 916/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.4157 - val_loss: 14.4658\n",
      "Epoch 917/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.2397 - val_loss: 14.4499\n",
      "Epoch 918/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.4532 - val_loss: 14.5633\n",
      "Epoch 919/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5570 - val_loss: 14.5661\n",
      "Epoch 920/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4765 - val_loss: 14.4631\n",
      "Epoch 921/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3003 - val_loss: 14.4278\n",
      "Epoch 922/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.4688 - val_loss: 14.3681\n",
      "Epoch 923/1000\n",
      "946/946 [==============================] - 0s 69us/step - loss: 12.3207 - val_loss: 14.4481\n",
      "Epoch 924/1000\n",
      "946/946 [==============================] - 0s 86us/step - loss: 12.3751 - val_loss: 14.3478\n",
      "Epoch 925/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5680 - val_loss: 14.3299\n",
      "Epoch 926/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4215 - val_loss: 14.4465\n",
      "Epoch 927/1000\n",
      "946/946 [==============================] - 0s 53us/step - loss: 12.3049 - val_loss: 14.3716\n",
      "Epoch 928/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4360 - val_loss: 14.5272\n",
      "Epoch 929/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4038 - val_loss: 14.4687\n",
      "Epoch 930/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.3756 - val_loss: 14.5122\n",
      "Epoch 931/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4532 - val_loss: 14.3707\n",
      "Epoch 932/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 12.3282 - val_loss: 14.4497\n",
      "Epoch 933/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3483 - val_loss: 14.4198\n",
      "Epoch 934/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.6007 - val_loss: 14.3671\n",
      "Epoch 935/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3291 - val_loss: 14.4904\n",
      "Epoch 936/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4481 - val_loss: 14.4671\n",
      "Epoch 937/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.2645 - val_loss: 14.3323\n",
      "Epoch 938/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.3126 - val_loss: 14.3639\n",
      "Epoch 939/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5106 - val_loss: 14.4150\n",
      "Epoch 940/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3761 - val_loss: 14.3680\n",
      "Epoch 941/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 12.2724 - val_loss: 14.3255\n",
      "Epoch 942/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4267 - val_loss: 14.3215\n",
      "Epoch 943/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.2993 - val_loss: 14.4518\n",
      "Epoch 944/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3258 - val_loss: 14.3488\n",
      "Epoch 945/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4182 - val_loss: 14.5146\n",
      "Epoch 946/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.4661 - val_loss: 14.4022\n",
      "Epoch 947/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.2808 - val_loss: 14.3789\n",
      "Epoch 948/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.4019 - val_loss: 14.3994\n",
      "Epoch 949/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.2852 - val_loss: 14.4751\n",
      "Epoch 950/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.2881 - val_loss: 14.3997\n",
      "Epoch 951/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.3939 - val_loss: 14.3279\n",
      "Epoch 952/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.4782 - val_loss: 14.4230\n",
      "Epoch 953/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.2866 - val_loss: 14.4291\n",
      "Epoch 954/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5163 - val_loss: 14.3904\n",
      "Epoch 955/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.5526 - val_loss: 14.3958\n",
      "Epoch 956/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4696 - val_loss: 14.4339\n",
      "Epoch 957/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.5993 - val_loss: 14.4883\n",
      "Epoch 958/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5807 - val_loss: 14.4726\n",
      "Epoch 959/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4968 - val_loss: 14.4047\n",
      "Epoch 960/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3907 - val_loss: 14.4774\n",
      "Epoch 961/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.3466 - val_loss: 14.3720\n",
      "Epoch 962/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3650 - val_loss: 14.4634\n",
      "Epoch 963/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3306 - val_loss: 14.3151\n",
      "Epoch 964/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.3403 - val_loss: 14.4156\n",
      "Epoch 965/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.3617 - val_loss: 14.3699\n",
      "Epoch 966/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5120 - val_loss: 14.4960\n",
      "Epoch 967/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4061 - val_loss: 14.4493\n",
      "Epoch 968/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.2947 - val_loss: 14.6195\n",
      "Epoch 969/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.3251 - val_loss: 14.2750\n",
      "Epoch 970/1000\n",
      "946/946 [==============================] - 0s 70us/step - loss: 12.3814 - val_loss: 14.4833\n",
      "Epoch 971/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.2165 - val_loss: 14.3381\n",
      "Epoch 972/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.3385 - val_loss: 14.5752\n",
      "Epoch 973/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5610 - val_loss: 14.3764\n",
      "Epoch 974/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4174 - val_loss: 14.4897\n",
      "Epoch 975/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4529 - val_loss: 14.3754\n",
      "Epoch 976/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.3647 - val_loss: 14.3584\n",
      "Epoch 977/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.3720 - val_loss: 14.3867\n",
      "Epoch 978/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4962 - val_loss: 14.3773\n",
      "Epoch 979/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.3644 - val_loss: 14.3723\n",
      "Epoch 980/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.1633 - val_loss: 14.4279\n",
      "Epoch 981/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.2920 - val_loss: 14.4595\n",
      "Epoch 982/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.4465 - val_loss: 14.4065\n",
      "Epoch 983/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5342 - val_loss: 14.4518\n",
      "Epoch 984/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3060 - val_loss: 14.3511\n",
      "Epoch 985/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3414 - val_loss: 14.7024\n",
      "Epoch 986/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.4205 - val_loss: 14.4538\n",
      "Epoch 987/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.3122 - val_loss: 14.4716\n",
      "Epoch 988/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4216 - val_loss: 14.3800\n",
      "Epoch 989/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5709 - val_loss: 14.3796\n",
      "Epoch 990/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4778 - val_loss: 14.4265\n",
      "Epoch 991/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.4436 - val_loss: 14.3864\n",
      "Epoch 992/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5139 - val_loss: 14.3684\n",
      "Epoch 993/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.3563 - val_loss: 14.4999\n",
      "Epoch 994/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 12.3636 - val_loss: 14.3346\n",
      "Epoch 995/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.5316 - val_loss: 14.3193\n",
      "Epoch 996/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.2919 - val_loss: 14.3615\n",
      "Epoch 997/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.4816 - val_loss: 14.4389\n",
      "Epoch 998/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4932 - val_loss: 14.3267\n",
      "Epoch 999/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 12.3790 - val_loss: 14.3617\n",
      "Epoch 1000/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 12.5190 - val_loss: 14.3208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a273bd5f8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs: 1000\n",
    "# val_loss: 13.937765464933692\n",
    "# regularization: <function l1 at 0x1a25311bf8> \n",
    "# lambda: 0.005\n",
    "# dropout: 0.25\n",
    "# hidden layers: 0\n",
    "\n",
    "network = Sequential()\n",
    "\n",
    "\n",
    "network.add(Dense(units=Xs_train.shape[1],\n",
    "                  activation=\"relu\",\n",
    "                  input_dim=Xs_train.shape[1],\n",
    "                  kernel_regularizer=regularizers.l1(.005)))\n",
    "network.add(Dropout(.25))\n",
    "\n",
    "\n",
    "network.add(Dense(units=1,\n",
    "                  activation=None,\n",
    "                  kernel_regularizer=regularizers.l1(.005)))\n",
    "\n",
    "network.compile(loss=\"mean_absolute_error\", optimizer=\"adam\")\n",
    "\n",
    "network.fit(Xs_train, y_train, validation_data=(Xs_test, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "nn_opt_params_1 = pred_maker(test, network, \"nn_opt_params_1.csv\", polyfunc=pf, scalerfunc=ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE = 28.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. second parameter optimization NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_feats = [x for x in train.columns if x != target]\n",
    "X_reg = train[reg_feats]\n",
    "y_reg = train[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(X_reg, y_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss2 = StandardScaler()\n",
    "Xrs_train = ss2.fit_transform(Xr_train)\n",
    "Xrs_test = ss2.transform(Xr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 946 samples, validate on 316 samples\n",
      "Epoch 1/1000\n",
      "946/946 [==============================] - 1s 696us/step - loss: 19.0524 - val_loss: 18.3230\n",
      "Epoch 2/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 16.3430 - val_loss: 15.4132\n",
      "Epoch 3/1000\n",
      "946/946 [==============================] - 0s 60us/step - loss: 14.8265 - val_loss: 14.6781\n",
      "Epoch 4/1000\n",
      "946/946 [==============================] - 0s 66us/step - loss: 14.3136 - val_loss: 14.4659\n",
      "Epoch 5/1000\n",
      "946/946 [==============================] - 0s 79us/step - loss: 14.1469 - val_loss: 14.2781\n",
      "Epoch 6/1000\n",
      "946/946 [==============================] - 0s 68us/step - loss: 14.0970 - val_loss: 14.2523\n",
      "Epoch 7/1000\n",
      "946/946 [==============================] - 0s 57us/step - loss: 13.8178 - val_loss: 14.1522\n",
      "Epoch 8/1000\n",
      "946/946 [==============================] - 0s 52us/step - loss: 13.7763 - val_loss: 13.9985\n",
      "Epoch 9/1000\n",
      "946/946 [==============================] - 0s 54us/step - loss: 13.7734 - val_loss: 13.9522\n",
      "Epoch 10/1000\n",
      "946/946 [==============================] - 0s 52us/step - loss: 13.5520 - val_loss: 13.9703\n",
      "Epoch 11/1000\n",
      "946/946 [==============================] - 0s 53us/step - loss: 13.5762 - val_loss: 13.8842\n",
      "Epoch 12/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 13.4958 - val_loss: 13.7810\n",
      "Epoch 13/1000\n",
      "946/946 [==============================] - 0s 51us/step - loss: 13.4340 - val_loss: 13.6753\n",
      "Epoch 14/1000\n",
      "946/946 [==============================] - 0s 66us/step - loss: 13.3138 - val_loss: 13.5801\n",
      "Epoch 15/1000\n",
      "946/946 [==============================] - 0s 58us/step - loss: 13.2697 - val_loss: 13.6171\n",
      "Epoch 16/1000\n",
      "946/946 [==============================] - 0s 67us/step - loss: 13.3695 - val_loss: 13.5540\n",
      "Epoch 17/1000\n",
      "946/946 [==============================] - 0s 61us/step - loss: 13.3032 - val_loss: 13.4759\n",
      "Epoch 18/1000\n",
      "946/946 [==============================] - 0s 53us/step - loss: 13.2399 - val_loss: 13.4478\n",
      "Epoch 19/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 13.2713 - val_loss: 13.4451\n",
      "Epoch 20/1000\n",
      "946/946 [==============================] - 0s 49us/step - loss: 13.2691 - val_loss: 13.3404\n",
      "Epoch 21/1000\n",
      "946/946 [==============================] - 0s 52us/step - loss: 13.1764 - val_loss: 13.3866\n",
      "Epoch 22/1000\n",
      "946/946 [==============================] - 0s 52us/step - loss: 12.9584 - val_loss: 13.3272\n",
      "Epoch 23/1000\n",
      "946/946 [==============================] - 0s 60us/step - loss: 12.9489 - val_loss: 13.2701\n",
      "Epoch 24/1000\n",
      "946/946 [==============================] - 0s 67us/step - loss: 13.0733 - val_loss: 13.2359\n",
      "Epoch 25/1000\n",
      "946/946 [==============================] - 0s 68us/step - loss: 12.8486 - val_loss: 13.2531\n",
      "Epoch 26/1000\n",
      "946/946 [==============================] - 0s 55us/step - loss: 13.0116 - val_loss: 13.2146\n",
      "Epoch 27/1000\n",
      "946/946 [==============================] - 0s 52us/step - loss: 12.9934 - val_loss: 13.2309\n",
      "Epoch 28/1000\n",
      "946/946 [==============================] - 0s 53us/step - loss: 13.0470 - val_loss: 13.2955\n",
      "Epoch 29/1000\n",
      "946/946 [==============================] - 0s 48us/step - loss: 12.8552 - val_loss: 13.1835\n",
      "Epoch 30/1000\n",
      "946/946 [==============================] - 0s 53us/step - loss: 12.8282 - val_loss: 13.2118\n",
      "Epoch 31/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 13.0318 - val_loss: 13.1371\n",
      "Epoch 32/1000\n",
      "946/946 [==============================] - 0s 52us/step - loss: 12.6937 - val_loss: 13.1422\n",
      "Epoch 33/1000\n",
      "946/946 [==============================] - 0s 58us/step - loss: 12.8929 - val_loss: 13.0859\n",
      "Epoch 34/1000\n",
      "946/946 [==============================] - 0s 67us/step - loss: 12.7374 - val_loss: 13.0525\n",
      "Epoch 35/1000\n",
      "946/946 [==============================] - 0s 73us/step - loss: 12.8725 - val_loss: 13.1078\n",
      "Epoch 36/1000\n",
      "946/946 [==============================] - 0s 80us/step - loss: 12.8775 - val_loss: 13.1027\n",
      "Epoch 37/1000\n",
      "946/946 [==============================] - 0s 61us/step - loss: 12.8454 - val_loss: 13.0282\n",
      "Epoch 38/1000\n",
      "946/946 [==============================] - 0s 55us/step - loss: 12.8028 - val_loss: 12.9822\n",
      "Epoch 39/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 12.8173 - val_loss: 13.0338\n",
      "Epoch 40/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 12.6605 - val_loss: 13.1036\n",
      "Epoch 41/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 12.7057 - val_loss: 13.0281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2cae21d0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs: 35\n",
    "# val_loss: 11.697192295245571\n",
    "# ???: <keras.regularizers.L1L2 object at 0x1a2bf693c8> \n",
    "# Dropout: 0.15\n",
    "# Hidden Layers: 1\n",
    "# Hidden Nodes: 150\n",
    "# max epochs: 1000\n",
    "\n",
    "network2 = Sequential()\n",
    "\n",
    "network2.add(Dense(units=Xrs_train.shape[1],\n",
    "                   activation=\"relu\",\n",
    "                   input_dim=Xrs_train.shape[1],\n",
    "                   kernel_regularizer=regularizers.l2(.001)))\n",
    "network2.add(Dropout(.15))\n",
    "\n",
    "network2.add(Dense(units=150,\n",
    "                   activation=\"relu\",\n",
    "                   kernel_regularizer=regularizers.l2(.001)))\n",
    "network2.add(Dropout(.15))\n",
    "\n",
    "network2.add(Dense(units=1,\n",
    "                   activation=None,\n",
    "                   kernel_regularizer=regularizers.l2(.001)))\n",
    "\n",
    "network2.compile(loss=\"mean_absolute_error\", optimizer=\"adam\")\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=3)\n",
    "\n",
    "network2.fit(Xrs_train, yr_train, validation_data=(Xrs_test, yr_test), epochs=1000, callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "nn_opt_params_2 = pred_maker(test, network2, \"nn_earlystop_no_poly_optp2.csv\", polyfunc=None, scalerfunc=ss2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE: 31.2 WHYYYYYYYYYYYYYY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. third parameter optimization NN (poly weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 946 samples, validate on 316 samples\n",
      "Epoch 1/1000\n",
      "946/946 [==============================] - 1s 1ms/step - loss: 17.0638 - val_loss: 16.8380\n",
      "Epoch 2/1000\n",
      "946/946 [==============================] - 0s 80us/step - loss: 14.5537 - val_loss: 16.5694\n",
      "Epoch 3/1000\n",
      "946/946 [==============================] - 0s 101us/step - loss: 14.1411 - val_loss: 16.1245\n",
      "Epoch 4/1000\n",
      "946/946 [==============================] - 0s 78us/step - loss: 14.1904 - val_loss: 16.0366\n",
      "Epoch 5/1000\n",
      "946/946 [==============================] - 0s 96us/step - loss: 13.7776 - val_loss: 16.0704\n",
      "Epoch 6/1000\n",
      "946/946 [==============================] - 0s 98us/step - loss: 13.5247 - val_loss: 15.9729\n",
      "Epoch 7/1000\n",
      "946/946 [==============================] - 0s 89us/step - loss: 13.3585 - val_loss: 15.9440\n",
      "Epoch 8/1000\n",
      "946/946 [==============================] - 0s 83us/step - loss: 13.3030 - val_loss: 15.6194\n",
      "Epoch 9/1000\n",
      "946/946 [==============================] - 0s 86us/step - loss: 13.3495 - val_loss: 15.3340\n",
      "Epoch 10/1000\n",
      "946/946 [==============================] - 0s 78us/step - loss: 13.2368 - val_loss: 15.2850\n",
      "Epoch 11/1000\n",
      "946/946 [==============================] - 0s 78us/step - loss: 13.1062 - val_loss: 15.4374\n",
      "Epoch 12/1000\n",
      "946/946 [==============================] - 0s 84us/step - loss: 13.0263 - val_loss: 15.2345\n",
      "Epoch 13/1000\n",
      "946/946 [==============================] - 0s 91us/step - loss: 12.9739 - val_loss: 15.2019\n",
      "Epoch 14/1000\n",
      "946/946 [==============================] - 0s 80us/step - loss: 13.0354 - val_loss: 15.3468\n",
      "Epoch 15/1000\n",
      "946/946 [==============================] - 0s 83us/step - loss: 13.0471 - val_loss: 15.4334\n",
      "Epoch 16/1000\n",
      "946/946 [==============================] - 0s 92us/step - loss: 12.7363 - val_loss: 15.2837\n",
      "Epoch 17/1000\n",
      "946/946 [==============================] - 0s 85us/step - loss: 12.8089 - val_loss: 15.1745\n",
      "Epoch 18/1000\n",
      "946/946 [==============================] - 0s 84us/step - loss: 12.6988 - val_loss: 14.7723\n",
      "Epoch 19/1000\n",
      "946/946 [==============================] - 0s 85us/step - loss: 12.6062 - val_loss: 14.8805\n",
      "Epoch 20/1000\n",
      "946/946 [==============================] - 0s 82us/step - loss: 12.6691 - val_loss: 14.6375\n",
      "Epoch 21/1000\n",
      "946/946 [==============================] - 0s 78us/step - loss: 12.6125 - val_loss: 14.8088\n",
      "Epoch 22/1000\n",
      "946/946 [==============================] - 0s 87us/step - loss: 12.5910 - val_loss: 14.9898\n",
      "Epoch 23/1000\n",
      "946/946 [==============================] - 0s 83us/step - loss: 12.5182 - val_loss: 14.8533\n",
      "Epoch 24/1000\n",
      "946/946 [==============================] - 0s 78us/step - loss: 12.5168 - val_loss: 14.7233\n",
      "Epoch 25/1000\n",
      "946/946 [==============================] - 0s 85us/step - loss: 12.5415 - val_loss: 14.7661\n",
      "Epoch 26/1000\n",
      "946/946 [==============================] - 0s 83us/step - loss: 12.4005 - val_loss: 14.6163\n",
      "Epoch 27/1000\n",
      "946/946 [==============================] - 0s 97us/step - loss: 12.2433 - val_loss: 14.6466\n",
      "Epoch 28/1000\n",
      "946/946 [==============================] - 0s 85us/step - loss: 12.5941 - val_loss: 14.7337\n",
      "Epoch 29/1000\n",
      "946/946 [==============================] - 0s 93us/step - loss: 12.3270 - val_loss: 14.4318\n",
      "Epoch 30/1000\n",
      "946/946 [==============================] - 0s 85us/step - loss: 12.1333 - val_loss: 14.5694\n",
      "Epoch 31/1000\n",
      "946/946 [==============================] - 0s 92us/step - loss: 12.0280 - val_loss: 14.4838\n",
      "Epoch 32/1000\n",
      "946/946 [==============================] - 0s 81us/step - loss: 12.1230 - val_loss: 14.7240\n",
      "Epoch 33/1000\n",
      "946/946 [==============================] - 0s 78us/step - loss: 12.0807 - val_loss: 14.6271\n",
      "Epoch 34/1000\n",
      "946/946 [==============================] - 0s 84us/step - loss: 12.3627 - val_loss: 14.4779\n",
      "Epoch 35/1000\n",
      "946/946 [==============================] - 0s 102us/step - loss: 12.0988 - val_loss: 14.4070\n",
      "Epoch 36/1000\n",
      "946/946 [==============================] - 0s 91us/step - loss: 11.9309 - val_loss: 14.7140\n",
      "Epoch 37/1000\n",
      "946/946 [==============================] - 0s 83us/step - loss: 12.1297 - val_loss: 14.7161\n",
      "Epoch 38/1000\n",
      "946/946 [==============================] - 0s 80us/step - loss: 11.9219 - val_loss: 14.4715\n",
      "Epoch 39/1000\n",
      "946/946 [==============================] - 0s 74us/step - loss: 12.0333 - val_loss: 14.5215\n",
      "Epoch 40/1000\n",
      "946/946 [==============================] - 0s 86us/step - loss: 11.8854 - val_loss: 14.5325\n",
      "Epoch 41/1000\n",
      "946/946 [==============================] - 0s 93us/step - loss: 12.2777 - val_loss: 14.5401\n",
      "Epoch 42/1000\n",
      "946/946 [==============================] - 0s 83us/step - loss: 11.8104 - val_loss: 14.4830\n",
      "Epoch 43/1000\n",
      "946/946 [==============================] - 0s 85us/step - loss: 12.1399 - val_loss: 14.3764\n",
      "Epoch 44/1000\n",
      "946/946 [==============================] - 0s 91us/step - loss: 11.9377 - val_loss: 14.7521\n",
      "Epoch 45/1000\n",
      "946/946 [==============================] - 0s 77us/step - loss: 11.6304 - val_loss: 14.1014\n",
      "Epoch 46/1000\n",
      "946/946 [==============================] - 0s 79us/step - loss: 11.6133 - val_loss: 14.6303\n",
      "Epoch 47/1000\n",
      "946/946 [==============================] - 0s 81us/step - loss: 11.8125 - val_loss: 14.1433\n",
      "Epoch 48/1000\n",
      "946/946 [==============================] - 0s 80us/step - loss: 11.6900 - val_loss: 14.1075\n",
      "Epoch 49/1000\n",
      "946/946 [==============================] - 0s 85us/step - loss: 11.6029 - val_loss: 14.5680\n",
      "Epoch 50/1000\n",
      "946/946 [==============================] - 0s 84us/step - loss: 11.6587 - val_loss: 14.1162\n",
      "Epoch 51/1000\n",
      "946/946 [==============================] - 0s 89us/step - loss: 11.6390 - val_loss: 14.2199\n",
      "Epoch 52/1000\n",
      "946/946 [==============================] - 0s 86us/step - loss: 11.5048 - val_loss: 14.1140\n",
      "Epoch 53/1000\n",
      "946/946 [==============================] - 0s 87us/step - loss: 11.4365 - val_loss: 14.2902\n",
      "Epoch 54/1000\n",
      "946/946 [==============================] - 0s 86us/step - loss: 11.6092 - val_loss: 14.1939\n",
      "Epoch 55/1000\n",
      "946/946 [==============================] - 0s 76us/step - loss: 11.3620 - val_loss: 14.1971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a30411048>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs: 39\n",
    "# val_loss: 13.14453761118383\n",
    "# regularizer: <keras.regularizers.L1L2 object at 0x1a2c8a1198>\n",
    "# dropout: 0.15\n",
    "# hidden layers: 2\n",
    "# hidden nodes: 75\n",
    "# epochs: 1000\n",
    "# patience: 10\n",
    "\n",
    "network3 = Sequential()\n",
    "\n",
    "network3.add(Dense(units=Xs_train.shape[1],\n",
    "                   activation=\"relu\",\n",
    "                   input_dim=Xs_train.shape[1],\n",
    "                   kernel_regularizer=regularizers.l2(.001)))\n",
    "network3.add(Dropout(.15))\n",
    "\n",
    "\n",
    "network3.add(Dense(units=75,\n",
    "                   activation=\"relu\",\n",
    "                   kernel_regularizer=regularizers.l2(.001)))\n",
    "network3.add(Dropout(.15))\n",
    "\n",
    "\n",
    "network3.add(Dense(units=75,\n",
    "                   activation=\"relu\",\n",
    "                   kernel_regularizer=regularizers.l2(.001)))\n",
    "network3.add(Dropout(.15))\n",
    "\n",
    "\n",
    "network3.add(Dense(units=1,\n",
    "                   activation=None,\n",
    "                   kernel_regularizer=regularizers.l2(.001)))\n",
    "\n",
    "network3.compile(loss=\"mean_absolute_error\", optimizer=\"adam\")\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=10)\n",
    "\n",
    "network3.fit(Xs_train, y_train, validation_data=(Xs_test, y_test), epochs=1000, callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "nn_opt_params_3 = pred_maker(test, network3, \"nn_earlystop_with_poly_optp3.csv\", polyfunc=pf, scalerfunc=ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE = 29.8438"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. just trying to tune randomly. L1, early drop, no poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 946 samples, validate on 316 samples\n",
      "Epoch 1/1000\n",
      "946/946 [==============================] - 0s 396us/step - loss: 20.1055 - val_loss: 20.3821\n",
      "Epoch 2/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 17.9574 - val_loss: 17.7281\n",
      "Epoch 3/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 15.6832 - val_loss: 15.8402\n",
      "Epoch 4/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 14.6378 - val_loss: 15.5679\n",
      "Epoch 5/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 14.4165 - val_loss: 15.3799\n",
      "Epoch 6/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 14.4457 - val_loss: 15.2206\n",
      "Epoch 7/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 14.1920 - val_loss: 15.1485\n",
      "Epoch 8/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 14.1148 - val_loss: 15.0341\n",
      "Epoch 9/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 13.9714 - val_loss: 14.9364\n",
      "Epoch 10/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 13.8468 - val_loss: 14.8645\n",
      "Epoch 11/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.7627 - val_loss: 14.8247\n",
      "Epoch 12/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 13.6864 - val_loss: 14.7523\n",
      "Epoch 13/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 13.6691 - val_loss: 14.6761\n",
      "Epoch 14/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 13.5641 - val_loss: 14.6201\n",
      "Epoch 15/1000\n",
      "946/946 [==============================] - 0s 53us/step - loss: 13.6900 - val_loss: 14.5697\n",
      "Epoch 16/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 13.5890 - val_loss: 14.5093\n",
      "Epoch 17/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 13.5732 - val_loss: 14.5112\n",
      "Epoch 18/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.3090 - val_loss: 14.4584\n",
      "Epoch 19/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 13.4082 - val_loss: 14.4274\n",
      "Epoch 20/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 13.4341 - val_loss: 14.4012\n",
      "Epoch 21/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 13.3466 - val_loss: 14.3747\n",
      "Epoch 22/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 13.2837 - val_loss: 14.3483\n",
      "Epoch 23/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 13.3800 - val_loss: 14.3005\n",
      "Epoch 24/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.4147 - val_loss: 14.2451\n",
      "Epoch 25/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 13.3316 - val_loss: 14.2230\n",
      "Epoch 26/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 13.1421 - val_loss: 14.2009\n",
      "Epoch 27/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 13.3061 - val_loss: 14.1895\n",
      "Epoch 28/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.1641 - val_loss: 14.1576\n",
      "Epoch 29/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 13.3110 - val_loss: 14.1372\n",
      "Epoch 30/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 13.2736 - val_loss: 14.1014\n",
      "Epoch 31/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 13.2688 - val_loss: 14.0717\n",
      "Epoch 32/1000\n",
      "946/946 [==============================] - 0s 45us/step - loss: 13.2237 - val_loss: 14.0567\n",
      "Epoch 33/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 13.0873 - val_loss: 14.0488\n",
      "Epoch 34/1000\n",
      "946/946 [==============================] - 0s 47us/step - loss: 13.1507 - val_loss: 14.0258\n",
      "Epoch 35/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 13.0233 - val_loss: 14.0203\n",
      "Epoch 36/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 13.1399 - val_loss: 14.0008\n",
      "Epoch 37/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.9053 - val_loss: 13.9812\n",
      "Epoch 38/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 13.2518 - val_loss: 13.9379\n",
      "Epoch 39/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 13.1903 - val_loss: 13.9299\n",
      "Epoch 40/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.9140 - val_loss: 13.9245\n",
      "Epoch 41/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 13.1090 - val_loss: 13.9174\n",
      "Epoch 42/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 13.0287 - val_loss: 13.8891\n",
      "Epoch 43/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.8348 - val_loss: 13.8651\n",
      "Epoch 44/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 13.0368 - val_loss: 13.8348\n",
      "Epoch 45/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 13.0507 - val_loss: 13.8303\n",
      "Epoch 46/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 13.0774 - val_loss: 13.8218\n",
      "Epoch 47/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.9922 - val_loss: 13.8073\n",
      "Epoch 48/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.7863 - val_loss: 13.7831\n",
      "Epoch 49/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.8830 - val_loss: 13.7630\n",
      "Epoch 50/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 13.0295 - val_loss: 13.8024\n",
      "Epoch 51/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 12.8989 - val_loss: 13.7685\n",
      "Epoch 52/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 13.1077 - val_loss: 13.7733\n",
      "Epoch 53/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 13.0394 - val_loss: 13.7308\n",
      "Epoch 54/1000\n",
      "946/946 [==============================] - 0s 42us/step - loss: 13.0274 - val_loss: 13.7290\n",
      "Epoch 55/1000\n",
      "946/946 [==============================] - 0s 50us/step - loss: 12.8236 - val_loss: 13.7156\n",
      "Epoch 56/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.9224 - val_loss: 13.7126\n",
      "Epoch 57/1000\n",
      "946/946 [==============================] - 0s 46us/step - loss: 12.8496 - val_loss: 13.7694\n",
      "Epoch 58/1000\n",
      "946/946 [==============================] - 0s 35us/step - loss: 12.9609 - val_loss: 13.7759\n",
      "Epoch 59/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.7850 - val_loss: 13.6999\n",
      "Epoch 60/1000\n",
      "946/946 [==============================] - 0s 34us/step - loss: 12.8577 - val_loss: 13.6998\n",
      "Epoch 61/1000\n",
      "946/946 [==============================] - 0s 35us/step - loss: 12.8053 - val_loss: 13.6759\n",
      "Epoch 62/1000\n",
      "946/946 [==============================] - 0s 36us/step - loss: 12.7025 - val_loss: 13.7215\n",
      "Epoch 63/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.8007 - val_loss: 13.6991\n",
      "Epoch 64/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.7591 - val_loss: 13.6707\n",
      "Epoch 65/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.8156 - val_loss: 13.6278\n",
      "Epoch 66/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.7040 - val_loss: 13.6088\n",
      "Epoch 67/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.7697 - val_loss: 13.6266\n",
      "Epoch 68/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.9060 - val_loss: 13.6246\n",
      "Epoch 69/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.8263 - val_loss: 13.6056\n",
      "Epoch 70/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.7140 - val_loss: 13.6339\n",
      "Epoch 71/1000\n",
      "946/946 [==============================] - 0s 36us/step - loss: 12.7685 - val_loss: 13.6302\n",
      "Epoch 72/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.8131 - val_loss: 13.6117\n",
      "Epoch 73/1000\n",
      "946/946 [==============================] - 0s 35us/step - loss: 12.7407 - val_loss: 13.5962\n",
      "Epoch 74/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.7446 - val_loss: 13.5844\n",
      "Epoch 75/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.7601 - val_loss: 13.5384\n",
      "Epoch 76/1000\n",
      "946/946 [==============================] - 0s 36us/step - loss: 12.6313 - val_loss: 13.5525\n",
      "Epoch 77/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.7503 - val_loss: 13.5088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.7016 - val_loss: 13.5156\n",
      "Epoch 79/1000\n",
      "946/946 [==============================] - 0s 40us/step - loss: 12.7530 - val_loss: 13.5094\n",
      "Epoch 80/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.7755 - val_loss: 13.4850\n",
      "Epoch 81/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.7156 - val_loss: 13.5575\n",
      "Epoch 82/1000\n",
      "946/946 [==============================] - 0s 35us/step - loss: 12.6816 - val_loss: 13.5059\n",
      "Epoch 83/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.5547 - val_loss: 13.4441\n",
      "Epoch 84/1000\n",
      "946/946 [==============================] - 0s 35us/step - loss: 12.5934 - val_loss: 13.5113\n",
      "Epoch 85/1000\n",
      "946/946 [==============================] - 0s 36us/step - loss: 12.5816 - val_loss: 13.4803\n",
      "Epoch 86/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.6445 - val_loss: 13.4449\n",
      "Epoch 87/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.5406 - val_loss: 13.5112\n",
      "Epoch 88/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.6336 - val_loss: 13.4547\n",
      "Epoch 89/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.5410 - val_loss: 13.4535\n",
      "Epoch 90/1000\n",
      "946/946 [==============================] - 0s 36us/step - loss: 12.5800 - val_loss: 13.4416\n",
      "Epoch 91/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.4921 - val_loss: 13.4154\n",
      "Epoch 92/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.6832 - val_loss: 13.3912\n",
      "Epoch 93/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.3751 - val_loss: 13.3922\n",
      "Epoch 94/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.6038 - val_loss: 13.3931\n",
      "Epoch 95/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.4628 - val_loss: 13.4303\n",
      "Epoch 96/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4795 - val_loss: 13.3928\n",
      "Epoch 97/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5499 - val_loss: 13.4241\n",
      "Epoch 98/1000\n",
      "946/946 [==============================] - 0s 36us/step - loss: 12.5631 - val_loss: 13.4054\n",
      "Epoch 99/1000\n",
      "946/946 [==============================] - 0s 43us/step - loss: 12.6257 - val_loss: 13.3722\n",
      "Epoch 100/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.6198 - val_loss: 13.3931\n",
      "Epoch 101/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.5608 - val_loss: 13.3978\n",
      "Epoch 102/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.5700 - val_loss: 13.4175\n",
      "Epoch 103/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.5576 - val_loss: 13.3617\n",
      "Epoch 104/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.5068 - val_loss: 13.3703\n",
      "Epoch 105/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.4229 - val_loss: 13.3828\n",
      "Epoch 106/1000\n",
      "946/946 [==============================] - 0s 32us/step - loss: 12.4157 - val_loss: 13.3966\n",
      "Epoch 107/1000\n",
      "946/946 [==============================] - 0s 33us/step - loss: 12.6940 - val_loss: 13.3904\n",
      "Epoch 108/1000\n",
      "946/946 [==============================] - 0s 36us/step - loss: 12.5255 - val_loss: 13.3724\n",
      "Epoch 109/1000\n",
      "946/946 [==============================] - 0s 35us/step - loss: 12.4110 - val_loss: 13.3248\n",
      "Epoch 110/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.4639 - val_loss: 13.3146\n",
      "Epoch 111/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.5970 - val_loss: 13.3628\n",
      "Epoch 112/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.4977 - val_loss: 13.3171\n",
      "Epoch 113/1000\n",
      "946/946 [==============================] - 0s 39us/step - loss: 12.3863 - val_loss: 13.3055\n",
      "Epoch 114/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.5187 - val_loss: 13.3767\n",
      "Epoch 115/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.4410 - val_loss: 13.2996\n",
      "Epoch 116/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.5276 - val_loss: 13.3015\n",
      "Epoch 117/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.4398 - val_loss: 13.3001\n",
      "Epoch 118/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.4860 - val_loss: 13.3012\n",
      "Epoch 119/1000\n",
      "946/946 [==============================] - 0s 35us/step - loss: 12.5239 - val_loss: 13.2521\n",
      "Epoch 120/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.4656 - val_loss: 13.2630\n",
      "Epoch 121/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.5405 - val_loss: 13.2464\n",
      "Epoch 122/1000\n",
      "946/946 [==============================] - 0s 41us/step - loss: 12.5953 - val_loss: 13.2815\n",
      "Epoch 123/1000\n",
      "946/946 [==============================] - 0s 44us/step - loss: 12.4959 - val_loss: 13.2636\n",
      "Epoch 124/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.2761 - val_loss: 13.3040\n",
      "Epoch 125/1000\n",
      "946/946 [==============================] - 0s 35us/step - loss: 12.3927 - val_loss: 13.2829\n",
      "Epoch 126/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.4662 - val_loss: 13.2529\n",
      "Epoch 127/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.3598 - val_loss: 13.2663\n",
      "Epoch 128/1000\n",
      "946/946 [==============================] - 0s 35us/step - loss: 12.5006 - val_loss: 13.2871\n",
      "Epoch 129/1000\n",
      "946/946 [==============================] - 0s 37us/step - loss: 12.5349 - val_loss: 13.3112\n",
      "Epoch 130/1000\n",
      "946/946 [==============================] - 0s 38us/step - loss: 12.4207 - val_loss: 13.2603\n",
      "Epoch 131/1000\n",
      "946/946 [==============================] - 0s 36us/step - loss: 12.2519 - val_loss: 13.2623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a240e0b00>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs: 134\n",
    "# val_loss: 12.61628206298345\n",
    "# regularizer: l1\n",
    "# dropout: 0.2\n",
    "# hidden layers: 1\n",
    "# hidden nodes: 75\n",
    "# epochs: 1000\n",
    "# patience: 10\n",
    "\n",
    "network4 = Sequential()\n",
    "\n",
    "network4.add(Dense(units=Xrs_train.shape[1],\n",
    "                   activation=\"relu\",\n",
    "                   input_dim=Xrs_train.shape[1],\n",
    "                   kernel_regularizer=regularizers.l1(.001)))\n",
    "network4.add(Dropout(.2))\n",
    "\n",
    "\n",
    "network4.add(Dense(units=75,\n",
    "                   activation=\"relu\",\n",
    "                   kernel_regularizer=regularizers.l1(.001)))\n",
    "network4.add(Dropout(.2))\n",
    "\n",
    "\n",
    "# network3.add(Dense(units=75,\n",
    "#                    activation=\"relu\",\n",
    "#                    kernel_regularizer=regularizers.l1(.001)))\n",
    "# network3.add(Dropout(.2))\n",
    "\n",
    "\n",
    "network4.add(Dense(units=1,\n",
    "                   activation=None,\n",
    "                   kernel_regularizer=regularizers.l1(.001)))\n",
    "\n",
    "network4.compile(loss=\"mean_absolute_error\", optimizer=\"adam\")\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=10)\n",
    "\n",
    "network4.fit(Xrs_train, yr_train, validation_data=(Xrs_test, yr_test), epochs=1000, callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "new_preds = pred_maker(test, network4, \"nn_earlystop_nopoly_l1.csv\", polyfunc=None, scalerfunc=ss2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE: 29.7476"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
